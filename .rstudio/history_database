1618254751080:filter(!is.na(X63)) %>%
1618254751105:rename(Country = `Data Source`)%>%
1618254751126:rename(Fertility_Rate = X63)
1618254751173:filter(Country != Country Name)
1618254763248:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618254763267:library(openintro)
1618254763288:library(tidyverse)
1618254763308:library(dplyr)
1618254763359:fertility <- read_csv("Fertility.csv")
1618254763598:femalepop <- read_csv("FemalePopulation.csv")
1618254763834:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254763875:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254763906:fertility <- fertility %>%
1618254763923:select(`Data Source` ,X63) %>%
1618254763946:filter(!is.na(X63)) %>%
1618254763966:rename(Country = `Data Source`)%>%
1618254763987:rename(Fertility_Rate = X63) %>%
1618254764006:filter(Country != Country Name)
1618254779337:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618254779362:library(openintro)
1618254779381:library(tidyverse)
1618254779405:library(dplyr)
1618254779451:fertility <- read_csv("Fertility.csv")
1618254779652:femalepop <- read_csv("FemalePopulation.csv")
1618254779908:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254779949:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254779981:fertility <- fertility %>%
1618254779999:select(`Data Source` ,X63) %>%
1618254780020:filter(!is.na(X63)) %>%
1618254780040:rename(Country = `Data Source`)%>%
1618254780059:rename(Fertility_Rate = X63) %>%
1618254780075:filter(Country != "Country Name")
1618254780113:fertility
1618254780182:femalepop
1618254780435:# Use this to calculate some summary measures.
1618254780514:# Use this to create some plots.
1618254780601:# Here you can run your lm...
1618254780647:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618254780785:## Maybe create a nice scatterplot with a regression line laid on top.
1618254780890:# Here you can calculate your CIs, run a bootstrap, etc.
1618254780966:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254781032:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618254781123:# Here you can calculate your test stats, critical values, etc.
1618254781170:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254781258:# Here you can calculate your test stats, critical values, etc.
1618254781302:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618254781333:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618254781406:# Here you can calculate your Credible Interval
1618254781493:# Here you can include some relevant visualizations.
1618254807267:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254807303:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254807342:fertility <- fertility %>%
1618254807367:select(`Data Source` ,X63) %>%
1618254807393:filter(!is.na(X63)) %>%
1618254807418:rename(Country = `Data Source`)%>%
1618254807443:rename(Fertility_Rate = X63) %>%
1618254807464:filter(Country != "Country Name")
1618254811122:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618254811143:library(openintro)
1618254811160:library(tidyverse)
1618254811182:library(dplyr)
1618254811228:fertility <- read_csv("Fertility.csv")
1618254811744:femalepop <- read_csv("FemalePopulation.csv")
1618254811974:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254812011:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254812046:fertility <- fertility %>%
1618254812067:select(`Data Source` ,X63) %>%
1618254812091:filter(!is.na(X63)) %>%
1618254812122:rename(Country = `Data Source`)%>%
1618254812146:rename(Fertility_Rate = X63) %>%
1618254812169:filter(Country != "Country Name")
1618254812218:fertility
1618254812288:femalepop <- femalepop %>%
1618254812305:select(`Data Source` ,X63) %>%
1618254812328:filter(!is.na(X63)) %>%
1618254812349:rename(Country = `Data Source`)%>%
1618254812370:rename(Fertility_Rate = X63) %>%
1618254812393:filter(Country != "Country Name")
1618254812432:femalepop
1618254812529:# Use this to calculate some summary measures.
1618254812624:# Use this to create some plots.
1618254812701:# Here you can run your lm...
1618254812741:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618254812863:## Maybe create a nice scatterplot with a regression line laid on top.
1618254812968:# Here you can calculate your CIs, run a bootstrap, etc.
1618254813021:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254813116:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618254813209:# Here you can calculate your test stats, critical values, etc.
1618254813254:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254813336:# Here you can calculate your test stats, critical values, etc.
1618254813381:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618254813402:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618254813478:# Here you can calculate your Credible Interval
1618254813564:# Here you can include some relevant visualizations.
1618254828707:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254828744:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254828775:fertility <- fertility %>%
1618254828795:select(`Data Source` ,X63) %>%
1618254828822:filter(!is.na(X63)) %>%
1618254828842:rename(Country = `Data Source`)%>%
1618254828858:rename(Fertility_Rate = X63) %>%
1618254828877:filter(Country != "Country Name")
1618254832784:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618254832808:library(openintro)
1618254832828:library(tidyverse)
1618254832848:library(dplyr)
1618254832889:fertility <- read_csv("Fertility.csv")
1618254833109:femalepop <- read_csv("FemalePopulation.csv")
1618254833328:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618254833365:# You may need additional chunks, in case you want to include some of the cleaning output.
1618254833398:fertility <- fertility %>%
1618254833421:select(`Data Source` ,X63) %>%
1618254833443:filter(!is.na(X63)) %>%
1618254833461:rename(Country = `Data Source`)%>%
1618254833482:rename(Fertility_Rate = X63) %>%
1618254833500:filter(Country != "Country Name")
1618254833542:fertility
1618254833611:femalepop <- femalepop %>%
1618254833628:select(`Data Source` ,X63) %>%
1618254833647:filter(!is.na(X63)) %>%
1618254833670:rename(Country = `Data Source`)%>%
1618254833693:rename(Population = X63) %>%
1618254833711:filter(Country != "Country Name")
1618254833746:femalepop
1618254833834:# Use this to calculate some summary measures.
1618254833912:# Use this to create some plots.
1618254833993:# Here you can run your lm...
1618254834034:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618254834164:## Maybe create a nice scatterplot with a regression line laid on top.
1618254834282:# Here you can calculate your CIs, run a bootstrap, etc.
1618254834343:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254834423:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618254834510:# Here you can calculate your test stats, critical values, etc.
1618254834553:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618254834632:# Here you can calculate your test stats, critical values, etc.
1618254834672:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618254834693:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618254834772:# Here you can calculate your Credible Interval
1618254834848:# Here you can include some relevant visualizations.
1618255157033:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255157054:library(openintro)
1618255157072:library(tidyverse)
1618255157090:library(dplyr)
1618255157131:fertility <- read_csv("Fertility.csv")
1618255157385:femalepop <- read_csv("FemalePopulation.csv")
1618255157654:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255157697:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255157729:fertility <- fertility %>%
1618255157751:select(`Data Source` ,X63) %>%
1618255157769:filter(!is.na(X63)) %>%
1618255157789:rename(Country = `Data Source`)%>%
1618255157809:rename(Fertility_Rate = X63) %>%
1618255157828:filter(Country != "Country Name" && Country != "Bermuda")
1618255157870:fertility
1618255157931:femalepop <- femalepop %>%
1618255157951:select(`Data Source` ,X63) %>%
1618255157970:filter(!is.na(X63)) %>%
1618255157989:rename(Country = `Data Source`)%>%
1618255158014:rename(Population = X63) %>%
1618255158035:filter(Country != "Country Name")
1618255158081:femalepop
1618255158173:# Use this to calculate some summary measures.
1618255158283:# Use this to create some plots.
1618255158360:# Here you can run your lm...
1618255158400:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255158537:## Maybe create a nice scatterplot with a regression line laid on top.
1618255158644:# Here you can calculate your CIs, run a bootstrap, etc.
1618255158707:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255158788:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255158873:# Here you can calculate your test stats, critical values, etc.
1618255158918:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255158999:# Here you can calculate your test stats, critical values, etc.
1618255159045:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255159066:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255159150:# Here you can calculate your Credible Interval
1618255159279:# Here you can include some relevant visualizations.
1618255210693:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255210716:library(openintro)
1618255210738:library(tidyverse)
1618255210761:library(dplyr)
1618255210810:fertility <- read_csv("Fertility.csv")
1618255211005:femalepop <- read_csv("FemalePopulation.csv")
1618255211245:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255211290:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255211322:fertility <- fertility %>%
1618255211343:select(`Data Source` ,X63) %>%
1618255211363:filter(!is.na(X63)) %>%
1618255211383:rename(Country = `Data Source`)%>%
1618255211404:rename(Fertility_Rate = X63) %>%
1618255211422:filter(Country != "Country Name") %>%
1618255211441:filter(Country != "Bermuda")
1618255211482:fertility
1618255211547:femalepop <- femalepop %>%
1618255211568:select(`Data Source` ,X63) %>%
1618255211592:filter(!is.na(X63)) %>%
1618255211610:rename(Country = `Data Source`)%>%
1618255211632:rename(Population = X63) %>%
1618255211655:filter(Country != "Country Name")
1618255211697:femalepop
1618255211805:# Use this to calculate some summary measures.
1618255211925:# Use this to create some plots.
1618255212020:# Here you can run your lm...
1618255212057:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255212205:## Maybe create a nice scatterplot with a regression line laid on top.
1618255212324:# Here you can calculate your CIs, run a bootstrap, etc.
1618255212381:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255212463:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255212550:# Here you can calculate your test stats, critical values, etc.
1618255212595:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255212685:# Here you can calculate your test stats, critical values, etc.
1618255212732:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255212756:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255212833:# Here you can calculate your Credible Interval
1618255212906:# Here you can include some relevant visualizations.
1618255226251:View(femalepop)
1618255227736:View(fertility)
1618255381097:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255381120:library(openintro)
1618255381145:library(tidyverse)
1618255381174:library(dplyr)
1618255381227:fertility <- read_csv("Fertility.csv")
1618255381438:femalepop <- read_csv("FemalePopulation.csv")
1618255381773:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255381818:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255381850:fertility <- fertility %>%
1618255381870:select(`Data Source` ,X63) %>%
1618255381890:filter(!is.na(X63)) %>%
1618255381917:rename(Country = `Data Source`)%>%
1618255381939:rename(Fertility_Rate = X63) %>%
1618255381960:filter(Country != "Country Name") %>%
1618255381982:filter(Country != "Bermuda")
1618255382031:filter(Country != "Eritrea")
1618255393352:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255393378:library(openintro)
1618255393397:library(tidyverse)
1618255393419:library(dplyr)
1618255393474:fertility <- read_csv("Fertility.csv")
1618255393679:femalepop <- read_csv("FemalePopulation.csv")
1618255393941:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255393982:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255394024:fertility <- fertility %>%
1618255394046:select(`Data Source` ,X63) %>%
1618255394072:filter(!is.na(X63)) %>%
1618255394093:rename(Country = `Data Source`)%>%
1618255394116:rename(Fertility_Rate = X63) %>%
1618255394140:filter(Country != "Country Name") %>%
1618255394161:filter(Country != "Bermuda")
1618255394200:filter(Country != "Eritrea")
1618255417281:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255417304:library(openintro)
1618255417323:library(tidyverse)
1618255417342:library(dplyr)
1618255417388:fertility <- read_csv("Fertility.csv")
1618255417622:femalepop <- read_csv("FemalePopulation.csv")
1618255417840:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255417878:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255417923:fertility <- fertility %>%
1618255417945:select(`Data Source` ,X63) %>%
1618255417966:filter(!is.na(X63)) %>%
1618255417987:rename(Country = `Data Source`)%>%
1618255418011:rename(Fertility_Rate = X63) %>%
1618255418033:filter(Country != "Country Name") %>%
1618255418056:filter(Country != "Bermuda")
1618255418100:filter(Country != "Eritrea")
1618255451850:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255451869:library(openintro)
1618255451887:library(tidyverse)
1618255451906:library(dplyr)
1618255451952:fertility <- read_csv("Fertility.csv")
1618255452215:femalepop <- read_csv("FemalePopulation.csv")
1618255452472:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255452519:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255452556:fertility <- fertility %>%
1618255452579:select(`Data Source` ,X63) %>%
1618255452598:filter(!is.na(X63)) %>%
1618255452615:rename(Country = `Data Source`)%>%
1618255452646:rename(Fertility_Rate = X63) %>%
1618255452677:filter(Country != "Country Name") %>%
1618255452708:filter(Country != "Bermuda")
1618255452794:filter(Fertility_Rate != "4.056000")
1618255482640:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255482662:library(openintro)
1618255482686:library(tidyverse)
1618255482706:library(dplyr)
1618255482752:fertility <- read_csv("Fertility.csv")
1618255482950:femalepop <- read_csv("FemalePopulation.csv")
1618255483198:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255483235:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255483265:fertility <- fertility %>%
1618255483283:select(`Data Source` ,X63) %>%
1618255483303:filter(!is.na(X63)) %>%
1618255483322:rename(Country = `Data Source`)%>%
1618255483340:rename(Fertility_Rate = X63) %>%
1618255483358:filter(Country != "Country Name") %>%
1618255483379:filter(Country != "Bermuda" || "Eritrea")
1618255483417:fertility
1618255483483:femalepop <- femalepop %>%
1618255483503:select(`Data Source` ,X63) %>%
1618255483522:filter(!is.na(X63)) %>%
1618255483544:rename(Country = `Data Source`)%>%
1618255483564:rename(Population = X63) %>%
1618255483583:filter(Country != "Country Name")
1618255483641:femalepop
1618255483734:# Use this to calculate some summary measures.
1618255483844:# Use this to create some plots.
1618255483918:# Here you can run your lm...
1618255483955:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255484079:## Maybe create a nice scatterplot with a regression line laid on top.
1618255484175:# Here you can calculate your CIs, run a bootstrap, etc.
1618255484227:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255484298:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255484373:# Here you can calculate your test stats, critical values, etc.
1618255484410:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255484477:# Here you can calculate your test stats, critical values, etc.
1618255484519:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255484541:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255484622:# Here you can calculate your Credible Interval
1618255484711:# Here you can include some relevant visualizations.
1618255517511:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255517531:library(openintro)
1618255517551:library(tidyverse)
1618255517574:library(dplyr)
1618255517638:fertility <- read_csv("Fertility.csv")
1618255517830:femalepop <- read_csv("FemalePopulation.csv")
1618255518097:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255518142:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255518183:fertility <- fertility %>%
1618255518206:select(`Data Source` ,X63) %>%
1618255518229:filter(!is.na(X63)) %>%
1618255518250:rename(Country = `Data Source`)%>%
1618255518271:rename(Fertility_Rate = X63) %>%
1618255518294:filter(Country != "Country Name") %>%
1618255518324:filter(Country != "Bermuda" || Country != "Eritrea")
1618255518372:fertility
1618255518434:femalepop <- femalepop %>%
1618255518451:select(`Data Source` ,X63) %>%
1618255518477:filter(!is.na(X63)) %>%
1618255518495:rename(Country = `Data Source`)%>%
1618255518522:rename(Population = X63) %>%
1618255518541:filter(Country != "Country Name")
1618255518579:femalepop
1618255518689:# Use this to calculate some summary measures.
1618255518829:# Use this to create some plots.
1618255518911:# Here you can run your lm...
1618255518949:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255519079:## Maybe create a nice scatterplot with a regression line laid on top.
1618255519195:# Here you can calculate your CIs, run a bootstrap, etc.
1618255519258:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255519351:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255519442:# Here you can calculate your test stats, critical values, etc.
1618255519486:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255519569:# Here you can calculate your test stats, critical values, etc.
1618255519611:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255519634:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255519714:# Here you can calculate your Credible Interval
1618255519806:# Here you can include some relevant visualizations.
1618255530607:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255530631:library(openintro)
1618255530652:library(tidyverse)
1618255530676:library(dplyr)
1618255530735:fertility <- read_csv("Fertility.csv")
1618255530965:femalepop <- read_csv("FemalePopulation.csv")
1618255531216:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255531260:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255531295:fertility <- fertility %>%
1618255531317:select(`Data Source` ,X63) %>%
1618255531341:filter(!is.na(X63)) %>%
1618255531364:rename(Country = `Data Source`)%>%
1618255531387:rename(Fertility_Rate = X63) %>%
1618255531412:filter(Country != "Country Name") %>%
1618255531433:filter(Country != "Bermuda" & Country != "Eritrea")
1618255531475:fertility
1618255531557:femalepop <- femalepop %>%
1618255531582:select(`Data Source` ,X63) %>%
1618255531606:filter(!is.na(X63)) %>%
1618255531631:rename(Country = `Data Source`)%>%
1618255531652:rename(Population = X63) %>%
1618255531676:filter(Country != "Country Name")
1618255531717:femalepop
1618255531821:# Use this to calculate some summary measures.
1618255531943:# Use this to create some plots.
1618255532035:# Here you can run your lm...
1618255532087:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255532226:## Maybe create a nice scatterplot with a regression line laid on top.
1618255532333:# Here you can calculate your CIs, run a bootstrap, etc.
1618255532395:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255532481:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255532559:# Here you can calculate your test stats, critical values, etc.
1618255532610:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255532697:# Here you can calculate your test stats, critical values, etc.
1618255532747:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255532770:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255532856:# Here you can calculate your Credible Interval
1618255532971:# Here you can include some relevant visualizations.
1618255591606:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255591626:library(openintro)
1618255591647:library(tidyverse)
1618255591669:library(dplyr)
1618255591714:fertility <- read_csv("Fertility.csv")
1618255591916:femalepop <- read_csv("FemalePopulation.csv")
1618255592215:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255592267:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255592301:fertility <- fertility %>%
1618255592323:select(`Data Source` ,X63) %>%
1618255592343:filter(!is.na(X63)) %>%
1618255592362:rename(Country = `Data Source`)%>%
1618255592383:rename(Fertility_Rate = X63) %>%
1618255592406:filter(Country != "Country Name") %>%
1618255592428:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands")
1618255592469:fertility
1618255592537:femalepop <- femalepop %>%
1618255592556:select(`Data Source` ,X63) %>%
1618255592578:filter(!is.na(X63)) %>%
1618255592598:rename(Country = `Data Source`)%>%
1618255592617:rename(Population = X63) %>%
1618255592636:filter(Country != "Country Name")
1618255592679:femalepop
1618255592771:# Use this to calculate some summary measures.
1618255592880:# Use this to create some plots.
1618255592961:# Here you can run your lm...
1618255593004:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255593147:## Maybe create a nice scatterplot with a regression line laid on top.
1618255593283:# Here you can calculate your CIs, run a bootstrap, etc.
1618255593338:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255593424:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255593510:# Here you can calculate your test stats, critical values, etc.
1618255593556:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255593635:# Here you can calculate your test stats, critical values, etc.
1618255593678:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255593697:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255593778:# Here you can calculate your Credible Interval
1618255593865:# Here you can include some relevant visualizations.
1618255663357:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255663385:library(openintro)
1618255663407:library(tidyverse)
1618255663427:library(dplyr)
1618255663478:fertility <- read_csv("Fertility.csv")
1618255663712:femalepop <- read_csv("FemalePopulation.csv")
1618255663973:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255664020:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255664056:fertility <- fertility %>%
1618255664076:select(`Data Source` ,X63) %>%
1618255664097:filter(!is.na(X63)) %>%
1618255664125:rename(Country = `Data Source`)%>%
1618255664148:rename(Fertility_Rate = X63) %>%
1618255664174:filter(Country != "Country Name") %>%
1618255664197:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland")
1618255664249:fertility
1618255664329:femalepop <- femalepop %>%
1618255664354:select(`Data Source` ,X63) %>%
1618255664373:filter(!is.na(X63)) %>%
1618255664399:rename(Country = `Data Source`)%>%
1618255664422:rename(Population = X63) %>%
1618255664454:filter(Country != "Country Name")
1618255664493:femalepop
1618255664596:# Use this to calculate some summary measures.
1618255664723:# Use this to create some plots.
1618255664808:# Here you can run your lm...
1618255664850:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255664984:## Maybe create a nice scatterplot with a regression line laid on top.
1618255665091:# Here you can calculate your CIs, run a bootstrap, etc.
1618255665152:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255665227:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255665302:# Here you can calculate your test stats, critical values, etc.
1618255665344:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255665420:# Here you can calculate your test stats, critical values, etc.
1618255665462:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255665486:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255665566:# Here you can calculate your Credible Interval
1618255665649:# Here you can include some relevant visualizations.
1618255735506:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255735527:library(openintro)
1618255735550:library(tidyverse)
1618255735577:library(dplyr)
1618255735626:fertility <- read_csv("Fertility.csv")
1618255735853:femalepop <- read_csv("FemalePopulation.csv")
1618255736089:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255736128:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255736164:fertility <- fertility %>%
1618255736184:select(`Data Source` ,X63) %>%
1618255736204:filter(!is.na(X63)) %>%
1618255736230:rename(Country = `Data Source`)%>%
1618255736254:rename(Fertility_Rate = X63) %>%
1618255736278:filter(Country != "Country Name") %>%
1618255736299:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein")
1618255736340:fertility
1618255736420:femalepop <- femalepop %>%
1618255736444:select(`Data Source` ,X63) %>%
1618255736468:filter(!is.na(X63)) %>%
1618255736491:rename(Country = `Data Source`)%>%
1618255736513:rename(Population = X63) %>%
1618255736534:filter(Country != "Country Name")
1618255736574:femalepop
1618255736671:# Use this to calculate some summary measures.
1618255736774:# Use this to create some plots.
1618255736855:# Here you can run your lm...
1618255736898:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255737028:## Maybe create a nice scatterplot with a regression line laid on top.
1618255737137:# Here you can calculate your CIs, run a bootstrap, etc.
1618255737200:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255737291:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255737374:# Here you can calculate your test stats, critical values, etc.
1618255737419:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255737497:# Here you can calculate your test stats, critical values, etc.
1618255737539:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255737562:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255737641:# Here you can calculate your Credible Interval
1618255737725:# Here you can include some relevant visualizations.
1618255798754:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255798778:library(openintro)
1618255798797:library(tidyverse)
1618255798817:library(dplyr)
1618255798867:fertility <- read_csv("Fertility.csv")
1618255799069:femalepop <- read_csv("FemalePopulation.csv")
1618255799345:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255799401:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255799442:fertility <- fertility %>%
1618255799464:select(`Data Source` ,X63) %>%
1618255799487:filter(!is.na(X63)) %>%
1618255799524:rename(Country = `Data Source`)%>%
1618255799544:rename(Fertility_Rate = X63) %>%
1618255799574:filter(Country != "Country Name") %>%
1618255799619:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)")
1618255799661:fertility
1618255799730:femalepop <- femalepop %>%
1618255799750:select(`Data Source` ,X63) %>%
1618255799769:filter(!is.na(X63)) %>%
1618255799790:rename(Country = `Data Source`)%>%
1618255799814:rename(Population = X63) %>%
1618255799837:filter(Country != "Country Name")
1618255799883:femalepop
1618255799980:# Use this to calculate some summary measures.
1618255800096:# Use this to create some plots.
1618255800194:# Here you can run your lm...
1618255800246:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255800395:## Maybe create a nice scatterplot with a regression line laid on top.
1618255800506:# Here you can calculate your CIs, run a bootstrap, etc.
1618255800570:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255800658:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255800751:# Here you can calculate your test stats, critical values, etc.
1618255800801:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255800894:# Here you can calculate your test stats, critical values, etc.
1618255800943:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255800964:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255801054:# Here you can calculate your Credible Interval
1618255801153:# Here you can include some relevant visualizations.
1618255963437:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255963459:library(openintro)
1618255963479:library(tidyverse)
1618255963499:library(dplyr)
1618255963553:fertility <- read_csv("Fertility.csv")
1618255963761:femalepop <- read_csv("FemalePopulation.csv")
1618255964028:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255964069:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255964103:fertility <- fertility %>%
1618255964123:select(`Data Source` ,X63) %>%
1618255964140:filter(!is.na(X63)) %>%
1618255964157:rename(Country = `Data Source`)%>%
1618255964178:rename(Fertility_Rate = X63) %>%
1618255964199:filter(Country != "Country Name") %>%
1618255964219:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World")
1618255964259:fertility
1618255964334:femalepop <- femalepop %>%
1618255964354:select(`Data Source` ,X63) %>%
1618255964382:filter(!is.na(X63)) %>%
1618255964404:rename(Country = `Data Source`)%>%
1618255964424:rename(Population = X63) %>%
1618255964444:filter(Country != "Country Name")
1618255964486:femalepop
1618255964571:# Use this to calculate some summary measures.
1618255964700:# Use this to create some plots.
1618255964777:# Here you can run your lm...
1618255964817:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255964946:## Maybe create a nice scatterplot with a regression line laid on top.
1618255965068:# Here you can calculate your CIs, run a bootstrap, etc.
1618255965125:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255965198:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255965276:# Here you can calculate your test stats, critical values, etc.
1618255965316:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255965394:# Here you can calculate your test stats, critical values, etc.
1618255965438:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255965460:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255965549:# Here you can calculate your Credible Interval
1618255965620:# Here you can include some relevant visualizations.
1618255984317:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618255984335:library(openintro)
1618255984356:library(tidyverse)
1618255984377:library(dplyr)
1618255984427:fertility <- read_csv("Fertility.csv")
1618255984650:femalepop <- read_csv("FemalePopulation.csv")
1618255984904:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618255984946:# You may need additional chunks, in case you want to include some of the cleaning output.
1618255984977:fertility <- fertility %>%
1618255984996:select(`Data Source` ,X63) %>%
1618255985015:filter(!is.na(X63)) %>%
1618255985036:rename(Country = `Data Source`)%>%
1618255985060:rename(Fertility_Rate = X63) %>%
1618255985083:filter(Country != "Country Name") %>%
1618255985102:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World")
1618255985143:fertility
1618255985216:femalepop <- femalepop %>%
1618255985235:select(`Data Source` ,X63) %>%
1618255985254:filter(!is.na(X63)) %>%
1618255985277:rename(Country = `Data Source`)%>%
1618255985297:rename(Population = X63) %>%
1618255985320:filter(Country != "Country Name" & Country != "World")
1618255985364:femalepop
1618255985466:# Use this to calculate some summary measures.
1618255985587:# Use this to create some plots.
1618255985675:# Here you can run your lm...
1618255985722:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618255985878:## Maybe create a nice scatterplot with a regression line laid on top.
1618255985996:# Here you can calculate your CIs, run a bootstrap, etc.
1618255986056:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255986174:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618255986260:# Here you can calculate your test stats, critical values, etc.
1618255986297:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618255986365:# Here you can calculate your test stats, critical values, etc.
1618255986412:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618255986434:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618255986511:# Here you can calculate your Credible Interval
1618255986596:# Here you can include some relevant visualizations.
1618256246770:# Use this to calculate some summary measures.
1618256246796:summary(fertility$Fertility_Rate)
1618256246864:summary(femalepop$Population)
1618256255321:# Use this to calculate some summary measures.
1618256255346:summary(fertility$Fertility_Rate)
1618256255441:summary(femalepop$Population)
1618256339726:# Use this to calculate some summary measures.
1618256339748:summary(fertility$Fertility_Rate)
1618256339825:summary(femalepop$Population)
1618256339911:var(fertility$Fertility_Rate)
1618256339940:var(femalepop$Population)
1618256355131:# Use this to calculate some summary measures.
1618256355153:summary(fertility$Fertility_Rate)
1618256355240:summary(femalepop$Population)
1618256355319:sqrt(var(fertility$Fertility_Rate))
1618256355354:sqrt(var(femalepop$Population))
1618256622557:# Use this to calculate some summary measures.
1618256622577:summary(fertility$Fertility_Rate)
1618256622657:minimum(fertility$Fertility_Rate)
1618256627974:# Use this to calculate some summary measures.
1618256627998:summary(fertility$Fertility_Rate)
1618256628093:min(fertility$Fertility_Rate)
1618256628127:summary(femalepop$Population)
1618256628213:sqrt(var(fertility$Fertility_Rate))
1618256628254:sqrt(var(femalepop$Population))
1618256648379:# Use this to calculate some summary measures.
1618256648402:summary(fertility$Fertility_Rate)
1618256648492:summary(femalepop$Population)
1618256648573:min(femalepop$Population)
1618256648606:sqrt(var(fertility$Fertility_Rate))
1618256648647:sqrt(var(femalepop$Population))
1618256724702:# Use this to calculate some summary measures.
1618256724729:summary(fertility$Fertility_Rate, signif(digits = 10))
1618256724800:summary(femalepop$Population)
1618256724881:sqrt(var(fertility$Fertility_Rate))
1618256724915:sqrt(var(femalepop$Population))
1618257550573:# Use this to calculate some summary measures.
1618257550609:summary(fertility$Fertility_Rate, digits = signif(digits = 10))
1618257592844:# Use this to calculate some summary measures.
1618257592865:summary(fertility$Fertility_Rate, digits = signif(fertility$Fertility_Rate, digits = 10))
1618257595139:summary(femalepop$Population)
1618257595237:sqrt(var(fertility$Fertility_Rate))
1618257595276:sqrt(var(femalepop$Population))
1618257597832:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618257597853:library(openintro)
1618257597874:library(tidyverse)
1618257597902:library(dplyr)
1618257597946:fertility <- read_csv("Fertility.csv")
1618257598191:femalepop <- read_csv("FemalePopulation.csv")
1618257598468:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618257598510:# You may need additional chunks, in case you want to include some of the cleaning output.
1618257598549:fertility <- fertility %>%
1618257598573:select(`Data Source` ,X63) %>%
1618257598595:filter(!is.na(X63)) %>%
1618257598614:rename(Country = `Data Source`)%>%
1618257598636:rename(Fertility_Rate = X63) %>%
1618257598661:filter(Country != "Country Name") %>%
1618257598685:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World")
1618257598731:fertility
1618257598802:femalepop <- femalepop %>%
1618257598823:select(`Data Source` ,X63) %>%
1618257598842:filter(!is.na(X63)) %>%
1618257598864:rename(Country = `Data Source`)%>%
1618257598883:rename(Population = X63) %>%
1618257598901:filter(Country != "Country Name" & Country != "World")
1618257598946:femalepop
1618257599052:# Use this to calculate some summary measures.
1618257599080:summary(fertility$Fertility_Rate, digits = signif(fertility$Fertility_Rate, digits = 10))
1618257601334:summary(femalepop$Population)
1618257601418:sqrt(var(fertility$Fertility_Rate))
1618257601455:sqrt(var(femalepop$Population))
1618257601528:# Use this to create some plots.
1618257601616:# Here you can run your lm...
1618257601659:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618257601811:## Maybe create a nice scatterplot with a regression line laid on top.
1618257601936:# Here you can calculate your CIs, run a bootstrap, etc.
1618257601998:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618257602078:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618257602178:# Here you can calculate your test stats, critical values, etc.
1618257602221:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618257602301:# Here you can calculate your test stats, critical values, etc.
1618257602349:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618257602371:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618257602453:# Here you can calculate your Credible Interval
1618257602534:# Here you can include some relevant visualizations.
1618257615045:# Use this to calculate some summary measures.
1618257615068:summary(fertility$Fertility_Rate, digits = signif(fertility$Fertility_Rate, digits = 1))
1618257617345:summary(femalepop$Population)
1618257617438:sqrt(var(fertility$Fertility_Rate))
1618257617474:sqrt(var(femalepop$Population))
1618257627378:# Use this to calculate some summary measures.
1618257627412:summary(fertility$Fertility_Rate, digits = signif(fertility$Fertility_Rate))
1618257629746:summary(femalepop$Population)
1618257629837:sqrt(var(fertility$Fertility_Rate))
1618257629871:sqrt(var(femalepop$Population))
1618257635123:# Use this to calculate some summary measures.
1618257635146:summary(fertility$Fertility_Rate)
1618257635240:summary(femalepop$Population)
1618257635323:sqrt(var(fertility$Fertility_Rate))
1618257635358:sqrt(var(femalepop$Population))
1618258424146:View(femalepop)
1618258505523:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618258505552:library(openintro)
1618258505575:library(tidyverse)
1618258505597:library(dplyr)
1618258505653:fertility <- read_csv("Fertility.csv")
1618258505897:femalepop <- read_csv("FemalePopulation.csv")
1618258506162:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618258506207:# You may need additional chunks, in case you want to include some of the cleaning output.
1618258506247:fertility <- fertility %>%
1618258506272:select(`Data Source` ,X63) %>%
1618258506294:filter(!is.na(X63)) %>%
1618258506317:rename(Country = `Data Source`)%>%
1618258506342:rename(Fertility_Rate = X63) %>%
1618258506371:filter(Country != "Country Name") %>%
1618258506396:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "IDA & IBRD total")
1618258506444:fertility
1618258506516:femalepop <- femalepop %>%
1618258506536:select(`Data Source` ,X63) %>%
1618258506557:filter(!is.na(X63)) %>%
1618258506588:rename(Country = `Data Source`)%>%
1618258506609:rename(Population = X63) %>%
1618258506630:filter(Country != "Country Name" & Country != "World" & Country != "IDA & IBRD total")
1618258506671:femalepop
1618258506753:# Use this to calculate some summary measures.
1618258506781:summary(fertility$Fertility_Rate)
1618258506850:summary(femalepop$Population)
1618258506938:sqrt(var(fertility$Fertility_Rate))
1618258506974:sqrt(var(femalepop$Population))
1618258507046:# Use this to create some plots.
1618258507136:# Here you can run your lm...
1618258507177:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618258507311:## Maybe create a nice scatterplot with a regression line laid on top.
1618258507428:# Here you can calculate your CIs, run a bootstrap, etc.
1618258507482:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618258507555:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618258507639:# Here you can calculate your test stats, critical values, etc.
1618258507684:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618258507764:# Here you can calculate your test stats, critical values, etc.
1618258507810:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618258507831:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618258507906:# Here you can calculate your Credible Interval
1618258507983:# Here you can include some relevant visualizations.
1618258525535:View(femalepop)
1618260112288:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618260112310:library(openintro)
1618260112329:library(tidyverse)
1618260112348:library(dplyr)
1618260112398:fertility <- read_csv("Fertility.csv")
1618260112628:femalepop <- read_csv("FemalePopulation.csv")
1618260112899:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618260112939:# You may need additional chunks, in case you want to include some of the cleaning output.
1618260112972:fertility <- fertility %>%
1618260112990:select(`Data Source` ,X63) %>%
1618260113012:filter(!is.na(X63)) %>%
1618260113036:rename(Country = `Data Source`)%>%
1618260113062:rename(Fertility_Rate = X63) %>%
1618260113083:filter(Country != "Country Name") %>%
1618260113105:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income")
1618260113151:fertility
1618260113214:femalepop <- femalepop %>%
1618260113235:select(`Data Source` ,X63) %>%
1618260113253:filter(!is.na(X63)) %>%
1618260113276:rename(Country = `Data Source`)%>%
1618260113298:rename(Population = X63) %>%
1618260113321:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income")
1618260113365:femalepop
1618260113454:# Use this to calculate some summary measures.
1618260113480:summary(fertility$Fertility_Rate)
1618260113555:summary(femalepop$Population)
1618260113633:sqrt(var(fertility$Fertility_Rate))
1618260113661:sqrt(var(femalepop$Population))
1618260113735:# Use this to create some plots.
1618260113813:# Here you can run your lm...
1618260113849:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618260113981:## Maybe create a nice scatterplot with a regression line laid on top.
1618260114091:# Here you can calculate your CIs, run a bootstrap, etc.
1618260114153:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260114242:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618260114336:# Here you can calculate your test stats, critical values, etc.
1618260114376:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260114463:# Here you can calculate your test stats, critical values, etc.
1618260114508:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618260114530:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618260114614:# Here you can calculate your Credible Interval
1618260114711:# Here you can include some relevant visualizations.
1618260183948:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618260183972:library(openintro)
1618260183995:library(tidyverse)
1618260184020:library(dplyr)
1618260184082:fertility <- read_csv("Fertility.csv")
1618260184296:femalepop <- read_csv("FemalePopulation.csv")
1618260184574:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618260184624:# You may need additional chunks, in case you want to include some of the cleaning output.
1618260184664:fertility <- fertility %>%
1618260184682:select(`Data Source` ,X63) %>%
1618260184705:filter(!is.na(X63)) %>%
1618260184728:rename(Country = `Data Source`)%>%
1618260184749:rename(Fertility_Rate = X63) %>%
1618260184773:filter(Country != "Country Name") %>%
1618260184795:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income")
1618260184837:fertility
1618260184907:femalepop <- femalepop %>%
1618260184929:select(`Data Source` ,X63) %>%
1618260184948:filter(!is.na(X63)) %>%
1618260184975:rename(Country = `Data Source`)%>%
1618260184992:rename(Population = X63) %>%
1618260185010:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income")
1618260185049:femalepop
1618260185145:# Use this to calculate some summary measures.
1618260185172:summary(fertility$Fertility_Rate)
1618260185247:summary(femalepop$Population)
1618260185321:sqrt(var(fertility$Fertility_Rate))
1618260185354:sqrt(var(femalepop$Population))
1618260185427:# Use this to create some plots.
1618260185512:# Here you can run your lm...
1618260185557:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618260185703:## Maybe create a nice scatterplot with a regression line laid on top.
1618260185812:# Here you can calculate your CIs, run a bootstrap, etc.
1618260185866:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260185943:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618260186040:# Here you can calculate your test stats, critical values, etc.
1618260186080:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260186184:# Here you can calculate your test stats, critical values, etc.
1618260186223:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618260186246:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618260186339:# Here you can calculate your Credible Interval
1618260186417:# Here you can include some relevant visualizations.
1618260277790:# Use this to calculate some summary measures.
1618260277811:summary(fertility$Fertility_Rate)
1618260277894:summary(femalepop$Population)
1618260277971:sqrt(var(fertility$Fertility_Rate))
1618260278005:sqrt(var(femalepop$Population))
1618260380858:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618260380881:library(openintro)
1618260380902:library(tidyverse)
1618260380927:library(dplyr)
1618260380976:fertility <- read_csv("Fertility.csv")
1618260381184:femalepop <- read_csv("FemalePopulation.csv")
1618260381431:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618260381475:# You may need additional chunks, in case you want to include some of the cleaning output.
1618260381513:fertility <- fertility %>%
1618260381530:select(`Data Source` ,X63) %>%
1618260381546:filter(!is.na(X63)) %>%
1618260381565:rename(Country = `Data Source`)%>%
1618260381585:rename(Fertility_Rate = X63) %>%
1618260381605:filter(Country != "Country Name") %>%
1618260381625:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618260381668:fertility
1618260381739:femalepop <- femalepop %>%
1618260381761:select(`Data Source` ,X63) %>%
1618260381778:filter(!is.na(X63)) %>%
1618260381796:rename(Country = `Data Source`)%>%
1618260381816:rename(Population = X63) %>%
1618260381840:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618260381881:femalepop
1618260381971:# Use this to calculate some summary measures.
1618260381999:summary(fertility$Fertility_Rate)
1618260382089:summary(femalepop$Population)
1618260382186:sqrt(var(fertility$Fertility_Rate))
1618260382220:sqrt(var(femalepop$Population))
1618260382314:# Use this to create some plots.
1618260382394:# Here you can run your lm...
1618260382435:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618260382575:## Maybe create a nice scatterplot with a regression line laid on top.
1618260382692:# Here you can calculate your CIs, run a bootstrap, etc.
1618260382753:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260382828:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618260382929:# Here you can calculate your test stats, critical values, etc.
1618260382973:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618260383064:# Here you can calculate your test stats, critical values, etc.
1618260383108:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618260383131:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618260383213:# Here you can calculate your Credible Interval
1618260383300:# Here you can include some relevant visualizations.
1618262443341:View(fertility)
1618263236581:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618263236607:library(openintro)
1618263236634:library(tidyverse)
1618263236658:library(dplyr)
1618263236706:fertility <- read_csv("Fertility.csv")
1618263236934:femalepop <- read_csv("FemalePopulation.csv")
1618263237227:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618263237275:# You may need additional chunks, in case you want to include some of the cleaning output.
1618263237317:fertility <- fertility %>%
1618263237338:select(`Data Source` ,X63) %>%
1618263237365:filter(!is.na(X63)) %>%
1618263237390:rename(Country = `Data Source`)%>%
1618263237416:rename(Fertility_Rate = X63) %>%
1618263237435:filter(Country != "Country Name") %>%
1618263237459:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618263237506:fertility
1618263237589:femalepop <- femalepop %>%
1618263237610:select(`Data Source` ,X63) %>%
1618263237636:filter(!is.na(X63)) %>%
1618263237655:rename(Country = `Data Source`)%>%
1618263237681:rename(Population = X63) %>%
1618263237708:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618263237751:femalepop
1618263237824:# Use this to calculate some summary measures.
1618263237854:summary(fertility$Fertility_Rate)
1618263237939:summary(femalepop$Population)
1618263238030:sqrt(var(fertility$Fertility_Rate))
1618263238063:sqrt(var(femalepop$Population))
1618263238141:# Use this to create some plots.
1618263238232:# Here you can run your lm...
1618263238281:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618263238418:## Maybe create a nice scatterplot with a regression line laid on top.
1618263238535:# Here you can calculate your CIs, run a bootstrap, etc.
1618263238602:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618263238683:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618263238762:# Here you can calculate your test stats, critical values, etc.
1618263238805:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618263238893:# Here you can calculate your test stats, critical values, etc.
1618263238940:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618263238962:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618263239044:# Here you can calculate your Credible Interval
1618263239126:# Here you can include some relevant visualizations.
1618263748665:# Use this to create some plots.
1618263748721:pop <- (femalepop$Population)
1618263748764:ggplot(data = femalepop,
1618263748785:aes(x = pop)) +
1618263748809:geom_histogram(bins=30,colour="black",
1618263748830:fill = "light blue")+
1618263748853:xlab("Volume of Cars")+
1618263748875:ylab("Number of radar signs")+
1618263748898:ggtitle("Histogram of volume of cars recorded by a radar sign in Toronto in Sept. 2020")
1618263757281:# Use this to create some plots.
1618263757344:pop <- (femalepop$Population)
1618263757386:ggplot(data = femalepop,
1618263757414:aes(x = pop)) +
1618263757435:geom_histogram(bins=10,colour="black",
1618263757462:fill = "light blue")+
1618263757486:xlab("Volume of Cars")+
1618263757506:ylab("Number of radar signs")+
1618263757534:ggtitle("Histogram of volume of cars recorded by a radar sign in Toronto in Sept. 2020")
1618263764288:# Use this to create some plots.
1618263764343:pop <- (femalepop$Population)
1618263764385:ggplot(data = femalepop,
1618263764409:aes(x = pop)) +
1618263764430:geom_histogram(bins=8,colour="black",
1618263764460:fill = "light blue")+
1618263764485:xlab("Volume of Cars")+
1618263764507:ylab("Number of radar signs")+
1618263764529:ggtitle("Histogram of volume of cars recorded by a radar sign in Toronto in Sept. 2020")
1618263774546:# Use this to create some plots.
1618263774603:pop <- (femalepop$Population)
1618263774646:ggplot(data = femalepop,
1618263774670:aes(x = pop)) +
1618263774695:geom_histogram(bins=100,colour="black",
1618263774721:fill = "light blue")+
1618263774757:xlab("Volume of Cars")+
1618263774778:ylab("Number of radar signs")+
1618263774800:ggtitle("Histogram of volume of cars recorded by a radar sign in Toronto in Sept. 2020")
1618263786645:# Use this to create some plots.
1618263786710:pop <- (femalepop$Population)
1618263786748:ggplot(data = femalepop,
1618263786771:aes(x = pop)) +
1618263786811:geom_histogram(bins=50,colour="black",
1618263786849:fill = "light blue")+
1618263786870:xlab("Volume of Cars")+
1618263786890:ylab("Number of radar signs")+
1618263786912:ggtitle("Histogram of volume of cars recorded by a radar sign in Toronto in Sept. 2020")
1618263825121:# Use this to create some plots.
1618263825182:pop <- (femalepop$Population)
1618263825220:ggplot(data = femalepop,
1618263825240:aes(x = pop)) +
1618263825261:geom_histogram(bins=50,colour="black",
1618263825283:fill = "light blue")+
1618263825304:xlab("Population count")+
1618263825325:ylab("Number of countries")+
1618263825346:ggtitle("Histogram of global female population in 2018")
1618263947096:# Use this to create some plots.
1618263947154:pop <- (femalepop$Population)
1618263947192:ggplot(data = femalepop,
1618263947213:aes(x = pop)) +
1618263947237:geom_histogram(bins=50,colour="black",
1618263947260:fill = "light blue")+
1618263947282:xlab("Population")+
1618263947301:ylab("Number of countries")+
1618263947318:scale_x_continuous()+
1618263947335:ggtitle("Histogram of global female population in 2018")
1618263998039:# Use this to create some plots.
1618263998070:options(scipen=999)
1618263998105:pop <- (femalepop$Population)
1618263998147:ggplot(data = femalepop,
1618263998166:aes(x = pop)) +
1618263998186:geom_histogram(bins=50,colour="black",
1618263998205:fill = "light blue")+
1618263998224:xlab("Population")+
1618263998243:ylab("Number of countries")+
1618263998266:scale_x_continuous()+
1618263998285:ggtitle("Histogram of global female population in 2018")
1618264015358:# Use this to create some plots.
1618264015382:options(scipen=999)
1618264015420:pop <- (femalepop$Population)
1618264015457:ggplot(data = femalepop,
1618264015478:aes(x = pop)) +
1618264015499:geom_histogram(bins= 40,colour="black",
1618264015519:fill = "light blue")+
1618264015541:xlab("Population")+
1618264015565:ylab("Number of countries")+
1618264015594:scale_x_continuous()+
1618264015621:ggtitle("Histogram of global female population in 2018")
1618264057215:# Use this to create some plots.
1618264057238:options(scipen=999)
1618264057278:pop <- (femalepop$Population)
1618264057319:ggplot(data = femalepop,
1618264057339:aes(x = pop)) +
1618264057362:geom_histogram(bins= 40,colour="black",
1618264057391:fill = "light blue")+
1618264057423:xlab("Population")+
1618264057447:ylab("Number of countries")+
1618264057475:scale_x_continuous()+
1618264057501:theme_classic()
1618264057800:ggtitle("Histogram of global female population in 2018")
1618264067980:# Use this to create some plots.
1618264068001:options(scipen=999)
1618264068039:pop <- (femalepop$Population)
1618264068081:ggplot(data = femalepop,
1618264068105:aes(x = pop)) +
1618264068127:geom_histogram(bins= 40,colour="black",
1618264068150:fill = "light blue")+
1618264068176:xlab("Population")+
1618264068198:ylab("Number of countries")+
1618264068225:scale_x_continuous()+
1618264068251:theme_classic()+
1618264068274:ggtitle("Histogram of global female population in 2018")
1618264176387:options(scipen=999)
1618264176435:fert <- (fertility$Fertility_Rate)
1618264176481:ggplot(data = fertility,
1618264176506:aes(x = fert)) +
1618264176525:geom_histogram(bins= 40,colour="black",
1618264176544:fill = "light blue")+
1618264176563:xlab("Population")+
1618264176582:ylab("Number of countries")+
1618264176603:scale_x_continuous()+
1618264176627:theme_classic()+
1618264176649:ggtitle("Histogram of global female population in 2018")
1618264183458:options(scipen=999)
1618264183500:fert <- (fertility$Fertility_Rate)
1618264183538:ggplot(data = fertility,
1618264183561:aes(x = fert)) +
1618264183587:geom_histogram(bins= 20,colour="black",
1618264183605:fill = "light blue")+
1618264183624:xlab("Population")+
1618264183648:ylab("Number of countries")+
1618264183670:scale_x_continuous()+
1618264183691:theme_classic()+
1618264183715:ggtitle("Histogram of global female population in 2018")
1618264219743:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618264219767:library(openintro)
1618264219790:library(tidyverse)
1618264219812:library(dplyr)
1618264219864:fertility <- read_csv("Fertility.csv")
1618264220074:femalepop <- read_csv("FemalePopulation.csv")
1618264220353:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618264220400:# You may need additional chunks, in case you want to include some of the cleaning output.
1618264220438:fertility <- fertility %>%
1618264220460:select(`Data Source` ,X63) %>%
1618264220482:filter(!is.na(X63)) %>%
1618264220503:rename(Country = `Data Source`)%>%
1618264220528:rename(Fertility_Rate = X63) %>%
1618264220551:filter(Country != "Country Name") %>%
1618264220570:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618264220628:fertility
1618264220691:femalepop <- femalepop %>%
1618264220719:select(`Data Source` ,X63) %>%
1618264220738:filter(!is.na(X63)) %>%
1618264220758:rename(Country = `Data Source`)%>%
1618264220778:rename(Population = X63) %>%
1618264220799:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618264220838:femalepop
1618264220918:# Use this to calculate some summary measures.
1618264220946:summary(fertility$Fertility_Rate)
1618264221024:summary(femalepop$Population)
1618264221102:sqrt(var(fertility$Fertility_Rate))
1618264221138:sqrt(var(femalepop$Population))
1618264221226:# Use this to create some plots.
1618264221253:options(scipen=999)
1618264221296:pop <- (femalepop$Population)
1618264221341:ggplot(data = femalepop,
1618264221363:aes(x = pop)) +
1618264221381:geom_histogram(bins= 40,colour="black",
1618264221402:fill = "light blue")+
1618264221424:xlab("Population")+
1618264221448:ylab("Number of countries")+
1618264221473:scale_x_continuous()+
1618264221497:theme_classic()+
1618264221523:ggtitle("Histogram of global female population in 2018")
1618264221918:options(scipen=999)
1618264221965:fert <- (fertility$Fertility_Rate)
1618264222012:ggplot(data = fertility,
1618264222034:aes(x = fert)) +
1618264222056:geom_histogram(bins= 20,colour="black",
1618264222077:fill = "light blue")+
1618264222099:xlab("Fertility rate")+
1618264222116:ylab("Number of countries")+
1618264222140:scale_x_continuous()+
1618264222163:theme_classic()+
1618264222187:ggtitle("Histogram of global fertility rates in 2018")
1618264222524:# Here you can run your lm...
1618264222575:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618264222757:## Maybe create a nice scatterplot with a regression line laid on top.
1618264222873:# Here you can calculate your CIs, run a bootstrap, etc.
1618264222945:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618264223031:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618264223144:# Here you can calculate your test stats, critical values, etc.
1618264223198:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618264223282:# Here you can calculate your test stats, critical values, etc.
1618264223327:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618264223352:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618264223438:# Here you can calculate your Credible Interval
1618264223528:# Here you can include some relevant visualizations.
1618580657169:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618580657219:library(openintro)
1618580657327:library(tidyverse)
1618580657352:library(dplyr)
1618580657515:fertility <- read_csv("Fertility.csv")
1618580657992:femalepop <- read_csv("FemalePopulation.csv")
1618580658390:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618580658438:# You may need additional chunks, in case you want to include some of the cleaning output.
1618580658478:fertility <- fertility %>%
1618580658498:select(`Data Source` ,X63) %>%
1618580658519:filter(!is.na(X63)) %>%
1618580658539:rename(Country = `Data Source`)%>%
1618580658560:rename(Fertility_Rate = X63) %>%
1618580658582:filter(Country != "Country Name") %>%
1618580658604:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618580658661:fertility
1618580658731:femalepop <- femalepop %>%
1618580658752:select(`Data Source` ,X63) %>%
1618580658792:filter(!is.na(X63)) %>%
1618580658811:rename(Country = `Data Source`)%>%
1618580658834:rename(Population = X63) %>%
1618580658854:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618580658898:femalepop
1618580658975:# Use this to calculate some summary measures.
1618580659004:summary(fertility$Fertility_Rate)
1618580659098:summary(femalepop$Population)
1618580659183:sqrt(var(fertility$Fertility_Rate))
1618580659219:sqrt(var(femalepop$Population))
1618580659302:# Use this to create some plots.
1618580659333:options(scipen=999)
1618580659377:pop <- (femalepop$Population)
1618580659422:ggplot(data = femalepop,
1618580659447:aes(x = pop)) +
1618580659473:geom_histogram(bins= 40,colour="black",
1618580659492:fill = "light blue")+
1618580659511:xlab("Population")+
1618580659528:ylab("Number of countries")+
1618580659546:scale_x_continuous()+
1618580659563:theme_classic()+
1618580659583:ggtitle("Histogram of global female population in 2018")
1618580660077:options(scipen=999)
1618580660121:fert <- (fertility$Fertility_Rate)
1618580660158:ggplot(data = fertility,
1618580660180:aes(x = fert)) +
1618580660202:geom_histogram(bins= 20,colour="black",
1618580660225:fill = "light blue")+
1618580660248:xlab("Fertility rate")+
1618580660267:ylab("Number of countries")+
1618580660286:scale_x_continuous()+
1618580660309:theme_classic()+
1618580660332:ggtitle("Histogram of global fertility rates in 2018")
1618580660850:# Here you can run your lm...
1618580660896:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618580661042:## Maybe create a nice scatterplot with a regression line laid on top.
1618580661158:# Here you can calculate your CIs, run a bootstrap, etc.
1618580661226:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618580661318:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618580661398:# Here you can calculate your test stats, critical values, etc.
1618580661440:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618580661533:# Here you can calculate your test stats, critical values, etc.
1618580661581:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618580661603:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618580661681:# Here you can calculate your Credible Interval
1618580661763:# Here you can include some relevant visualizations.
1618581121144:# Use this to create some plots.
1618581121165:options(scipen=999)
1618581121202:pop <- (femalepop$Population)
1618581121239:ggplot(data = femalepop,
1618581121264:aes(x = pop)) +
1618581121283:geom_histogram(bins= 20,colour="black",
1618581121308:fill = "light blue")+
1618581121329:xlab("Population")+
1618581121355:ylab("Number of countries")+
1618581121376:scale_x_continuous()+
1618581121394:theme_classic()+
1618581121418:ggtitle("Histogram of global female population in 2018")
1618581132860:# Use this to create some plots.
1618581132885:options(scipen=999)
1618581132924:pop <- (femalepop$Population)
1618581132958:ggplot(data = femalepop,
1618581132989:aes(x = pop)) +
1618581133009:geom_histogram(bins= 15,colour="black",
1618581133027:fill = "light blue")+
1618581133048:xlab("Population")+
1618581133071:ylab("Number of countries")+
1618581133091:scale_x_continuous()+
1618581133109:theme_classic()+
1618581133130:ggtitle("Histogram of global female population in 2018")
1618581149612:# Use this to create some plots.
1618581149634:options(scipen=999)
1618581149690:pop <- (femalepop$Population)
1618581149724:ggplot(data = femalepop,
1618581149749:aes(x = pop)) +
1618581149771:geom_histogram(bins= 25,colour="black",
1618581149791:fill = "light blue")+
1618581149813:xlab("Population")+
1618581149835:ylab("Number of countries")+
1618581149857:scale_x_continuous()+
1618581149882:theme_classic()+
1618581149903:ggtitle("Histogram of global female population in 2018")
1618583565184:# Here you can run your lm...
1618583565220:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583565269:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583565295:total
1618583565365:#lm( ~ Population, data = data)
1618583568455:View(total)
1618583578572:View(total)
1618583636602:# Here you can run your lm...
1618583636639:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583636692:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583636719:total
1618583636778:lm(fertility.Fertility_Rate ~ femalepop.Population, data = total)
1618583643733:# Here you can run your lm...
1618583643772:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583643832:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583643856:total
1618583643929:lm(fertility.Fertility_Rate ~ femalepop.Population, data = total)
1618583651761:# Here you can run your lm...
1618583651796:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583651854:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583651891:lm(fertility.Fertility_Rate ~ femalepop.Population, data = total)
1618583659312:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618583659350:library(openintro)
1618583659369:library(opendatatoronto)
1618583669704:install.packages(c("opendatatoronto", "patchwork"))
1618583678758:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618583678804:library(openintro)
1618583679044:library(opendatatoronto)
1618583679081:library(dplyr)
1618583679102:library(patchwork)
1618583679161:library(tidyverse)
1618583679210:set.seed(899)
1618583679237:mse1 = numeric(10)
1618583679266:mse2 = numeric(10)
1618583679310:for(i in 1:100){
1618583679331:sigma_sq = i
1618583679356:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583679390:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583679427:n <- 100
1618583679450:M <- 1000
1618583679513:sim <- list(
1618583679540:T1 = numeric(M),
1618583679567:T2 = numeric(M)
1618583679589:)
1618583679613:for (j in 1:M) {
1618583679637:# Sample from Normal
1618583679659:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583679679:# Record the values of the two estimators:
1618583679699:sim$T1[j] <- T1(thesample)
1618583679717:sim$T2[j] <- T2(thesample)
1618583679745:}
1618583679783:#MSE
1618583679806:MSE_T1 <- var(sim$T1) + (mean(sim$T1) - sigma_sq)^2
1618583679828:MSE_T2 <- var(sim$T2) + (mean(sim$T2) - sigma_sq)^2
1618583679869:mse1[i] = MSE_T1
1618583679891:mse2[i] = MSE_T2
1618583679914:}
1618583683007:## Create your plots below. (I recommend using ggplot)
1618583683059:leftplot <- tibble(T1 = mse1) %>%
1618583683080:ggplot(aes(x = T1)) +
1618583683099:theme_classic() +
1618583683119:ggtitle("Histogram of MSE for multiple sigma squared values")+
1618583683140:theme(plot.title = element_text(size=8))+
1618583683160:xlab("MSE of estimator T1")+
1618583683180:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583683518:rightplot <- tibble(T2 = mse2) %>%
1618583683539:ggplot(aes(x = T2)) +
1618583683562:theme_classic() +
1618583683582:ggtitle("Histogram of MSE for multiple sigma squared values")+
1618583683601:theme(plot.title = element_text(size=8))+
1618583683620:xlab("MSE of estimator T2")+
1618583683638:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583683953:leftplot | rightplot
1618583684393:set.seed(899)
1618583684416:bias1 = numeric(10)
1618583684437:bias2 = numeric(10)
1618583684478:for(a in 1:100){
1618583684501:sigma_sq = a
1618583684524:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583684542:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583684571:n <- 100
1618583684592:M <- 1000
1618583684646:sim <- list(
1618583684667:T1 = numeric(M),
1618583684687:T2 = numeric(M)
1618583684709:)
1618583684734:for (b in 1:M) {
1618583684754:# Sample from Normal
1618583684773:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583684799:# Record the values of the two estimators:
1618583684826:sim$T1[b] <- T1(thesample)
1618583684844:sim$T2[b] <- T2(thesample)
1618583684861:}
1618583684896:#Bias
1618583684929:Bias_T1 <- mean(sim$T1) - sigma_sq
1618583684949:Bias_T2 <- mean(sim$T2) - sigma_sq
1618583684983:bias1[a] = Bias_T1
1618583685001:bias2[a] = Bias_T2
1618583685020:}
1618583687796:leftplotbias <- tibble(T1 = bias1) %>%
1618583687821:ggplot(aes(x = bias1)) +
1618583687842:theme_classic() +
1618583687865:ggtitle("Histogram of bias for multiple sigma squared values")+
1618583687894:theme(plot.title = element_text(size=8))+
1618583687916:xlab("Bias of estimator T1")+
1618583687940:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583688274:rightplotbias <- tibble(T2 = bias2) %>%
1618583688293:ggplot(aes(x = bias2)) +
1618583688313:theme_classic() +
1618583688332:ggtitle("Histogram of bias for multiple sigma squared values")+
1618583688357:theme(plot.title = element_text(size=8))+
1618583688378:xlab("Bias of estimator T2")+
1618583688400:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583688725:leftplotbias | rightplotbias
1618583689122:set.seed(899)
1618583689147:var1 = numeric(10)
1618583689168:var2 = numeric(10)
1618583689208:for(c in 1:100){
1618583689228:sigma_sq = c
1618583689247:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583689264:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583689307:n <- 100
1618583689324:M <- 1000
1618583689375:sim <- list(
1618583689395:T1 = numeric(M),
1618583689417:T2 = numeric(M)
1618583689436:)
1618583689457:for (d in 1:M) {
1618583689476:# Sample from Normal
1618583689495:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583689515:# Record the values of the two estimators:
1618583689535:sim$T1[d] <- T1(thesample)
1618583689555:sim$T2[d] <- T2(thesample)
1618583689581:}
1618583689619:#Bias
1618583689654:Var_T1 <- var(sim$T1)
1618583689673:Var_T2 <- var(sim$T2)
1618583689711:var1[c] = Var_T1
1618583689732:var2[c] = Var_T2
1618583689751:}
1618583692508:leftplotvar <- tibble(T1 = var1) %>%
1618583692538:ggplot(aes(x = var1)) +
1618583692559:theme_classic() +
1618583692580:xlab("Variance of estimator T1")+
1618583692602:ggtitle("Histogram of variance for multiple sigma squared values")+
1618583692625:theme(plot.title = element_text(size=7))+
1618583692646:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583692950:rightplotvar <- tibble(T2 = var2) %>%
1618583692972:ggplot(aes(x = var2)) +
1618583692994:theme_classic() +
1618583693016:ggtitle("Histogram of variance for multiple sigma squared values")+
1618583693039:theme(plot.title = element_text(size=7))+
1618583693059:xlab("Variance of estimator T2")+
1618583693080:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583693434:leftplotvar | rightplotvar
1618583693837:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618583693882:# You may need additional chunks.
1618583693930:# I would recommend not including any of the Cleaning process output here.
1618583693969:# get package
1618583693992:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583694613:package
1618583694672:# get all resources for this package
1618583694691:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583694848:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1618583694866:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1618583694914:# load the first datastore resource as a sample
1618583694935:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1618583696990:data
1618583697248:data %>%
1618583697272:ggplot(aes(x = Population, y=AutoTheft_AVG))+
1618583697293:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618583697316:theme(plot.title = element_text(size=12))+
1618583697334:geom_point(col = "blue")
1618583709458:# Here you can run a linear regression on your two variables of interest.
1618583709494:lm(AutoTheft_AVG ~ Population, data = data)
1618583714324:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618583714363:library(openintro)
1618583714385:library(opendatatoronto)
1618583714405:library(dplyr)
1618583714431:library(patchwork)
1618583714452:library(tidyverse)
1618583714497:set.seed(899)
1618583714526:mse1 = numeric(10)
1618583714552:mse2 = numeric(10)
1618583714592:for(i in 1:100){
1618583714614:sigma_sq = i
1618583714635:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583714656:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583714690:n <- 100
1618583714715:M <- 1000
1618583714774:sim <- list(
1618583714796:T1 = numeric(M),
1618583714817:T2 = numeric(M)
1618583714837:)
1618583714857:for (j in 1:M) {
1618583714881:# Sample from Normal
1618583714905:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583714926:# Record the values of the two estimators:
1618583714948:sim$T1[j] <- T1(thesample)
1618583714971:sim$T2[j] <- T2(thesample)
1618583715004:}
1618583715039:#MSE
1618583715323:MSE_T1 <- var(sim$T1) + (mean(sim$T1) - sigma_sq)^2
1618583715346:MSE_T2 <- var(sim$T2) + (mean(sim$T2) - sigma_sq)^2
1618583715379:mse1[i] = MSE_T1
1618583715398:mse2[i] = MSE_T2
1618583715421:}
1618583718239:## Create your plots below. (I recommend using ggplot)
1618583718280:leftplot <- tibble(T1 = mse1) %>%
1618583718302:ggplot(aes(x = T1)) +
1618583718323:theme_classic() +
1618583718343:ggtitle("Histogram of MSE for multiple sigma squared values")+
1618583718366:theme(plot.title = element_text(size=8))+
1618583718391:xlab("MSE of estimator T1")+
1618583718413:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583718745:rightplot <- tibble(T2 = mse2) %>%
1618583718768:ggplot(aes(x = T2)) +
1618583718789:theme_classic() +
1618583718809:ggtitle("Histogram of MSE for multiple sigma squared values")+
1618583718829:theme(plot.title = element_text(size=8))+
1618583718861:xlab("MSE of estimator T2")+
1618583718881:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583719207:leftplot | rightplot
1618583719636:set.seed(899)
1618583719670:bias1 = numeric(10)
1618583719695:bias2 = numeric(10)
1618583719733:for(a in 1:100){
1618583719756:sigma_sq = a
1618583719781:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583719803:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583719839:n <- 100
1618583719863:M <- 1000
1618583719919:sim <- list(
1618583719942:T1 = numeric(M),
1618583719964:T2 = numeric(M)
1618583719986:)
1618583720011:for (b in 1:M) {
1618583720032:# Sample from Normal
1618583720054:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583720083:# Record the values of the two estimators:
1618583720105:sim$T1[b] <- T1(thesample)
1618583720126:sim$T2[b] <- T2(thesample)
1618583720149:}
1618583720196:#Bias
1618583720232:Bias_T1 <- mean(sim$T1) - sigma_sq
1618583720252:Bias_T2 <- mean(sim$T2) - sigma_sq
1618583720289:bias1[a] = Bias_T1
1618583720307:bias2[a] = Bias_T2
1618583720327:}
1618583723227:leftplotbias <- tibble(T1 = bias1) %>%
1618583723255:ggplot(aes(x = bias1)) +
1618583723278:theme_classic() +
1618583723301:ggtitle("Histogram of bias for multiple sigma squared values")+
1618583723324:theme(plot.title = element_text(size=8))+
1618583723344:xlab("Bias of estimator T1")+
1618583723365:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583723716:rightplotbias <- tibble(T2 = bias2) %>%
1618583723740:ggplot(aes(x = bias2)) +
1618583723769:theme_classic() +
1618583723792:ggtitle("Histogram of bias for multiple sigma squared values")+
1618583723816:theme(plot.title = element_text(size=8))+
1618583723844:xlab("Bias of estimator T2")+
1618583723868:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583724204:leftplotbias | rightplotbias
1618583724591:set.seed(899)
1618583724619:var1 = numeric(10)
1618583724646:var2 = numeric(10)
1618583724686:for(c in 1:100){
1618583724706:sigma_sq = c
1618583724725:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1618583724748:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1618583724788:n <- 100
1618583724812:M <- 1000
1618583724872:sim <- list(
1618583724898:T1 = numeric(M),
1618583724918:T2 = numeric(M)
1618583724940:)
1618583724962:for (d in 1:M) {
1618583724984:# Sample from Normal
1618583725018:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1618583725042:# Record the values of the two estimators:
1618583725067:sim$T1[d] <- T1(thesample)
1618583725097:sim$T2[d] <- T2(thesample)
1618583725121:}
1618583725160:#Bias
1618583725196:Var_T1 <- var(sim$T1)
1618583725218:Var_T2 <- var(sim$T2)
1618583725263:var1[c] = Var_T1
1618583725285:var2[c] = Var_T2
1618583725308:}
1618583727969:leftplotvar <- tibble(T1 = var1) %>%
1618583727996:ggplot(aes(x = var1)) +
1618583728017:theme_classic() +
1618583728039:xlab("Variance of estimator T1")+
1618583728059:ggtitle("Histogram of variance for multiple sigma squared values")+
1618583728076:theme(plot.title = element_text(size=7))+
1618583728094:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583728416:rightplotvar <- tibble(T2 = var2) %>%
1618583728435:ggplot(aes(x = var2)) +
1618583728457:theme_classic() +
1618583728479:ggtitle("Histogram of variance for multiple sigma squared values")+
1618583728501:theme(plot.title = element_text(size=7))+
1618583728520:xlab("Variance of estimator T2")+
1618583728541:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1618583728862:leftplotvar | rightplotvar
1618583729292:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618583729342:# You may need additional chunks.
1618583729376:# I would recommend not including any of the Cleaning process output here.
1618583729411:# get package
1618583729438:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583729536:package
1618583729606:# get all resources for this package
1618583729624:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583729703:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1618583729722:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1618583729766:# load the first datastore resource as a sample
1618583729789:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1618583731217:data
1618583731474:data %>%
1618583731501:ggplot(aes(x = Population, y=AutoTheft_AVG))+
1618583731524:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618583731554:theme(plot.title = element_text(size=12))+
1618583731576:geom_point(col = "blue")
1618583741996:# Here you can run a linear regression on your two variables of interest.
1618583742033:lm(AutoTheft_AVG ~ Population, data = data)
1618583752042:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618583752083:library(openintro)
1618583752102:library(opendatatoronto)
1618583752122:library(dplyr)
1618583752146:library(patchwork)
1618583752167:library(tidyverse)
1618583768807:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618583768846:# You may need additional chunks.
1618583768884:# I would recommend not including any of the Cleaning process output here.
1618583768918:# get package
1618583768946:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583769043:package
1618583769101:# get all resources for this package
1618583769119:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1618583769196:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1618583769215:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1618583769265:# load the first datastore resource as a sample
1618583769292:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1618583770711:data
1618583773638:data %>%
1618583773672:ggplot(aes(x = Population, y=AutoTheft_AVG))+
1618583773691:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618583773714:theme(plot.title = element_text(size=12))+
1618583773733:geom_point(col = "blue")
1618583788588:# Here you can run a linear regression on your two variables of interest.
1618583788624:lm(AutoTheft_AVG ~ Population, data = data)
1618583803552:# Here you can run your lm...
1618583803587:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583803651:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583803690:lm(fertility.Fertility_Rate ~ femalepop.Population, data = total)
1618583845678:# Here you can run your lm...
1618583845717:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583845773:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583845821:linearmodel<-lm(fertility.Fertility_Rate ~ femalepop.Population, data = total)
1618583845909:summary(linearmodel)
1618583887956:# Here you can run your lm...
1618583887993:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583888047:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583888092:linearmodel<-lm(femalepop.Population ~fertility.Fertility_Rate , data = total)
1618583888167:summary(linearmodel)
1618583924446:# Here you can run your lm...
1618583924479:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618583924545:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618583924602:linearmodel<-lm(fertility.Fertility_Rate  ~femalepop.Population , data = total)
1618583924683:summary(linearmodel)
1618584040005:# Here you can run your lm...
1618584040049:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584040106:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584040151:linearmodel<-lm(fertility.Fertility_Rate  ~femalepop.Population , data = total)
1618584040226:summary(linearmodel)
1618584040624:total %>%
1618584040648:ggplot(aes(x = femalepop.Population, y=fertility.Fertility_Rate))+
1618584040667:geom_point(col = "blue")+
1618584040687:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618584040706:theme(plot.title = element_text(size=12))
1618584040879:#geom_abline(slope = 0.001457, intercept = -0.598671, col="red")
1618584080565:# Here you can run your lm...
1618584080604:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584080661:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584080708:linearmodel<-lm(fertility.Fertility_Rate  ~femalepop.Population , data = total)
1618584080776:summary(linearmodel)
1618584081194:total %>%
1618584081218:ggplot(aes(x =fertility.Fertility_Rate , y=femalepop.Population))+
1618584081240:geom_point(col = "blue")+
1618584081259:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618584081279:theme(plot.title = element_text(size=12))
1618584081412:#geom_abline(slope = 0.001457, intercept = -0.598671, col="red")
1618584180487:# Here you can run your lm...
1618584180526:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584180591:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584180638:lm(fertility.Fertility_Rate  ~femalepop.Population , data = total)
1618584180719:linearmodel
1618584180813:total %>%
1618584180836:ggplot(aes(x =fertility.Fertility_Rate , y=femalepop.Population))+
1618584180865:geom_point(col = "blue")+
1618584180886:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618584180911:theme(plot.title = element_text(size=12))
1618584181054:#geom_abline(slope = 0.001457, intercept = -0.598671, col="red")
1618584246676:# Here you can run your lm...
1618584246722:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584246778:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584246819:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584246896:linearmodel
1618584246990:total %>%
1618584247009:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584247027:geom_point(col = "blue")+
1618584247057:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618584247079:theme(plot.title = element_text(size=12))
1618584247218:#geom_abline(slope = 0.001457, intercept = -0.598671, col="red")
1618584273495:# Here you can run your lm...
1618584273533:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584273591:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584273628:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584273702:linearmodel
1618584273790:total %>%
1618584273811:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584273833:geom_point(col = "blue")+
1618584273857:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1618584273880:theme(plot.title = element_text(size=12))+
1618584273906:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618584342974:# Here you can run your lm...
1618584343010:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584343074:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584343121:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584343216:linearmodel
1618584343308:total %>%
1618584343330:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584343355:geom_point(col = "blue")+
1618584343378:ggtitle("Scatterplot of Population given Fertility")+
1618584343403:theme(plot.title = element_text(size=12))+
1618584343428:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618584366787:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618584366807:library(openintro)
1618584366831:library(tidyverse)
1618584366866:library(dplyr)
1618584366922:fertility <- read_csv("Fertility.csv")
1618584367157:femalepop <- read_csv("FemalePopulation.csv")
1618584367436:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618584367480:# You may need additional chunks, in case you want to include some of the cleaning output.
1618584367521:fertility <- fertility %>%
1618584367549:select(`Data Source` ,X63) %>%
1618584367567:filter(!is.na(X63)) %>%
1618584367585:rename(Country = `Data Source`)%>%
1618584367606:rename(Fertility_Rate = X63) %>%
1618584367626:filter(Country != "Country Name") %>%
1618584367650:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618584367692:fertility
1618584367770:femalepop <- femalepop %>%
1618584367792:select(`Data Source` ,X63) %>%
1618584367815:filter(!is.na(X63)) %>%
1618584367840:rename(Country = `Data Source`)%>%
1618584367863:rename(Population = X63) %>%
1618584367888:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618584367928:femalepop
1618584368015:# Use this to calculate some summary measures.
1618584368045:summary(fertility$Fertility_Rate)
1618584368123:summary(femalepop$Population)
1618584368208:sqrt(var(fertility$Fertility_Rate))
1618584368255:sqrt(var(femalepop$Population))
1618584368340:# Use this to create some plots.
1618584368375:options(scipen=999)
1618584368416:pop <- (femalepop$Population)
1618584368455:ggplot(data = femalepop,
1618584368475:aes(x = pop)) +
1618584368500:geom_histogram(bins= 25,colour="black",
1618584368519:fill = "light blue")+
1618584368539:xlab("Population")+
1618584368562:ylab("Number of countries")+
1618584368584:scale_x_continuous()+
1618584368603:theme_classic()+
1618584368623:ggtitle("Histogram of global female population in 2018")
1618584368943:options(scipen=999)
1618584368986:fert <- (fertility$Fertility_Rate)
1618584369024:ggplot(data = fertility,
1618584369046:aes(x = fert)) +
1618584369069:geom_histogram(bins= 20,colour="black",
1618584369091:fill = "light blue")+
1618584369113:xlab("Fertility rate")+
1618584369135:ylab("Number of countries")+
1618584369157:scale_x_continuous()+
1618584369191:theme_classic()+
1618584369217:ggtitle("Histogram of global fertility rates in 2018")
1618584369897:# Here you can run your lm...
1618584369942:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584369999:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584370043:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584370142:linearmodel
1618584370250:total %>%
1618584370273:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584370298:geom_point(col = "blue")+
1618584370323:ggtitle("Scatterplot of population given fertility")
1618584370454:theme(plot.title = element_text(size=12))+
1618584370486:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618584383466:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618584383492:library(openintro)
1618584383517:library(tidyverse)
1618584383539:library(dplyr)
1618584383594:fertility <- read_csv("Fertility.csv")
1618584383816:femalepop <- read_csv("FemalePopulation.csv")
1618584384065:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618584384112:# You may need additional chunks, in case you want to include some of the cleaning output.
1618584384148:fertility <- fertility %>%
1618584384169:select(`Data Source` ,X63) %>%
1618584384190:filter(!is.na(X63)) %>%
1618584384212:rename(Country = `Data Source`)%>%
1618584384233:rename(Fertility_Rate = X63) %>%
1618584384253:filter(Country != "Country Name") %>%
1618584384273:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618584384314:fertility
1618584384382:femalepop <- femalepop %>%
1618584384402:select(`Data Source` ,X63) %>%
1618584384421:filter(!is.na(X63)) %>%
1618584384441:rename(Country = `Data Source`)%>%
1618584384464:rename(Population = X63) %>%
1618584384485:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618584384524:femalepop
1618584384602:# Use this to calculate some summary measures.
1618584384628:summary(fertility$Fertility_Rate)
1618584384720:summary(femalepop$Population)
1618584384813:sqrt(var(fertility$Fertility_Rate))
1618584384849:sqrt(var(femalepop$Population))
1618584384940:# Use this to create some plots.
1618584384965:options(scipen=999)
1618584385007:pop <- (femalepop$Population)
1618584385045:ggplot(data = femalepop,
1618584385063:aes(x = pop)) +
1618584385083:geom_histogram(bins= 25,colour="black",
1618584385101:fill = "light blue")+
1618584385121:xlab("Population")+
1618584385146:ylab("Number of countries")+
1618584385166:scale_x_continuous()+
1618584385189:theme_classic()+
1618584385208:ggtitle("Histogram of global female population in 2018")
1618584385559:options(scipen=999)
1618584385618:fert <- (fertility$Fertility_Rate)
1618584385653:ggplot(data = fertility,
1618584385676:aes(x = fert)) +
1618584385706:geom_histogram(bins= 20,colour="black",
1618584385732:fill = "light blue")+
1618584385757:xlab("Fertility rate")+
1618584385780:ylab("Number of countries")+
1618584385805:scale_x_continuous()+
1618584385827:theme_classic()+
1618584385850:ggtitle("Histogram of global fertility rates in 2018")
1618584386189:# Here you can run your lm...
1618584386232:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584386288:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584386332:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584386419:linearmodel
1618584386529:total %>%
1618584386552:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584386579:geom_point(col = "blue")+
1618584386602:ggtitle("Scatterplot of population given fertility")+
1618584386630:theme(plot.title = element_text(size=12))+
1618584386658:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618584386974:## Maybe create a nice scatterplot with a regression line laid on top.
1618584387100:# Here you can calculate your CIs, run a bootstrap, etc.
1618584387172:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618584387257:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618584387350:# Here you can calculate your test stats, critical values, etc.
1618584387398:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618584387484:# Here you can calculate your test stats, critical values, etc.
1618584387532:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618584387556:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618584387649:# Here you can calculate your Credible Interval
1618584387750:# Here you can include some relevant visualizations.
1618584776796:# Here you can run your lm...
1618584776833:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584776868:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584776907:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584776990:linearmodel
1618584777079:total %>%
1618584777098:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584777121:geom_point(col = "blue")+
1618584777145:ggtitle("Scatterplot of population given fertility")+
1618584777166:theme(plot.title = element_text(size=12))+
1618584777187:xlab("Fertility Rate")+
1618584777208:ylab("Female Population")+
1618584777228:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618584791318:# Here you can run your lm...
1618584791349:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618584791385:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618584791426:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618584791508:linearmodel
1618584791591:total %>%
1618584791613:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618584791631:geom_point(col = "blue")+
1618584791650:ggtitle("Scatterplot of population given fertility")+
1618584791670:theme(plot.title = element_text(size=12))+
1618584791688:xlab("Fertility Rate")+
1618584791709:ylab("Female Population")+
1618584791728:theme_classic()+
1618584791748:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618590311589:pt(8.557, df=96)
1618590326190:pt(8.557, df=96, lower.tail = FALSE)
1618590341702:pt(8.557, df=96, lower.tail = TRUE)
1618590564416:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618590564441:library(openintro)
1618590564461:library(tidyverse)
1618590564480:library(dplyr)
1618590564529:fertility <- read_csv("Fertility.csv")
1618590564740:femalepop <- read_csv("FemalePopulation.csv")
1618590564999:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618590565049:# You may need additional chunks, in case you want to include some of the cleaning output.
1618590565095:fertility <- fertility %>%
1618590565126:select(`Data Source` ,X63) %>%
1618590565146:filter(!is.na(X63)) %>%
1618590565165:rename(Country = `Data Source`)%>%
1618590565184:rename(Fertility_Rate = X63) %>%
1618590565205:filter(Country != "Country Name") %>%
1618590565229:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618590565273:fertility
1618590565346:femalepop <- femalepop %>%
1618590565372:select(`Data Source` ,X63) %>%
1618590565393:filter(!is.na(X63)) %>%
1618590565412:rename(Country = `Data Source`)%>%
1618590565434:rename(Population = X63) %>%
1618590565455:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618590565501:femalepop
1618590565610:# Use this to calculate some summary measures.
1618590565638:summary(fertility$Fertility_Rate)
1618590565728:summary(femalepop$Population)
1618590565810:sqrt(var(fertility$Fertility_Rate))
1618590565848:sqrt(var(femalepop$Population))
1618590565938:# Use this to create some plots.
1618590565978:options(scipen=999)
1618590566029:pop <- (femalepop$Population)
1618590566074:ggplot(data = femalepop,
1618590566095:aes(x = pop)) +
1618590566124:geom_histogram(bins= 25,colour="black",
1618590566145:fill = "light blue")+
1618590566163:xlab("Population")+
1618590566185:ylab("Number of countries")+
1618590566206:scale_x_continuous()+
1618590566227:theme_classic()+
1618590566247:ggtitle("Histogram of global female population in 2018")
1618590566581:options(scipen=999)
1618590566629:fert <- (fertility$Fertility_Rate)
1618590566671:ggplot(data = fertility,
1618590566692:aes(x = fert)) +
1618590566716:geom_histogram(bins= 20,colour="black",
1618590566746:fill = "light blue")+
1618590566773:xlab("Fertility rate")+
1618590566799:ylab("Number of countries")+
1618590566818:scale_x_continuous()+
1618590566842:theme_classic()+
1618590566862:ggtitle("Histogram of global fertility rates in 2018")
1618590567158:# Here you can run your lm...
1618590567198:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618590567241:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618590567288:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618590567371:linearmodel
1618590567467:total %>%
1618590567489:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618590567510:geom_point(col = "blue")+
1618590567533:ggtitle("Scatterplot of population given fertility")+
1618590567552:theme(plot.title = element_text(size=12))+
1618590567585:xlab("Fertility Rate")+
1618590567606:ylab("Female Population")+
1618590567628:theme_classic()+
1618590567648:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618590567975:## Maybe create a nice scatterplot with a regression line laid on top.
1618590568083:# Here you can calculate your CIs, run a bootstrap, etc.
1618590568135:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618590568229:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618590568328:# Here you can calculate your test stats, critical values, etc.
1618590568371:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618590568450:# Here you can calculate your test stats, critical values, etc.
1618590568497:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618590568516:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618590568592:# Here you can calculate your Credible Interval
1618590568685:# Here you can include some relevant visualizations.
1618603164825:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618603164862:library(openintro)
1618603164954:library(tidyverse)
1618603164975:library(dplyr)
1618603165133:fertility <- read_csv("Fertility.csv")
1618603165528:femalepop <- read_csv("FemalePopulation.csv")
1618603165829:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618603165870:# You may need additional chunks, in case you want to include some of the cleaning output.
1618603165906:fertility <- fertility %>%
1618603165924:select(`Data Source` ,X63) %>%
1618603165974:filter(!is.na(X63)) %>%
1618603165996:rename(Country = `Data Source`)%>%
1618603166018:rename(Fertility_Rate = X63) %>%
1618603166040:filter(Country != "Country Name") %>%
1618603166059:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618603166115:fertility
1618603166172:femalepop <- femalepop %>%
1618603166192:select(`Data Source` ,X63) %>%
1618603166212:filter(!is.na(X63)) %>%
1618603166231:rename(Country = `Data Source`)%>%
1618603166247:rename(Population = X63) %>%
1618603166265:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618603166301:femalepop
1618603166373:# Use this to calculate some summary measures.
1618603166409:summary(fertility$Fertility_Rate)
1618603166480:summary(femalepop$Population)
1618603166557:sqrt(var(fertility$Fertility_Rate))
1618603166588:sqrt(var(femalepop$Population))
1618603166671:# Use this to create some plots.
1618603166696:options(scipen=999)
1618603166732:pop <- (femalepop$Population)
1618603166765:ggplot(data = femalepop,
1618603166784:aes(x = pop)) +
1618603166803:geom_histogram(bins= 25,colour="black",
1618603166822:fill = "light blue")+
1618603166844:xlab("Population")+
1618603166863:ylab("Number of countries")+
1618603166881:scale_x_continuous()+
1618603166902:theme_classic()+
1618603166920:ggtitle("Histogram of global female population in 2018")
1618603167380:options(scipen=999)
1618603167425:fert <- (fertility$Fertility_Rate)
1618603167463:ggplot(data = fertility,
1618603167481:aes(x = fert)) +
1618603167502:geom_histogram(bins= 20,colour="black",
1618603167524:fill = "light blue")+
1618603167546:xlab("Fertility rate")+
1618603167566:ylab("Number of countries")+
1618603167589:scale_x_continuous()+
1618603167617:theme_classic()+
1618603167638:ggtitle("Histogram of global fertility rates in 2018")
1618603168150:# Here you can run your lm...
1618603168196:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618603168234:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618603168277:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618603168361:linearmodel
1618603817240:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618603817265:library(openintro)
1618603817288:library(tidyverse)
1618603817312:library(dplyr)
1618603817355:fertility <- read_csv("Fertility.csv")
1618603817576:femalepop <- read_csv("FemalePopulation.csv")
1618603817824:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618603817863:# You may need additional chunks, in case you want to include some of the cleaning output.
1618603817903:fertility <- fertility %>%
1618603817923:select(`Data Source` ,X63) %>%
1618603817941:filter(!is.na(X63)) %>%
1618603817964:rename(Country = `Data Source`)%>%
1618603817990:rename(Fertility_Rate = X63) %>%
1618603818009:filter(Country != "Country Name") %>%
1618603818031:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618603818073:fertility
1618603818137:femalepop <- femalepop %>%
1618603818160:select(`Data Source` ,X63) %>%
1618603818184:filter(!is.na(X63)) %>%
1618603818208:rename(Country = `Data Source`)%>%
1618603818228:rename(Population = X63) %>%
1618603818251:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618603818318:femalepop
1618603818391:# Use this to calculate some summary measures.
1618603818419:summary(fertility$Fertility_Rate)
1618603818503:summary(femalepop$Population)
1618603818574:sqrt(var(fertility$Fertility_Rate))
1618603818602:sqrt(var(femalepop$Population))
1618603818684:# Use this to create some plots.
1618603818711:options(scipen=999)
1618603818748:pop <- (femalepop$Population)
1618603818789:ggplot(data = femalepop,
1618603818807:aes(x = pop)) +
1618603818829:geom_histogram(bins= 25,colour="black",
1618603818850:fill = "light blue")+
1618603818867:xlab("Population")+
1618603818886:ylab("Number of countries")+
1618603818904:scale_x_continuous()+
1618603818924:theme_classic()+
1618603818942:ggtitle("Histogram of global female population in 2018")
1618603819256:options(scipen=999)
1618603819296:fert <- (fertility$Fertility_Rate)
1618603819337:ggplot(data = fertility,
1618603819356:aes(x = fert)) +
1618603819375:geom_histogram(bins= 20,colour="black",
1618603819402:fill = "light blue")+
1618603819425:xlab("Fertility rate")+
1618603819445:ylab("Number of countries")+
1618603819464:scale_x_continuous()+
1618603819489:theme_classic()+
1618603819508:ggtitle("Histogram of global fertility rates in 2018")
1618603819801:# Here you can run your lm...
1618603819845:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618603819879:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618603819920:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618603820004:linearmodel
1618705580560:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618705580611:library(openintro)
1618705580698:library(tidyverse)
1618705580719:library(dplyr)
1618705580885:fertility <- read_csv("Fertility.csv")
1618705581241:femalepop <- read_csv("FemalePopulation.csv")
1618705581555:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618705581629:# You may need additional chunks, in case you want to include some of the cleaning output.
1618705581705:fertility <- fertility %>%
1618705581729:select(`Data Source` ,X63) %>%
1618705581750:filter(!is.na(X63)) %>%
1618705581772:rename(Country = `Data Source`)%>%
1618705581795:rename(Fertility_Rate = X63) %>%
1618705581814:filter(Country != "Country Name") %>%
1618705581834:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618705581885:fertility
1618705581949:femalepop <- femalepop %>%
1618705581977:select(`Data Source` ,X63) %>%
1618705582005:filter(!is.na(X63)) %>%
1618705582051:rename(Country = `Data Source`)%>%
1618705582075:rename(Population = X63) %>%
1618705582109:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618705582144:femalepop
1618705582215:# Use this to calculate some summary measures.
1618705582243:summary(fertility$Fertility_Rate)
1618705582327:summary(femalepop$Population)
1618705582437:sqrt(var(fertility$Fertility_Rate))
1618705582500:sqrt(var(femalepop$Population))
1618705582591:# Use this to create some plots.
1618705582625:options(scipen=999)
1618705582664:pop <- (femalepop$Population)
1618705582710:ggplot(data = femalepop,
1618705582733:aes(x = pop)) +
1618705582755:geom_histogram(bins= 25,colour="black",
1618705582777:fill = "light blue")+
1618705582803:xlab("Population")+
1618705582833:ylab("Number of countries")+
1618705582871:scale_x_continuous()+
1618705582907:theme_classic()+
1618705582943:ggtitle("Histogram of global female population in 2018")
1618705583384:options(scipen=999)
1618705583435:fert <- (fertility$Fertility_Rate)
1618705583480:ggplot(data = fertility,
1618705583505:aes(x = fert)) +
1618705583534:geom_histogram(bins= 20,colour="black",
1618705583563:fill = "light blue")+
1618705583589:xlab("Fertility rate")+
1618705583636:ylab("Number of countries")+
1618705583669:scale_x_continuous()+
1618705583696:theme_classic()+
1618705583721:ggtitle("Histogram of global fertility rates in 2018")
1618705584145:# Here you can run your lm...
1618705584195:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618705584242:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618705584304:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618705584432:linearmodel
1618705594176:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618705594206:library(openintro)
1618705594234:library(tidyverse)
1618705594265:library(dplyr)
1618705594316:fertility <- read_csv("Fertility.csv")
1618705594525:femalepop <- read_csv("FemalePopulation.csv")
1618705594764:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618705594814:# You may need additional chunks, in case you want to include some of the cleaning output.
1618705594853:fertility <- fertility %>%
1618705594873:select(`Data Source` ,X63) %>%
1618705594896:filter(!is.na(X63)) %>%
1618705594924:rename(Country = `Data Source`)%>%
1618705594960:rename(Fertility_Rate = X63) %>%
1618705594987:filter(Country != "Country Name") %>%
1618705595014:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618705595061:fertility
1618705595135:femalepop <- femalepop %>%
1618705595157:select(`Data Source` ,X63) %>%
1618705595178:filter(!is.na(X63)) %>%
1618705595200:rename(Country = `Data Source`)%>%
1618705595227:rename(Population = X63) %>%
1618705595248:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618705595293:femalepop
1618705595397:# Use this to calculate some summary measures.
1618705595445:summary(fertility$Fertility_Rate)
1618705595548:summary(femalepop$Population)
1618705595640:sqrt(var(fertility$Fertility_Rate))
1618705595678:sqrt(var(femalepop$Population))
1618705595777:# Use this to create some plots.
1618705595812:options(scipen=999)
1618705595858:pop <- (femalepop$Population)
1618705595904:ggplot(data = femalepop,
1618705595927:aes(x = pop)) +
1618705595952:geom_histogram(bins= 25,colour="black",
1618705595988:fill = "light blue")+
1618705596029:xlab("Population")+
1618705596078:ylab("Number of countries")+
1618705596113:scale_x_continuous()+
1618705596133:theme_classic()+
1618705596157:ggtitle("Histogram of global female population in 2018")
1618705596479:options(scipen=999)
1618705596530:fert <- (fertility$Fertility_Rate)
1618705596572:ggplot(data = fertility,
1618705596593:aes(x = fert)) +
1618705596616:geom_histogram(bins= 20,colour="black",
1618705596658:fill = "light blue")+
1618705596691:xlab("Fertility rate")+
1618705596729:ylab("Number of countries")+
1618705596757:scale_x_continuous()+
1618705596792:theme_classic()+
1618705596818:ggtitle("Histogram of global fertility rates in 2018")
1618705597135:# Here you can run your lm...
1618705597178:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618705597220:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618705597309:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618705597456:total %>%
1618705597481:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618705597504:geom_point(col = "blue")+
1618705597527:ggtitle("Scatterplot of population given fertility")+
1618705597550:theme(plot.title = element_text(size=12))+
1618705597575:xlab("Fertility Rate")+
1618705597599:ylab("Female Population")+
1618705597625:theme_classic()+
1618705597650:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618705597988:## Maybe create a nice scatterplot with a regression line laid on top.
1618705598093:# Here you can calculate your CIs, run a bootstrap, etc.
1618705598156:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618705598250:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618705598379:# Here you can calculate your test stats, critical values, etc.
1618705598425:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618705598510:# Here you can calculate your test stats, critical values, etc.
1618705598555:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618705598579:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618705598687:# Here you can calculate your Credible Interval
1618705598793:# Here you can include some relevant visualizations.
1618763984023:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618763984070:library(openintro)
1618763984160:library(tidyverse)
1618763984182:library(dplyr)
1618763984342:fertility <- read_csv("Fertility.csv")
1618763984781:femalepop <- read_csv("FemalePopulation.csv")
1618763985071:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618763985113:# You may need additional chunks, in case you want to include some of the cleaning output.
1618763985184:fertility <- fertility %>%
1618763985209:select(`Data Source` ,X63) %>%
1618763985233:filter(!is.na(X63)) %>%
1618763985259:rename(Country = `Data Source`)%>%
1618763985283:rename(Fertility_Rate = X63) %>%
1618763985313:filter(Country != "Country Name") %>%
1618763985336:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618763985395:fertility
1618763985468:femalepop <- femalepop %>%
1618763985489:select(`Data Source` ,X63) %>%
1618763985508:filter(!is.na(X63)) %>%
1618763985530:rename(Country = `Data Source`)%>%
1618763985548:rename(Population = X63) %>%
1618763985567:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618763985601:femalepop
1618763985671:# Use this to calculate some summary measures.
1618763985703:summary(fertility$Fertility_Rate)
1618763985803:summary(femalepop$Population)
1618763985902:sqrt(var(fertility$Fertility_Rate))
1618763985939:sqrt(var(femalepop$Population))
1618763986028:# Use this to create some plots.
1618763986057:options(scipen=999)
1618763986095:pop <- (femalepop$Population)
1618763986137:ggplot(data = femalepop,
1618763986160:aes(x = pop)) +
1618763986180:geom_histogram(bins= 25,colour="black",
1618763986199:fill = "light blue")+
1618763986220:xlab("Population")+
1618763986243:ylab("Number of countries")+
1618763986262:scale_x_continuous()+
1618763986282:theme_classic()+
1618763986302:ggtitle("Histogram of global female population in 2018")
1618763986747:options(scipen=999)
1618763986799:fert <- (fertility$Fertility_Rate)
1618763986843:ggplot(data = fertility,
1618763986861:aes(x = fert)) +
1618763986879:geom_histogram(bins= 20,colour="black",
1618763986895:fill = "light blue")+
1618763986914:xlab("Fertility rate")+
1618763986932:ylab("Number of countries")+
1618763986953:scale_x_continuous()+
1618763986973:theme_classic()+
1618763986994:ggtitle("Histogram of global fertility rates in 2018")
1618763987405:# Here you can run your lm...
1618763987450:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618763987486:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618763987527:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618763987620:total %>%
1618763987642:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618763987662:geom_point(col = "blue")+
1618763987682:ggtitle("Scatterplot of population given fertility")+
1618763987703:theme(plot.title = element_text(size=12))+
1618763987723:xlab("Fertility Rate")+
1618763987742:ylab("Female Population")+
1618763987767:theme_classic()+
1618763987785:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618763988076:## Maybe create a nice scatterplot with a regression line laid on top.
1618763988193:# Here you can calculate your CIs, run a bootstrap, etc.
1618763988256:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618763988334:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618763988418:# Here you can calculate your test stats, critical values, etc.
1618763988461:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618763988536:# Here you can calculate your test stats, critical values, etc.
1618763988591:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618763988612:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618763988701:# Here you can calculate your Credible Interval
1618763988788:# Here you can include some relevant visualizations.
1618763990032:View(total)
1618763995928:View(femalepop)
1618764265232:View(femalepop)
1618765733471:# Here you can calculate your test stats, critical values, etc.
1618765733507:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765733529:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765733548:L1 <- (1/3)^34543857 * (1/3)^33652378 * (1/3)^42000374
1618765733571:L2 <- (0.313)^34543857 * (0.305)^33652378 * (0.381)^42000374
1618765733607:teststat <- -2(log(L1)-log(L2))
1618765755137:# Here you can calculate your test stats, critical values, etc.
1618765755178:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765755198:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765755220:L1 <- (1/3)^34543857 * (1/3)^33652378 * (1/3)^42000374
1618765755244:L2 <- (0.313)^34543857 * (0.305)^33652378 * (0.381)^42000374
1618765755282:teststat <- -2(log(L1)-log(L2))
1618765783112:# Here you can calculate your test stats, critical values, etc.
1618765783152:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765783174:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765783194:L1 <- (1/3)^34543857*(1/3)^33652378*(1/3)^42000374
1618765783218:L2 <- (0.313)^34543857 * (0.305)^33652378 * (0.381)^42000374
1618765783259:teststat <- -2(log(L1)-log(L2))
1618765839504:# Here you can calculate your test stats, critical values, etc.
1618765839543:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765839566:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765839586:L1 <- (1/3)^(34543857)*(1/3)^(33652378)*(1/3)^(42000374)
1618765839609:L2 <- (0.313)^(34543857)*(0.305)^(33652378)*(0.381)^(42000374)
1618765839645:teststat <- -2(log(L1)-log(L2))
1618765880350:(1/3)^(34543857)
1618765944168:# Here you can calculate your test stats, critical values, etc.
1618765944214:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765944236:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765944255:L1 <- (1/3)^(345)*(1/3)^(336)*(1/3)^(420)
1618765944274:L2 <- (0.313)^(345)*(0.305)^(336)*(0.381)^(420)
1618765944314:teststat <- -2(log(L1)-log(L2))
1618765970015:# Here you can calculate your test stats, critical values, etc.
1618765970061:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618765970080:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618765970098:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618765970119:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618765970160:teststat <- -2(log(L1)-log(L2))
1618765982972:(1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618765997832:(0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618766006465:0.00000000000000000000000000000000000000000000000000001095319/0.00000000000000000000000000000000000000000000000000001618435
1618766035665:log(0.00000000000000000000000000000000000000000000000000001095319)
1618766063410:log(0.00000000000000000000000000000000000000000000000000001618435)
1618766093345:-121.946 - (-121.5556)
1618766100958:-2(-0.3904)
1618766106853:-2*(-0.3904)
1618768314349:# Here you can calculate your test stats, critical values, etc.
1618768314393:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618768314413:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618768314441:L1 <- (1/3)^(3.5)*(1/3)^(3.4)*(1/3)^(4.2)
1618768314470:L2 <- (0.313)^(3.5)*(0.305)^(3.4)*(0.381)^(4.2)
1618768314508:teststat <- -2(log(L1)-log(L2))
1618768323251:# Here you can calculate your test stats, critical values, etc.
1618768323282:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618768323301:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618768323324:L1 <- (1/3)^(3.5)*(1/3)^(3.4)*(1/3)^(4.2)
1618768323346:L2 <- (0.313)^(3.5)*(0.305)^(3.4)*(0.381)^(4.2)
1618768323382:teststat <- -2*(log(L1)-log(L2))
1618768340564:# Here you can calculate your test stats, critical values, etc.
1618768340599:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618768340616:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618768340633:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618768340652:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618768340684:teststat <- -2*(log(L1)-log(L2))
1618768340705:teststat
1618768372423:# Here you can calculate your test stats, critical values, etc.
1618768372455:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618768372473:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618768372493:L1 <- (1/3)^(350)*(1/3)^(340)*(1/3)^(420)
1618768372514:L2 <- (0.313)^(350)*(0.305)^(340)*(0.381)^(420)
1618768372551:teststat <- -2*(log(L1)-log(L2))
1618768372571:teststat
1618768386709:# Here you can calculate your test stats, critical values, etc.
1618768386748:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618768386769:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618768386787:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618768386808:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618768386841:teststat <- -2*(log(L1)-log(L2))
1618768386862:teststat
1618768761351:pchisq(0.7808, lower.tail = FALSE, df=2)
1618772558877:# Here you can calculate your CIs, run a bootstrap, etc.
1618772558939:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618772559008:femalepop %>%
1618772559032:summarise(
1618772559057:mean_cal = mean(Population),
1618772559082:sd_cal = sd(Population),
1618772559106:n_cal = n())
1618772584329:# Here you can calculate your CIs, run a bootstrap, etc.
1618772584392:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618772584449:femalepop %>%
1618772584472:summarise(
1618772584493:mean_pop = mean(Population),
1618772584518:sd_pop = sd(Population),
1618772584546:n_cal = n())
1618772721266:# Here you can calculate your CIs, run a bootstrap, etc.
1618772721332:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618772721392:femalepop %>%
1618772721413:summarise(
1618772721436:mean_pop = mean(Population),
1618772721462:sd_pop = sd(Population),
1618772721484:n_cal = n())
1618772721558:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618772721597:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618772818783:# Here you can calculate your CIs, run a bootstrap, etc.
1618772818838:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618772818892:femalepop %>%
1618772818914:summarise(
1618772818937:mean_pop = mean(Population),
1618772818958:sd_pop = sd(Population),
1618772818976:n_cal = n())
1618772819050:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618772819090:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618774107944:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774107981:1/n_cal
1618774118777:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774118817:1/femalepop$n_cal
1618774138279:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774138317:1/femalepop$n_cal
1618774143595:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774143636:1/femalepop$n_cal
1618774202731:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774202772:(1/195)*(sum(femalepop$Population))^2
1618774250716:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774250757:(1/195)*(sum(femalepop$Population)^2)
1618774257585:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774257617:(1/195)*(sum(femalepop$Population))^2
1618774262462:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774262502:(1/195)*(sum(femalepop$Population)^2)
1618774272269:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774272323:(1/195)*(sum(femalepop$Population^2))
1618774290752:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618774290784:(1/195)*(sum((femalepop$Population)^2))
1618784878017:# Here you can calculate your test stats, critical values, etc.
1618784878057:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618784878098:pnorm(-1.86)+ pnorm(1.86, lower.tail = FALSE)
1618784885211:# Here you can calculate your test stats, critical values, etc.
1618784885254:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618784885294:pnorm(-1.86)+ pnorm(1.86, lower.tail = FALSE)
1618785077399:# Here you can calculate your test stats, critical values, etc.
1618785077441:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785077482:pnorm(-1.87)+ pnorm(1.87, lower.tail = FALSE)
1618785086629:# Here you can calculate your test stats, critical values, etc.
1618785086673:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785086717:pnorm(-1.88)+ pnorm(1.88, lower.tail = FALSE)
1618785094593:# Here you can calculate your test stats, critical values, etc.
1618785094634:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785094674:pnorm(-1.92)+ pnorm(1.92, lower.tail = FALSE)
1618785102857:# Here you can calculate your test stats, critical values, etc.
1618785102895:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785102932:pnorm(-1.95)+ pnorm(1.95, lower.tail = FALSE)
1618785109208:# Here you can calculate your test stats, critical values, etc.
1618785109248:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785109292:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618785696634:# Here you can calculate your test stats, critical values, etc.
1618785696672:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785696706:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618785746531:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618785746553:library(openintro)
1618785746576:library(tidyverse)
1618785746599:library(dplyr)
1618785746647:fertility <- read_csv("Fertility.csv")
1618785746866:femalepop <- read_csv("FemalePopulation.csv")
1618785747128:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618785747172:# You may need additional chunks, in case you want to include some of the cleaning output.
1618785747218:fertility <- fertility %>%
1618785747240:select(`Data Source` ,X63) %>%
1618785747263:filter(!is.na(X63)) %>%
1618785747292:rename(Country = `Data Source`)%>%
1618785747314:rename(Fertility_Rate = X63) %>%
1618785747337:filter(Country != "Country Name") %>%
1618785747359:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618785747402:fertility
1618785747463:femalepop <- femalepop %>%
1618785747482:select(`Data Source` ,X63) %>%
1618785747503:filter(!is.na(X63)) %>%
1618785747525:rename(Country = `Data Source`)%>%
1618785747542:rename(Population = X63) %>%
1618785747592:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618785747630:femalepop
1618785747709:# Use this to calculate some summary measures.
1618785747740:summary(fertility$Fertility_Rate)
1618785747815:summary(femalepop$Population)
1618785747892:sqrt(var(fertility$Fertility_Rate))
1618785747934:sqrt(var(femalepop$Population))
1618785748008:# Use this to create some plots.
1618785748035:options(scipen=999)
1618785748065:pop <- (femalepop$Population)
1618785748103:ggplot(data = femalepop,
1618785748124:aes(x = pop)) +
1618785748143:geom_histogram(bins= 25,colour="black",
1618785748161:fill = "light blue")+
1618785748182:xlab("Population")+
1618785748204:ylab("Number of countries")+
1618785748228:scale_x_continuous()+
1618785748248:theme_classic()+
1618785748271:ggtitle("Histogram of global female population in 2018")
1618785748572:options(scipen=999)
1618785748609:fert <- (fertility$Fertility_Rate)
1618785748645:ggplot(data = fertility,
1618785748664:aes(x = fert)) +
1618785748683:geom_histogram(bins= 20,colour="black",
1618785748700:fill = "light blue")+
1618785748720:xlab("Fertility rate")+
1618785748741:ylab("Number of countries")+
1618785748762:scale_x_continuous()+
1618785748781:theme_classic()+
1618785748802:ggtitle("Histogram of global fertility rates in 2018")
1618785749080:# Here you can run your lm...
1618785749126:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618785749161:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618785749201:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618785749289:total %>%
1618785749308:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618785749328:geom_point(col = "blue")+
1618785749350:ggtitle("Scatterplot of population given fertility")+
1618785749370:theme(plot.title = element_text(size=12))+
1618785749394:xlab("Fertility Rate")+
1618785749415:ylab("Female Population")+
1618785749434:theme_classic()+
1618785749455:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618785749759:## Maybe create a nice scatterplot with a regression line laid on top.
1618785749853:# Here you can calculate your CIs, run a bootstrap, etc.
1618785749907:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785749959:femalepop %>%
1618785749981:summarise(
1618785749999:mean_pop = mean(Population),
1618785750027:sd_pop = sd(Population),
1618785750047:n_cal = n())
1618785750117:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618785750149:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618785750225:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618785750269:(1/195)*(sum((femalepop$Population)^2))
1618785750387:# Here you can calculate your test stats, critical values, etc.
1618785750430:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618785750471:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618785750581:# Here you can calculate your test stats, critical values, etc.
1618785750622:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618785750641:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618785750662:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618785750685:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618785750725:teststat <- -2*(log(L1)-log(L2))
1618785750748:teststat
1618785750810:# Here you can calculate your Credible Interval
1618785750884:# Here you can include some relevant visualizations.
1618786276280:# Here you can run your lm...
1618786276323:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618786276366:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618786276417:lm(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618786276513:total %>%
1618786276535:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618786276558:geom_point(col = "blue")+
1618786276579:ggtitle("Scatterplot of population given fertility")+
1618786276602:theme(plot.title = element_text(size=12))+
1618786276627:xlab("Fertility Rate")+
1618786276647:ylab("Female Population")+
1618786276670:theme_classic()+
1618786276692:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618786297745:# Here you can run your lm...
1618786297784:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618786297823:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618786297868:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618786298243:total %>%
1618786298266:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618786298288:geom_point(col = "blue")+
1618786298308:ggtitle("Scatterplot of population given fertility")+
1618786298328:theme(plot.title = element_text(size=12))+
1618786298346:xlab("Fertility Rate")+
1618786298364:ylab("Female Population")+
1618786298386:theme_classic()+
1618786298405:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618786348585:# Here you can run your lm...
1618786348623:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618786348670:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618786348715:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618786349062:cor(femalepop.Population ~ fertility.Fertility_Rate, data = total)
1618786361529:# Here you can run your lm...
1618786361566:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618786361604:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618786361650:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618786362010:total %>%
1618786362032:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618786362058:geom_point(col = "blue")+
1618786362082:ggtitle("Scatterplot of population given fertility")+
1618786362106:theme(plot.title = element_text(size=12))+
1618786362130:xlab("Fertility Rate")+
1618786362153:ylab("Female Population")+
1618786362175:theme_classic()+
1618786362197:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618786384463:# Here you can run your lm...
1618786384504:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618786384541:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618786384589:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618786384941:cor(femalepop$Population, fertility$Fertility_Rate)
1618786385002:total %>%
1618786385022:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618786385048:geom_point(col = "blue")+
1618786385068:ggtitle("Scatterplot of population given fertility")+
1618786385094:theme(plot.title = element_text(size=12))+
1618786385121:xlab("Fertility Rate")+
1618786385143:ylab("Female Population")+
1618786385176:theme_classic()+
1618786385196:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618787449228:View(fertility)
1618789563437:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618789563457:library(openintro)
1618789563476:library(tidyverse)
1618789563502:library(dplyr)
1618789563545:fertility <- read_csv("Fertility.csv")
1618789563745:femalepop <- read_csv("FemalePopulation.csv")
1618789563969:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618789564015:# You may need additional chunks, in case you want to include some of the cleaning output.
1618789564055:fertility <- fertility %>%
1618789564076:select(`Data Source` ,X63) %>%
1618789564096:filter(!is.na(X63)) %>%
1618789564127:rename(Country = `Data Source`)%>%
1618789564147:rename(Fertility_Rate = X63) %>%
1618789564170:filter(Country != "Country Name") %>%
1618789564190:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618789564228:fertility
1618789564293:femalepop <- femalepop %>%
1618789564319:select(`Data Source` ,X63) %>%
1618789564339:filter(!is.na(X63)) %>%
1618789564363:rename(Country = `Data Source`)%>%
1618789564387:rename(Population = X63) %>%
1618789564408:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618789564446:femalepop
1618789564520:# Use this to calculate some summary measures.
1618789564547:summary(fertility$Fertility_Rate)
1618789564658:summary(femalepop$Population)
1618789564745:sqrt(var(fertility$Fertility_Rate))
1618789564780:sqrt(var(femalepop$Population))
1618789564879:# Use this to create some plots.
1618789564908:options(scipen=999)
1618789564944:pop <- (femalepop$Population)
1618789564985:ggplot(data = femalepop,
1618789565003:aes(x = pop)) +
1618789565025:geom_histogram(bins= 25,colour="black",
1618789565046:fill = "light blue")+
1618789565067:xlab("Population")+
1618789565088:ylab("Number of countries")+
1618789565105:scale_x_continuous()+
1618789565128:theme_classic()+
1618789565149:ggtitle("Histogram of global female population in 2018")
1618789565446:options(scipen=999)
1618789565494:fert <- (fertility$Fertility_Rate)
1618789565538:ggplot(data = fertility,
1618789565558:aes(x = fert)) +
1618789565586:geom_histogram(bins= 20,colour="black",
1618789565604:fill = "light blue")+
1618789565624:xlab("Fertility rate")+
1618789565647:ylab("Number of countries")+
1618789565670:scale_x_continuous()+
1618789565686:theme_classic()+
1618789565706:ggtitle("Histogram of global fertility rates in 2018")
1618789565997:# Here you can run your lm...
1618789566035:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618789566070:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618789566113:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618789566410:cor(femalepop$Population, fertility$Fertility_Rate)
1618789566463:total %>%
1618789566483:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618789566503:geom_point(col = "blue")+
1618789566524:ggtitle("Scatterplot of population given fertility")+
1618789566547:theme(plot.title = element_text(size=12))+
1618789566567:xlab("Fertility Rate")+
1618789566586:ylab("Female Population")+
1618789566605:theme_classic()+
1618789566633:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618789566894:## Maybe create a nice scatterplot with a regression line laid on top.
1618789566990:# Here you can calculate your CIs, run a bootstrap, etc.
1618789567052:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618789567106:femalepop %>%
1618789567129:summarise(
1618789567149:mean_pop = mean(Population),
1618789567172:sd_pop = sd(Population),
1618789567196:n_cal = n())
1618789567259:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618789567292:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618789567379:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618789567411:(1/195)*(sum((femalepop$Population)^2))
1618789567487:# Here you can calculate your test stats, critical values, etc.
1618789567532:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618789567579:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618789567672:# Here you can calculate your test stats, critical values, etc.
1618789567718:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618789567742:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618789567767:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618789567789:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618789567826:teststat <- -2*(log(L1)-log(L2))
1618789567848:teststat
1618789567921:# Here you can calculate your Credible Interval
1618789568001:# Here you can include some relevant visualizations.
1618800785914:# Here you can calculate your Credible Interval
1618800785950:qgamma(0.025, shape =153, scale = 50/151)
1618800785982:qgamma(0.975, shape =153, scale = 50/151)
1618800790961:# Here you can calculate your Credible Interval
1618800790994:qgamma(0.025, shape =153, scale = 50/151)
1618800791023:qgamma(0.975, shape =153, scale = 50/151)
1618800804603:# Here you can calculate your Credible Interval
1618800804640:qgamma(0.025, shape =145, scale = 50/151)
1618800804674:qgamma(0.975, shape =153, scale = 50/151)
1618800845213:# Here you can calculate your Credible Interval
1618800845256:qgamma(0.025, shape =153, scale = 50/151)
1618800845297:qgamma(0.975, shape =153, scale = 50/151)
1618804440967:# Here you can run your lm...
1618804441012:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618804441050:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618804441093:summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618804441389:cor(femalepop$Population, fertility$Fertility_Rate)
1618804441440:total %>%
1618804441457:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618804441475:geom_point(col = "blue")+
1618804441494:ggtitle("Scatterplot of population given fertility")+
1618804441513:theme(plot.title = element_text(size=12))+
1618804441533:xlab("Fertility Rate")+
1618804441549:ylab("Female Population")+
1618804441567:theme_classic()+
1618804441589:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618849154881:# Here you can calculate your CIs, run a bootstrap, etc.
1618849154941:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618849155010:femalepop %>%
1618849155029:summarise(
1618849155046:mean_pop = mean(Population),
1618849155065:sd_pop = sd(Population),
1618849155086:n_cal = n())
1618849158798:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618849158820:library(openintro)
1618849158909:library(tidyverse)
1618849158929:library(dplyr)
1618849158969:fertility <- read_csv("Fertility.csv")
1618849159306:femalepop <- read_csv("FemalePopulation.csv")
1618849159664:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618849159706:# You may need additional chunks, in case you want to include some of the cleaning output.
1618849159747:fertility <- fertility %>%
1618849159791:select(`Data Source` ,X63) %>%
1618849159810:filter(!is.na(X63)) %>%
1618849159830:rename(Country = `Data Source`)%>%
1618849159847:rename(Fertility_Rate = X63) %>%
1618849159867:filter(Country != "Country Name") %>%
1618849159891:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618849159957:fertility
1618849160018:femalepop <- femalepop %>%
1618849160038:select(`Data Source` ,X63) %>%
1618849160056:filter(!is.na(X63)) %>%
1618849160074:rename(Country = `Data Source`)%>%
1618849160093:rename(Population = X63) %>%
1618849160112:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618849160148:femalepop
1618849160214:# Use this to calculate some summary measures.
1618849160238:summary(fertility$Fertility_Rate)
1618849160321:summary(femalepop$Population)
1618849160396:sqrt(var(fertility$Fertility_Rate))
1618849160427:sqrt(var(femalepop$Population))
1618849160496:# Use this to create some plots.
1618849160528:options(scipen=999)
1618849160568:pop <- (femalepop$Population)
1618849160607:ggplot(data = femalepop,
1618849160629:aes(x = pop)) +
1618849160653:geom_histogram(bins= 25,colour="black",
1618849160674:fill = "light blue")+
1618849160699:xlab("Population")+
1618849160719:ylab("Number of countries")+
1618849160740:scale_x_continuous()+
1618849160761:theme_classic()+
1618849160784:ggtitle("Histogram of global female population in 2018")
1618849161187:options(scipen=999)
1618849161229:fert <- (fertility$Fertility_Rate)
1618849161271:ggplot(data = fertility,
1618849161290:aes(x = fert)) +
1618849161308:geom_histogram(bins= 20,colour="black",
1618849161328:fill = "light blue")+
1618849161353:xlab("Fertility rate")+
1618849161374:ylab("Number of countries")+
1618849161392:scale_x_continuous()+
1618849161412:theme_classic()+
1618849161431:ggtitle("Histogram of global fertility rates in 2018")
1618849161775:# Here you can calculate your CIs, run a bootstrap, etc.
1618849161828:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618849161878:femalepop %>%
1618849161903:summarise(
1618849161923:mean_pop = mean(Population),
1618849161972:sd_pop = sd(Population),
1618849161999:n_cal = n())
1618849162064:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618849162097:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618849162181:# Here you can calculate your test stats, critical values, etc.
1618849162219:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618849162250:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618849162351:# Here you can calculate your test stats, critical values, etc.
1618849162399:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618849162420:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618849162439:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618849162464:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618849162504:teststat <- -2*(log(L1)-log(L2))
1618849162527:teststat
1618849162595:# Here you can run your lm...
1618849162631:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618849162665:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618849162701:#summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618849162717:#cor(femalepop$Population, fertility$Fertility_Rate)
1618849162770:total %>%
1618849162789:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618849162807:geom_point(col = "blue")+
1618849162827:ggtitle("Scatterplot of population given fertility")+
1618849162844:theme(plot.title = element_text(size=12))+
1618849162860:xlab("Fertility Rate")+
1618849162883:ylab("Female Population")+
1618849162901:theme_classic()+
1618849162918:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618849163220:## Maybe create a nice scatterplot with a regression line laid on top.
1618849163309:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618849163345:(1/195)*(sum((femalepop$Population)^2))
1618849163422:# Here you can calculate your Credible Interval
1618849163462:qgamma(0.025, shape =153, scale = 50/151)
1618849163503:qgamma(0.975, shape =153, scale = 50/151)
1618849163584:# Here you can include some relevant visualizations.
1618850424105:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1618850424124:library(openintro)
1618850424142:library(tidyverse)
1618850424159:library(dplyr)
1618850424193:fertility <- read_csv("Fertility.csv")
1618850424412:femalepop <- read_csv("FemalePopulation.csv")
1618850424895:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1618850424934:# You may need additional chunks, in case you want to include some of the cleaning output.
1618850424969:fertility <- fertility %>%
1618850424985:select(`Data Source` ,X63) %>%
1618850425009:filter(!is.na(X63)) %>%
1618850425027:rename(Country = `Data Source`)%>%
1618850425048:rename(Fertility_Rate = X63) %>%
1618850425067:filter(Country != "Country Name") %>%
1618850425084:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618850425123:fertility
1618850425178:femalepop <- femalepop %>%
1618850425201:select(`Data Source` ,X63) %>%
1618850425223:filter(!is.na(X63)) %>%
1618850425242:rename(Country = `Data Source`)%>%
1618850425259:rename(Population = X63) %>%
1618850425277:filter(Country != "Country Name" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1618850425314:femalepop
1618850425376:# Use this to calculate some summary measures.
1618850425401:summary(fertility$Fertility_Rate)
1618850425482:summary(femalepop$Population)
1618850425557:sqrt(var(fertility$Fertility_Rate))
1618850425589:sqrt(var(femalepop$Population))
1618850425654:# Use this to create some plots.
1618850425677:options(scipen=999)
1618850425712:pop <- (femalepop$Population)
1618850425748:ggplot(data = femalepop,
1618850425766:aes(x = pop)) +
1618850425785:geom_histogram(bins= 25,colour="black",
1618850425826:fill = "light blue")+
1618850425843:xlab("Population")+
1618850425858:ylab("Number of countries")+
1618850425874:scale_x_continuous()+
1618850425890:theme_classic()+
1618850425906:ggtitle("Histogram of global female population in 2018")
1618850426180:options(scipen=999)
1618850426225:fert <- (fertility$Fertility_Rate)
1618850426263:ggplot(data = fertility,
1618850426281:aes(x = fert)) +
1618850426300:geom_histogram(bins= 20,colour="black",
1618850426320:fill = "light blue")+
1618850426342:xlab("Fertility rate")+
1618850426359:ylab("Number of countries")+
1618850426381:scale_x_continuous()+
1618850426402:theme_classic()+
1618850426423:ggtitle("Histogram of global fertility rates in 2018")
1618850426718:# Here you can calculate your CIs, run a bootstrap, etc.
1618850426763:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618850426808:femalepop %>%
1618850426824:summarise(
1618850426842:mean_pop = mean(Population),
1618850426863:sd_pop = sd(Population),
1618850426886:n_cal = n())
1618850426942:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1618850426971:22017735- qnorm(0.975)*(79062105/sqrt(195))
1618850427053:# Here you can calculate your test stats, critical values, etc.
1618850427087:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1618850427121:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1618850427213:# Here you can calculate your test stats, critical values, etc.
1618850427253:# I feel like this section is exploring the distribution of the data. It may be helpful in describing the data. If that's the case, you should probably put this subsection first.
1618850427271:# Alternatively, you could use this to help you find a prior, perhaps?? If that's the case, then put this subsection directly before the Bayesian CI subsection
1618850427289:L1 <- (1/3)^(35)*(1/3)^(34)*(1/3)^(42)
1618850427310:L2 <- (0.313)^(35)*(0.305)^(34)*(0.381)^(42)
1618850427345:teststat <- -2*(log(L1)-log(L2))
1618850427365:teststat
1618850427430:# Here you can run your lm...
1618850427476:# I feel like the linear model should go at the end in terms of ordering. I mean, one variable stuff seems like it should preceed the two variable stuff. This is just a random thought and a bit of a recommendation if you aren't really sure about how to improve on the flow. Again, order things how you want, just be consistent between this section and the Methods (makes it easier for the reader).
1618850427511:total <- data.frame(fertility$Fertility_Rate, femalepop$Population)
1618850427550:#summary(lm(femalepop.Population ~ fertility.Fertility_Rate, data = total))
1618850427570:#cor(femalepop$Population, fertility$Fertility_Rate)
1618850427619:total %>%
1618850427650:ggplot(aes(x = fertility.Fertility_Rate , y=femalepop.Population))+
1618850427670:geom_point(col = "blue")+
1618850427694:ggtitle("Scatterplot of population given fertility")+
1618850427715:theme(plot.title = element_text(size=12))+
1618850427733:xlab("Fertility Rate")+
1618850427750:ylab("Female Population")+
1618850427768:theme_classic()+
1618850427786:geom_abline(slope = 0.0000000001556, intercept = 2.6664400382993, col="red")
1618850428076:## Maybe create a nice scatterplot with a regression line laid on top.
1618850428154:# Here you can calculate your MLE based on the data. (Again, if you're using the MLE in your CI, you should probably put this subsection before the CI subsection)..
1618850428190:(1/195)*(sum((femalepop$Population)^2))
1618850428266:# Here you can calculate your Credible Interval
1618850428329:qgamma(0.025, shape =153, scale = 50/151)
1618850428358:qgamma(0.975, shape =153, scale = 50/151)
1618850428428:# Here you can include some relevant visualizations.
1632237203339:library(readr)
1632237203364:cleaning_sim <- read_csv("Sta302/cleaning_sim.csv")
1632237203789:View(cleaning_sim)
1632237217707:# load dataset here
1632237217723:library(readr)
1632237217741:cleaning_sim <- read_csv("Sta302/cleaning_sim.csv")
1632237235200:# load dataset here
1632237235217:library(readr)
1632237235235:cleaning_sim <- read_csv("cleaning_sim.csv")
1632237235298:View(cleaning_sim)
1632237260790:# load dataset here
1632237260812:library(readr)
1632237260831:library(tidyverse)
1632237260848:cleaning_sim <- read_csv("cleaning_sim.csv")
1632237260891:glimpse(cleaning_sim)
1632237325145:# load dataset here
1632237325165:library(readr)
1632237325183:library(tidyverse)
1632237325202:cleaning_sim <- read_csv("~/Sta302/cleaning_sim.csv")
1632237325257:glimpse(cleaning_sim)
1632237335988:# load dataset here
1632237336009:library(readr)
1632237336028:library(tidyverse)
1632237336046:cleaning_sim <- read_csv("~/Sta302/cleaning_sim.csv")
1632237336094:head(cleaning_sim)
1632237441429:# find and print the mean and standard deviations here
1632237441461:crews_mean <- mean(crews)
1632237462869:# find and print the mean and standard deviations here
1632237462896:crews_mean <- mean(cleaning_sim$crews)
1632237462929:room_mean <- mean(cleaning_sim$room)
1632237462963:crews_mean
1632237462996:room_mean
1632237486539:# find and print the mean and standard deviations here
1632237486560:crews_mean <- mean(cleaning_sim$Crews)
1632237486580:room_mean <- mean(cleaning_sim$Room)
1632237486609:crews_mean
1632237486640:room_mean
1632237499491:# find and print the mean and standard deviations here
1632237499514:crews_mean <- mean(cleaning_sim$Crews)
1632237499537:room_mean <- mean(cleaning_sim$Rooms)
1632237499558:crews_mean
1632237499591:room_mean
1632237549155:# find and print the mean and standard deviations here
1632237549175:crews_mean <- mean(cleaning_sim$Crews)
1632237549197:room_mean <- mean(cleaning_sim$Rooms)
1632237549221:crews_mean
1632237549254:room_mean
1632237549289:crews_std <- std(cleaning_sim$Crews)
1632237562728:# find and print the mean and standard deviations here
1632237562750:crews_mean <- mean(cleaning_sim$Crews)
1632237562775:room_mean <- mean(cleaning_sim$Rooms)
1632237562796:crews_mean
1632237562831:room_mean
1632237562862:crews_std <- sd(cleaning_sim$Crews)
1632237562883:room_std <- sd(cleaning_sim$Rooms)
1632237562908:crews_std
1632237562940:room_std
1632237943120:# load dataset here
1632237943138:library(readr)
1632237943157:library(tidyverse)
1632237943177:library(ggplot2)
1632237943197:cleaning_sim <- read_csv("~/Sta302/cleaning_sim.csv")
1632237943243:head(cleaning_sim)
1632237945709:# find and print the mean and standard deviations here
1632237945728:crews_mean <- mean(cleaning_sim$Crews)
1632237945749:room_mean <- mean(cleaning_sim$Rooms)
1632237945773:crews_mean
1632237945803:room_mean
1632237945832:crews_std <- sd(cleaning_sim$Crews)
1632237945857:room_std <- sd(cleaning_sim$Rooms)
1632237945877:crews_std
1632237945905:room_std
1632237945941:boxplot1 %>% ggplot(aes(y=crews_mean)) +
1632237945962:geom_boxplot(color = 'blue', fill = 'red') +
1632237945984:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632237953327:# find and print the mean and standard deviations here
1632237953347:crews_mean <- mean(cleaning_sim$Crews)
1632237953370:room_mean <- mean(cleaning_sim$Rooms)
1632237953390:crews_mean
1632237953417:room_mean
1632237953449:crews_std <- sd(cleaning_sim$Crews)
1632237953471:room_std <- sd(cleaning_sim$Rooms)
1632237953494:crews_std
1632237953531:room_std
1632237953573:boxplot1 %>% ggplot(aes(y=crews_mean)) +
1632237953591:geom_boxplot(color = 'blue', fill = 'red') +
1632237953609:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632237978944:# find and print the mean and standard deviations here
1632237978966:crews_mean <- mean(cleaning_sim$Crews)
1632237978987:room_mean <- mean(cleaning_sim$Rooms)
1632237979009:crews_mean
1632237979040:room_mean
1632237979072:crews_std <- sd(cleaning_sim$Crews)
1632237979094:room_std <- sd(cleaning_sim$Rooms)
1632237979113:crews_std
1632237979145:room_std
1632237979185:boxplot1 <- cleaning_sim %>% ggplot(aes(y=crews_mean)) +
1632237979201:geom_boxplot(color = 'blue', fill = 'red') +
1632237979222:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632237979282:boxplot1
1632237991459:# find and print the mean and standard deviations here
1632237991479:crews_mean <- mean(cleaning_sim$Crews)
1632237991499:room_mean <- mean(cleaning_sim$Rooms)
1632237991522:crews_mean
1632237991551:room_mean
1632237991587:crews_std <- sd(cleaning_sim$Crews)
1632237991610:room_std <- sd(cleaning_sim$Rooms)
1632237991630:crews_std
1632237991662:room_std
1632237991706:boxplot1 <- cleaning_sim %>% ggplot(aes(y=crews)) +
1632237991724:geom_boxplot(color = 'blue', fill = 'red') +
1632237991745:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632237991809:boxplot1
1632238003931:# find and print the mean and standard deviations here
1632238003950:crews_mean <- mean(cleaning_sim$Crews)
1632238003972:room_mean <- mean(cleaning_sim$Rooms)
1632238003992:crews_mean
1632238004022:room_mean
1632238004048:crews_std <- sd(cleaning_sim$Crews)
1632238004069:room_std <- sd(cleaning_sim$Rooms)
1632238004090:crews_std
1632238004126:room_std
1632238004172:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632238004193:geom_boxplot(color = 'blue', fill = 'red') +
1632238004214:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632238004278:boxplot1
1632238022498:# find and print the mean and standard deviations here
1632238022515:crews_mean <- mean(cleaning_sim$Crews)
1632238022535:room_mean <- mean(cleaning_sim$Rooms)
1632238022554:crews_mean
1632238022580:room_mean
1632238022610:crews_std <- sd(cleaning_sim$Crews)
1632238022631:room_std <- sd(cleaning_sim$Rooms)
1632238022651:crews_std
1632238022686:room_std
1632238022723:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632238022740:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632238022758:labs(y='Mean of Crew Members', title = "Boxplot of Means of Crew Members")
1632238022817:boxplot1
1632238052833:# find and print the mean and standard deviations here
1632238052862:crews_mean <- mean(cleaning_sim$Crews)
1632238052885:room_mean <- mean(cleaning_sim$Rooms)
1632238052907:crews_mean
1632238052937:room_mean
1632238052968:crews_std <- sd(cleaning_sim$Crews)
1632238052988:room_std <- sd(cleaning_sim$Rooms)
1632238053011:crews_std
1632238053045:room_std
1632238053086:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632238053109:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632238053141:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632238053194:boxplot1
1632238076954:# find and print the mean and standard deviations here
1632238076973:crews_mean <- mean(cleaning_sim$Crews)
1632238076995:room_mean <- mean(cleaning_sim$Rooms)
1632238077018:crews_mean
1632238077045:room_mean
1632238077079:crews_std <- sd(cleaning_sim$Crews)
1632238077100:room_std <- sd(cleaning_sim$Rooms)
1632238077124:crews_std
1632238077157:room_std
1632238077203:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632238077222:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632238077243:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632238077301:boxplot1
1632238077453:boxplot2 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Rooms)) +
1632238077471:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632238077489:labs(y='Distribution of Rooms', title = "Boxplot of Rooms")
1632238077550:boxplot2
1632238162478:# add your plot code here
1632238162515:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238162538:geom_point(color = 'blue', fill = 'lightblue') +
1632238162559:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632238162618:boxplot1
1632238172269:# add your plot code here
1632238172302:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238172321:geom_point(color = 'blue', fill = 'lightblue') +
1632238172340:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632238172396:scatterplot1
1632238231320:# add your plot code here
1632238231354:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238231374:geom_point(color = 'blue', fill = 'lightblue') +
1632238231391:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632238231446:scatterplot1
1632238241090:# add your plot code here
1632238241123:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238241145:geom_point(color = 'blue') +
1632238241164:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632238241221:scatterplot1
1632238534249:# create your variable here
1632238534282:unique_crews <- unique(cleaning_sim$Crews)
1632238540071:# create your variable here
1632238540105:unique_crews <- unique(cleaning_sim$Crews)
1632238540129:unique_crews
1632238635739:# modify this code based on your variable names
1632238635774:ymeans <- NULL  # initialize your storage
1632238635801:for(i in unique_crews){
1632238635821:values <- cleaning_sim$Rooms[cleaning_sim$Crews==i]
1632238635840:ymeans <- c(ymeans, mean(values))
1632238635857:}
1632238635893:ymeans
1632238945952:# add previous plot code here
1632238945985:# add points using the code below and feel free to change the color and dot type
1632238946004:# (look up pch or points in the help file to see how)
1632238946039:scatterplot1
1632238946185:points(ymeans~unique_variable, col="blue", pch=19)
1632238973291:# add previous plot code here
1632238973328:# add points using the code below and feel free to change the color and dot type
1632238973354:# (look up pch or points in the help file to see how)
1632238973391:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238973411:geom_point(color = 'blue') +
1632238973431:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632238973490:scatterplot1
1632238973614:points(ymeans~unique_variable, col="blue", pch=19)
1632238983239:# add previous plot code here
1632238983274:# add points using the code below and feel free to change the color and dot type
1632238983297:# (look up pch or points in the help file to see how)
1632238983333:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632238983353:geom_point(color = 'blue') +
1632238983374:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632238983437:scatterplot1
1632238983566:points(ymeans~unique_crews, col="blue", pch=19)
1632239003044:# add previous plot code here
1632239003085:# add points using the code below and feel free to change the color and dot type
1632239003102:# (look up pch or points in the help file to see how)
1632239003148:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239003186:geom_point(color = 'blue') +
1632239003204:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632239003263:points(ymeans~unique_crews, col="blue", pch=19)
1632239008677:# add previous plot code here
1632239008715:# add points using the code below and feel free to change the color and dot type
1632239008734:# (look up pch or points in the help file to see how)
1632239008767:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239008786:geom_point(color = 'blue') +
1632239008806:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239008825:points(ymeans~unique_crews, col="blue", pch=19)
1632239039574:# add previous plot code here
1632239039610:# add points using the code below and feel free to change the color and dot type
1632239039630:# (look up pch or points in the help file to see how)
1632239039665:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=unique_crews, y=cleaning_sim$Rooms)) +
1632239039685:geom_point(color = 'blue') +
1632239039706:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239039724:points(ymeans~unique_crews, col="blue", pch=19)
1632239063455:# add previous plot code here
1632239063488:# add points using the code below and feel free to change the color and dot type
1632239063510:# (look up pch or points in the help file to see how)
1632239063544:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=unique_crews, y=cleaning_sim$Rooms)) +
1632239063566:geom_point(color = 'blue') +
1632239063585:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632239063629:#points(ymeans~unique_crews, col="blue", pch=19)
1632239070908:# add previous plot code here
1632239070947:# add points using the code below and feel free to change the color and dot type
1632239070966:# (look up pch or points in the help file to see how)
1632239070999:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=unique_crews, y=cleaning_sim$Rooms)) +
1632239071019:geom_point(color = 'blue') +
1632239071037:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632239071081:scatterplot1
1632239099259:# add previous plot code here
1632239099290:# add points using the code below and feel free to change the color and dot type
1632239099307:# (look up pch or points in the help file to see how)
1632239099335:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239099355:geom_point(color = 'blue') +
1632239099374:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632239099416:scatterplot1
1632239099527:#points(ymeans~unique_crews, col="blue", pch=19)
1632239111645:# add previous plot code here
1632239111679:# add points using the code below and feel free to change the color and dot type
1632239111697:# (look up pch or points in the help file to see how)
1632239111736:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239111754:geom_point(color = 'blue') +
1632239111773:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")+
1632239111790:points(ymeans~unique_crews, col="blue", pch=19)
1632239123015:# add previous plot code here
1632239123051:# add points using the code below and feel free to change the color and dot type
1632239123075:# (look up pch or points in the help file to see how)
1632239123111:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239123128:geom_point(color = 'blue') +
1632239123145:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")+
1632239123162:geom_points(ymeans~unique_crews, col="blue", pch=19)
1632239149711:# add previous plot code here
1632239149744:# add points using the code below and feel free to change the color and dot type
1632239149761:# (look up pch or points in the help file to see how)
1632239149794:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239149816:geom_point(color = 'blue') +
1632239149837:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")+
1632239149859:geom_point(ymeans~unique_crews, col="blue", pch=19)
1632239202635:# add previous plot code here
1632239202669:# add points using the code below and feel free to change the color and dot type
1632239202691:# (look up pch or points in the help file to see how)
1632239202724:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239202741:geom_point(color = 'blue') +
1632239202757:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")+
1632239202776:points(ymeans~unique_crews, col="blue", pch=19)
1632239212857:# add previous plot code here
1632239212889:# add points using the code below and feel free to change the color and dot type
1632239212909:# (look up pch or points in the help file to see how)
1632239212937:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239212955:geom_point(color = 'blue') +
1632239212972:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632239213030:scatterplot1
1632239213145:points(ymeans~unique_crews, col="blue", pch=19)
1632239423711:# add previous plot code here
1632239423746:# add points using the code below and feel free to change the color and dot type
1632239423764:# (look up pch or points in the help file to see how)
1632239423791:#scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239423807:#  geom_point(color = 'blue') +
1632239423822:#  labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239423841:#  geom_point(data = pointdata, mapping = aes(x = unique_crews, y = ymeans)
1632239423876:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot Example",
1632239423895:xlab="Car Weight ", ylab="Miles Per Gallon ", pch=19)
1632239423996:#scatterplot1
1632239424013:#points(ymeans~unique_crews, col="blue", pch=19)
1632239424031:#
1632239434869:# add previous plot code here
1632239434902:# add points using the code below and feel free to change the color and dot type
1632239434918:# (look up pch or points in the help file to see how)
1632239434951:#scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239434971:#  geom_point(color = 'blue') +
1632239434989:#  labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239435012:#  geom_point(data = pointdata, mapping = aes(x = unique_crews, y = ymeans)
1632239435051:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot Example",
1632239435071:xlab="Car Weight ", ylab="Miles Per Gallon ", pch=19)
1632239435107:points(ymeans~unique_crews, col="blue", pch=19)
1632239435152:#scatterplot1
1632239435171:#
1632239435191:#
1632239464476:# add previous plot code here
1632239464509:# add points using the code below and feel free to change the color and dot type
1632239464527:# (look up pch or points in the help file to see how)
1632239464563:#scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239464583:#  geom_point(color = 'blue') +
1632239464602:#  labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239464621:#  geom_point(data = pointdata, mapping = aes(x = unique_crews, y = ymeans)
1632239464653:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot Example",
1632239464673:xlab="Car Weight ", ylab="Miles Per Gallon ", pch=19, col='blue')
1632239464711:points(ymeans~unique_crews, col="red", pch=19)
1632239464754:#scatterplot1
1632239464776:#
1632239464797:#
1632239473533:# add previous plot code here
1632239473572:# add points using the code below and feel free to change the color and dot type
1632239473593:# (look up pch or points in the help file to see how)
1632239473629:#scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632239473652:#  geom_point(color = 'blue') +
1632239473673:#  labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms") +
1632239473694:#  geom_point(data = pointdata, mapping = aes(x = unique_crews, y = ymeans)
1632239473725:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot Example",
1632239473758:xlab="Car Weight ", ylab="Miles Per Gallon ", pch=19, col='lightblue')
1632239473798:points(ymeans~unique_crews, col="red", pch=19)
1632239473844:#scatterplot1
1632239473865:#
1632239473892:#
1632239526415:# add previous plot code here
1632239526454:# add points using the code below and feel free to change the color and dot type
1632239526485:# (look up pch or points in the help file to see how)
1632239526522:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239526543:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239526579:points(ymeans~unique_crews, col="red", pch=19)
1632239582783:sorted <- sort(ymeans)
1632239582821:diffs <- NULL
1632239582839:for(i in 1:(length(sorted)-1)){
1632239582857:diffs <- c(diffs, sorted[i+1]-sorted[i])
1632239582875:}
1632239582903:diffs
1632239598200:# compute the mean here
1632239598218:mean(diffs)
1632239659515:# add your previous plot code here with the points added
1632239659575:# uncomment below and replace the words slope and intercept with the values abova
1632239659600:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239659618:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239659654:points(ymeans~unique_crews, col="red", pch=19)
1632239659679:abline(a = intercept, b = slope)
1632239687174:# add your previous plot code here with the points added
1632239687204:# uncomment below and replace the words slope and intercept with the values abova
1632239687221:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239687237:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239687267:points(ymeans~unique_crews, col="red", pch=19)
1632239687287:abline(a = -0.61, b = 3.79)
1632239698805:# add your previous plot code here with the points added
1632239698838:# uncomment below and replace the words slope and intercept with the values abova
1632239698856:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239698876:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239698908:points(ymeans~unique_crews, col="red", pch=19)
1632239698935:abline(a = -0.61, b = 3.79, col= 'yello')
1632239703354:# add your previous plot code here with the points added
1632239703387:# uncomment below and replace the words slope and intercept with the values abova
1632239703407:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239703426:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239703460:points(ymeans~unique_crews, col="red", pch=19)
1632239703490:abline(a = -0.61, b = 3.79, col= 'yellow')
1632239716536:# add your previous plot code here with the points added
1632239716571:# uncomment below and replace the words slope and intercept with the values abova
1632239716592:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632239716611:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632239716655:points(ymeans~unique_crews, col="red", pch=19)
1632239716689:abline(a = -0.61, b = 3.79, col= 'purple')
1632338649690:knitr::opts_chunk$set(echo = TRUE)
1632338649893:ages <- c(3,4,5)
1632338649932:sample(ages, 2)
1632338698867:ages <- c(3,4,5)
1632338698903:sample(ages, 4)
1632338747587:ages <- c(3,4,5)
1632338747623:sample(ages, 3)
1632338749647:ages <- c(3,4,5)
1632338749684:sample(ages, 2)
1632338899382:time <- runif(n=6, min = 1, max = 10)
1632338899399:time
1632338923196:ages <- c(3,4,5)
1632338923233:sample(ages, 2)
1632338923276:time <- runif(n=6, min = 1, max = 10)
1632338923298:time
1632338923356:hist(time)
1632338929763:ages <- c(3,4,5)
1632338929802:sample(ages, 2)
1632338929847:time <- runif(n=600, min = 1, max = 10)
1632338929868:time
1632338932388:hist(time)
1632339385828:cGPA <- rnorm(n=100, 0, 4)
1632339396001:cGPA <- rnorm(n=100, 0, 4)
1632339396041:hist(cGPA)
1632339441273:cGPA <- rbeta(n=100, 0, 1)
1632339441314:hist(cGPA)
1632339444631:cGPA <- rbeta(n=100, 0, 4)
1632339444668:hist(cGPA)
1632339506165:cGPA <- rbeta(n=100, 4, 1)
1632339506207:hist(cGPA)
1632339515315:cGPA <- 4*rbeta(n=100, 4, 1)
1632339515354:hist(cGPA)
1632339646045:cGPA <- 4*rbeta(n=100, 4, 1)
1632339646084:hist(cGPA)
1632339646129:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339646168:time_distracted_min <- rpois(n, lambda=80)
1632339655468:cGPA <- 4*rbeta(n=100, 4, 1)
1632339655502:hist(cGPA)
1632339655540:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339655573:time_distracted_min <- rpois(n, lambda=80)
1632339655593:hist(time_distracted_min)
1632339811967:knitr::opts_chunk$set(echo = TRUE)
1632339811985:library(tidyverse)
1632339813683:knitr::opts_chunk$set(echo = TRUE)
1632339813699:library(tidyverse)
1632339813830:ages <- c(3,4,5)
1632339813866:sample(ages, 2)
1632339813907:time <- runif(n=600, min = 1, max = 10)
1632339813933:time
1632339816534:hist(time)
1632339816663:cGPA <- 4*rbeta(n=100, 4, 1)
1632339816700:hist(cGPA)
1632339816749:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339816784:time_distracted_min <- rpois(n, lambda=80)
1632339816802:hist(time_distracted_min)
1632339816875:my_data <- tibble (cGPA, type_of_distractor, time_distracted_min)
1632339846847:cGPA <- 4*rbeta(n=100, 4, 1)
1632339846883:hist(cGPA)
1632339846928:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339846972:time_distracted_min <- rpois(n, lambda=120)
1632339846997:hist(time_distracted_min)
1632339847082:my_data <- tibble (cGPA, type_of_distractor, time_distracted_min)
1632339871275:cGPA <- 4*rbeta(n=100, 4, 1)
1632339871313:hist(cGPA)
1632339871357:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339871401:time_distracted_min <- rpois(n, lambda=120)
1632339871425:hist(time_distracted_min)
1632339871507:my_data <- tibble(cGPA, type_of_distractor, time_distracted_min)
1632339874142:cGPA <- 4*rbeta(n=100, 4, 1)
1632339874180:hist(cGPA)
1632339874225:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339874265:time_distracted_min <- rpois(n, lambda=120)
1632339874284:hist(time_distracted_min)
1632339874366:my_data <- tibble(cGPA, type_of_distractor, time_distracted_min)
1632339892518:knitr::opts_chunk$set(echo = TRUE)
1632339892536:library(tidyverse)
1632339892604:ages <- c(3,4,5)
1632339892649:sample(ages, 2)
1632339892697:time <- runif(n=600, min = 1, max = 10)
1632339892720:time
1632339895346:hist(time)
1632339895465:cGPA <- 4*rbeta(n=100, 4, 1)
1632339895504:hist(cGPA)
1632339895549:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339895584:time_distracted_min <- rpois(n, lambda=120)
1632339895606:hist(time_distracted_min)
1632339895682:my_data <- tibble(cGPA, type_of_distractor, time_distracted_min)
1632339995977:cGPA <- 4*rbeta(n=100, 4, 1)
1632339996012:hist(cGPA)
1632339996056:type_of_distractor <- sample(c("Texting", "Social Media", "Pets"),size=100, replace = TRUE)
1632339996094:time_distracted_min <- rpois(n, lambda=100)
1632339996117:hist(time_distracted_min)
1632339996194:my_data <- tibble(cGPA, type_of_distractor, time_distracted_min)
1632357797791:penguins <- read_csv("~/Sta302/penguins.csv")
1632357797998:head(penguins)
1632357804094:penguins <- read_csv("~/Sta302/penguins.csv")
1632357804171:glimpse(penguins)
1632357815216:penguins <- read.csv("~/Sta302/penguins.csv")
1632357815251:glimpse(penguins)
1632358109773:penguins <- read.csv("~/Sta302/penguins.csv")
1632358109805:glimpse(penguins)
1632358109879:penguins_new <- penguins %>% filter(penguins$bill_depth_mm && penguins$bill_length_mm)
1632358115295:penguins <- read.csv("~/Sta302/penguins.csv")
1632358115331:glimpse(penguins)
1632358115405:penguins_new <- penguins %>% filter(penguins$bill_depth_mm && penguins$bill_length_mm)
1632358115438:penguins_new
1632358123882:penguins <- read.csv("~/Sta302/penguins.csv")
1632358123922:glimpse(penguins)
1632358124011:penguins_new <- penguins %>% select(penguins$bill_depth_mm && penguins$bill_length_mm)
1632358129709:penguins <- read.csv("~/Sta302/penguins.csv")
1632358129738:glimpse(penguins)
1632358129808:penguins_new <- penguins %>% filter(penguins$bill_depth_mm && penguins$bill_length_mm)
1632358129840:penguins_new
1632358227437:penguins <- read.csv("~/Sta302/penguins.csv")
1632358227473:glimpse(penguins)
1632358227541:penguins_new <- penguins %>% filter(penguins$bill_depth_mm)
1632358235190:penguins <- read.csv("~/Sta302/penguins.csv")
1632358235225:glimpse(penguins)
1632358235301:penguins_new <- penguins %>% filter(penguins$bill_depth_mm)
1632358238820:# load dataset here
1632358238842:library(readr)
1632358238863:library(tidyverse)
1632358238884:library(ggplot2)
1632358238903:cleaning_sim <- read_csv("~/Sta302/cleaning_sim.csv")
1632358238954:head(cleaning_sim)
1632358239009:# find and print the mean and standard deviations here
1632358239029:crews_mean <- mean(cleaning_sim$Crews)
1632358239050:room_mean <- mean(cleaning_sim$Rooms)
1632358239070:crews_mean
1632358239103:room_mean
1632358239134:crews_std <- sd(cleaning_sim$Crews)
1632358239155:room_std <- sd(cleaning_sim$Rooms)
1632358239180:crews_std
1632358239210:room_std
1632358239251:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632358239270:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632358239291:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632358239361:boxplot1
1632358239731:boxplot2 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Rooms)) +
1632358239750:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632358239768:labs(y='Distribution of Rooms', title = "Boxplot of Rooms")
1632358239832:boxplot2
1632358240473:# add your plot code here
1632358240509:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632358240530:geom_point(color = 'blue') +
1632358240548:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632358240614:scatterplot1
1632358240938:# create your variable here
1632358240977:unique_crews <- unique(cleaning_sim$Crews)
1632358241005:unique_crews
1632358241103:# modify this code based on your variable names
1632358241144:ymeans <- NULL  # initialize your storage
1632358241163:for(i in unique_crews){
1632358241180:values <- cleaning_sim$Rooms[cleaning_sim$Crews==i]
1632358241199:ymeans <- c(ymeans, mean(values))
1632358241217:}
1632358241246:ymeans
1632358241350:# add previous plot code here
1632358241392:# add points using the code below and feel free to change the color and dot type
1632358241419:# (look up pch or points in the help file to see how)
1632358241489:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632358241514:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632358241594:points(ymeans~unique_crews, col="red", pch=19)
1632358241706:sorted <- sort(ymeans)
1632358241747:diffs <- NULL
1632358241765:for(i in 1:(length(sorted)-1)){
1632358241782:diffs <- c(diffs, sorted[i+1]-sorted[i])
1632358241799:}
1632358241832:diffs
1632358241927:# compute the mean here
1632358241955:mean(diffs)
1632358242029:# add your previous plot code here with the points added
1632358242075:# uncomment below and replace the words slope and intercept with the values abova
1632358242095:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632358242113:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632358242148:points(ymeans~unique_crews, col="red", pch=19)
1632358242171:abline(a = -0.61, b = 3.79, col= 'purple')
1632358242258:penguins <- read.csv("~/Sta302/penguins.csv")
1632358242296:glimpse(penguins)
1632358242367:penguins_new <- penguins %>% filter(penguins$bill_depth_mm)
1632358250445:penguins <- read.csv("~/Sta302/penguins.csv")
1632358250483:glimpse(penguins)
1632358250562:penguins_new <- penguins %>% select(penguins$bill_depth_mm)
1632358344043:penguins <- read.csv("~/Sta302/penguins.csv")
1632358344075:glimpse(penguins)
1632358344147:penguins_new <- penguins %>% select(penguins ,penguins$bill_depth_mm) %>%
1632358344166:filter(!is.na(penguins$bill_depth_mm))
1632358354772:penguins <- read.csv("~/Sta302/penguins.csv")
1632358354809:glimpse(penguins)
1632358354885:penguins_new <- penguins %>% select(penguins, penguins$bill_depth_mm) %>%
1632358354907:filter(!is.na(penguins$bill_depth_mm))
1632358375636:penguins <- read.csv("~/Sta302/penguins.csv")
1632358375673:glimpse(penguins)
1632358375748:penguins_new <- penguins %>% select(penguins, penguins$bill_depth_mm)
1632358388081:penguins <- read.csv("~/Sta302/penguins.csv")
1632358388118:glimpse(penguins)
1632358388189:penguins <- penguins %>% select(penguins, penguins$bill_depth_mm)
1632358399029:penguins <- read.csv("~/Sta302/penguins.csv")
1632358399068:glimpse(penguins)
1632358399173:select(penguins, penguins$bill_depth_mm)
1632358432430:penguins <- read.csv("~/Sta302/penguins.csv")
1632358432462:glimpse(penguins)
1632358432553:select(penguins, penguins$flipper_length_mm)
1632358448408:penguins <- read.csv("~/Sta302/penguins.csv")
1632358448440:glimpse(penguins)
1632358448508:select(penguins, penguins$flipper_length_mm)
1632358452927:penguins <- read.csv("~/Sta302/penguins.csv")
1632358452959:glimpse(penguins)
1632358453026:select(penguins, penguins$flipper_length_mm) %>%
1632358453044:filter(!is.na(penguins$flipper_length_mm))
1632358459857:penguins <- read.csv("~/Sta302/penguins.csv")
1632358459891:glimpse(penguins)
1632358459977:filter(!is.na(penguins$flipper_length_mm))
1632358475743:penguins <- read.csv("~/Sta302/penguins.csv")
1632358475773:glimpse(penguins)
1632358475852:penguins <- penguins %>%  filter(!is.na(penguins$flipper_length_mm))
1632358475885:penguins
1632358500752:penguins <- read.csv("~/Sta302/penguins.csv")
1632358500782:glimpse(penguins)
1632358500865:penguins <- penguins %>% select(penguins, penguins$flipper_length_mm) %>%
1632358500886:filter(!is.na(penguins$flipper_length_mm))
1632358519008:penguins <- read.csv("~/Sta302/penguins.csv")
1632358519038:glimpse(penguins)
1632358519106:penguins <- penguins %>% filter(!is.na(penguins$flipper_length_mm)) %>%
1632358519125:select(penguins, penguins$flipper_length_mm)
1632358555752:penguins <- read.csv("~/Sta302/penguins.csv")
1632358555782:glimpse(penguins)
1632358555856:penguins <- penguins %>% filter(!is.na(penguins$flipper_length_mm)) %>%
1632358555873:select(penguins$flipper_length_mm)
1632358564128:penguins <- read.csv("~/Sta302/penguins.csv")
1632358564162:glimpse(penguins)
1632358564237:penguins <- penguins %>% filter(!is.na(penguins$flipper_length_mm)) %>%
1632358564255:penguins
1632358569954:penguins <- read.csv("~/Sta302/penguins.csv")
1632358569986:glimpse(penguins)
1632358570058:penguins <- penguins %>% filter(!is.na(penguins$flipper_length_mm))
1632358570093:penguins
1632358586311:penguins <- read.csv("~/Sta302/penguins.csv")
1632358586341:penguins
1632358586412:penguins1 <- penguins %>% filter(!is.na(penguins$flipper_length_mm))
1632358586441:penguins1
1632358601238:penguins <- read.csv("~/Sta302/penguins.csv")
1632358601273:penguins
1632358601345:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358601378:penguins1
1632358779505:penguins <- read.csv("~/Sta302/penguins.csv")
1632358779540:penguins
1632358779612:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358779643:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358787376:penguins <- read.csv("~/Sta302/penguins.csv")
1632358787409:penguins
1632358787477:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358787505:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358787535:penguins1
1632358826912:penguins <- read.csv("~/Sta302/penguins.csv")
1632358826945:penguins
1632358827016:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358827050:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358827079:penguins1 <- penguins %>% filter(penguins$bill_depth_mm == 2009)
1632358833829:penguins <- read.csv("~/Sta302/penguins.csv")
1632358833860:penguins
1632358833936:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358833968:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358833997:penguins1 <- penguins %>% filter(penguins$bill_depth_mm == 2009)
1632358834026:penguins1
1632358849089:penguins <- read.csv("~/Sta302/penguins.csv")
1632358849119:penguins
1632358849191:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358849223:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358849260:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632358849292:penguins1
1632358877968:penguins <- read.csv("~/Sta302/penguins.csv")
1632358878003:penguins
1632358878077:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358878108:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358878138:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632358878170:penguins1 <- penguins %>% select(penguins$bill_length_mm)
1632358928862:penguins <- read.csv("~/Sta302/penguins.csv")
1632358928894:penguins
1632358928969:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358928999:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358929029:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632358929060:penguins1 <- penguins %>% select(bill_length_mm)
1632358929083:penguins1
1632358951585:penguins <- read.csv("~/Sta302/penguins.csv")
1632358951615:penguins
1632358951680:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358951710:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358951742:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632358951771:penguins1 <- penguins %>% select(bill_length_mm)
1632358951796:penguins1
1632358966514:penguins <- read.csv("~/Sta302/penguins.csv")
1632358966545:penguins
1632358966612:penguins1 <- penguins %>% select(bill_length_mm)
1632358966639:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358966670:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632358966699:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632358966731:penguins1
1632358972915:penguins1 <- penguins %>% select(bill_length_mm)
1632358976929:penguins1
1632358982138:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358985119:penguins1
1632358991473:penguins1 <- penguins %>% select(bill_length_mm)
1632358991506:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632358994393:penguins1
1632359016839:penguins1 <- penguins %>% select(bill_length_mm)
1632359016878:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359016906:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359016934:penguins1 <- penguins %>% filter(penguins$year == 2009)
1632359018963:penguins1
1632359050589:penguins <- read.csv("~/Sta302/penguins.csv")
1632359050625:penguins
1632359050700:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359050731:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359050762:penguins1 <- penguins %>% filter(penguins$year == 2009) %>%
1632359050780:select(bill_length_mm & bill_depth_mm)
1632359059091:penguins <- read.csv("~/Sta302/penguins.csv")
1632359059120:penguins
1632359059191:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359059226:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359059257:penguins1 <- penguins %>% filter(penguins$year == 2009) %>%
1632359059282:select(bill_length_mm && bill_depth_mm)
1632359089395:penguins <- read.csv("~/Sta302/penguins.csv")
1632359089427:penguins
1632359089502:penguins1 <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359089539:penguins1 <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359089571:penguins1 <- penguins %>% filter(penguins$year == 2009) %>%
1632359089591:select(bill_length_mm) %>% select(bill_depth_mm)
1632359110158:penguins <- read.csv("~/Sta302/penguins.csv")
1632359110192:penguins
1632359110266:penguins <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359110301:penguins <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359110335:penguins <- penguins %>% filter(penguins$year == 2009) %>%
1632359110354:select(bill_length_mm) %>% select(bill_depth_mm)
1632359128796:penguins <- read.csv("~/Sta302/penguins.csv")
1632359128830:penguins
1632359128903:penguins <- penguins %>% filter(!is.na(penguins$bill_length_mm))
1632359128934:penguins <- penguins %>% filter(!is.na(penguins$bill_depth_mm))
1632359128967:penguins <- penguins %>% filter(penguins$year == 2009) %>%
1632359128984:select(bill_length_mm) %>% select(bill_depth_mm)
1632359197262:penguins <- penguins %>%
1632359197277:select(bill_length_mm, bill_depth_mm)
1632359197298:penguins
1632359241429:penguins
1632359247608:penguins <- penguins %>%
1632359247632:select(bill_length_mm, bill_depth_mm) %>%
1632359247652:filter(!is.na(penguins$bill_length_mm)) %>%
1632359247669:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359247688:filter(penguins$year == 2009)
1632359268675:penguins <- penguins %>%
1632359268692:select(bill_length_mm, bill_depth_mm) %>%
1632359268709:filter(!is.na(penguins$bill_length_mm)) %>%
1632359268724:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359271741:penguins
1632359283300:penguins <- penguins %>%
1632359283315:select(bill_length_mm, bill_depth_mm) %>%
1632359283331:filter(!is.na(penguins$bill_length_mm)) %>%
1632359283349:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359289894:penguins
1632359308361:penguins <- penguins %>%
1632359308378:select(bill_length_mm, bill_depth_mm) %>%
1632359308393:filter(!is.na(penguins$bill_length_mm)) %>%
1632359308408:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359308423:filter(penguins$year == 2009)
1632359317316:penguins <- penguins %>%
1632359317332:select(bill_length_mm, bill_depth_mm) %>%
1632359317346:filter(!is.na(penguins$bill_length_mm))
1632359321786:penguins
1632359332119:penguins <- penguins %>%
1632359332133:select(bill_length_mm, bill_depth_mm) %>%
1632359332150:filter(!is.na(penguins$bill_length_mm)) %>%
1632359332168:filter(!is.na(penguins$bill_depth_mm))
1632359335687:penguins
1632359343267:penguins <- penguins %>%
1632359343283:select(bill_length_mm, bill_depth_mm) %>%
1632359343299:filter(!is.na(penguins$bill_length_mm)) %>%
1632359343313:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359343334:filter(penguins$year == 2009)
1632359361062:penguins <- penguins %>%
1632359361079:select(bill_length_mm, bill_depth_mm) %>%
1632359361092:filter(!is.na(penguins$bill_length_mm)) %>%
1632359361106:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359361122:filter(penguins$year == "2009")
1632359372254:penguins <- penguins %>%
1632359372271:select(bill_length_mm, bill_depth_mm) %>%
1632359372287:filter(!is.na(penguins$bill_length_mm)) %>%
1632359372303:filter(!is.na(penguins$bill_depth_mm))
1632359374121:penguins
1632359490671:penguins <- read.csv("~/Sta302/penguins.csv")
1632359490703:penguins
1632359490772:penguins <- penguins %>%
1632359490791:select(bill_length_mm, bill_depth_mm, year) %>%
1632359490809:filter(!is.na(penguins$bill_length_mm)) %>%
1632359490828:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359490846:filter(penguins$year == 2009)
1632359495648:penguins
1632359502493:penguins <- penguins %>%
1632359502507:select(bill_length_mm, bill_depth_mm, year) %>%
1632359502523:filter(!is.na(penguins$bill_length_mm)) %>%
1632359502538:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359502554:filter(penguins$year == 2009)
1632359507307:penguins <- penguins %>%
1632359507332:select(bill_length_mm, bill_depth_mm, year) %>%
1632359507351:filter(!is.na(penguins$bill_length_mm)) %>%
1632359507369:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359507387:filter(penguins$year == 2009)
1632359510764:filter(penguins$year == 2009)
1632359523248:penguins <- penguins %>%
1632359523264:select(bill_length_mm, bill_depth_mm, year)
1632359525261:penguins
1632359538685:penguins <- penguins %>%
1632359538703:select(bill_length_mm, bill_depth_mm, year) %>%
1632359538717:filter(penguins$year == 2009)
1632359541548:filter(!is.na(penguins$bill_length_mm)) %>%
1632359541562:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359541577:penguins
1632359547288:penguins <- penguins %>%
1632359547319:select(bill_length_mm, bill_depth_mm, year) %>%
1632359547333:filter(penguins$year == 2009)
1632359549855:penguins
1632359557923:penguins <- penguins %>%
1632359557938:select(bill_length_mm, bill_depth_mm, year) %>%
1632359557952:filter(penguins$year == 2009)
1632359557977:filter(!is.na(penguins$bill_length_mm)) %>%
1632359557992:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359558012:penguins
1632359562063:penguins <- penguins %>%
1632359562082:select(bill_length_mm, bill_depth_mm, year) %>%
1632359562096:filter(penguins$year == 2009)
1632359562122:filter(!is.na(penguins$bill_length_mm)) %>%
1632359562141:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359562172:penguins
1632359565253:penguins <- penguins %>%
1632359565268:select(bill_length_mm, bill_depth_mm, year) %>%
1632359565284:filter(penguins$year == 2009)
1632359566680:filter(!is.na(penguins$bill_length_mm)) %>%
1632359566695:filter(!is.na(penguins$bill_depth_mm)) %>%
1632359566710:penguins
1632359575182:penguins <- penguins %>%
1632359575195:select(bill_length_mm, bill_depth_mm, year) %>%
1632359575209:filter(penguins$year == 2009)
1632359575234:filter(!is.na(penguins$bill_length_mm)) %>%
1632359575250:filter(!is.na(penguins$bill_depth_mm))
1632359587364:penguins <- penguins %>%
1632359587379:select(bill_length_mm, bill_depth_mm, year) %>%
1632359587395:filter(penguins$year == 2009) %>%
1632359587412:filter(!is.na(penguins$bill_length_mm)) %>%
1632359587435:filter(!is.na(penguins$bill_depth_mm))
1632359593252:penguins <- penguins %>%
1632359593269:select(bill_length_mm, bill_depth_mm, year) %>%
1632359593284:filter(penguins$year == 2009)
1632359595074:penguins
1632359599297:penguins <- penguins %>%
1632359599324:select(bill_length_mm, bill_depth_mm, year) %>%
1632359599342:filter(penguins$year == 2009) %>%
1632359599356:filter(!is.na(penguins$bill_length_mm))
1632359601487:penguins
1632359630436:penguins <- penguins %>%
1632359630451:select(bill_length_mm, bill_depth_mm, year) %>%
1632359630467:filter(penguins$year == 2009) %>%
1632359630484:filter(!is.na(penguins$bill_length_mm)) %>%
1632359630499:filter(!is.na(penguins$bill_depth_mm))
1632359634152:penguins
1632359654180:penguins <- read.csv("~/Sta302/penguins.csv")
1632359654213:penguins
1632359654279:penguins_new <- penguins %>%
1632359654297:select(bill_length_mm, bill_depth_mm, year) %>%
1632359654316:filter(penguins$year == 2009) %>%
1632359654338:filter(!is.na(penguins$bill_length_mm)) %>%
1632359654354:filter(!is.na(penguins$bill_depth_mm))
1632359665557:penguins <- penguins %>%
1632359665572:select(bill_length_mm, bill_depth_mm, year) %>%
1632359665587:filter(penguins$year == 2009) %>%
1632359665603:filter(!is.na(penguins$bill_length_mm)) %>%
1632359665622:filter(!is.na(penguins$bill_depth_mm))
1632359676010:penguins <- penguins %>%
1632359676025:select(bill_length_mm, bill_depth_mm, year) %>%
1632359676042:filter(penguins$year == 2009) %>%
1632359676060:filter(!is.na(penguins$bill_length_mm)) %>%
1632359676076:filter(!is.na(penguins$bill_depth_mm))
1632359684829:penguins
1632359688794:penguins <- penguins %>%
1632359688812:select(bill_length_mm, bill_depth_mm, year) %>%
1632359688829:filter(penguins$year == 2009) %>%
1632359688844:filter(!is.na(penguins$bill_length_mm)) %>%
1632359688861:filter(!is.na(penguins$bill_depth_mm))
1632359694714:penguins
1632359699098:penguins <- penguins %>%
1632359699114:select(bill_length_mm, bill_depth_mm, year) %>%
1632359699133:filter(penguins$year == 2009) %>%
1632359699149:filter(!is.na(penguins$bill_length_mm))
1632359703988:penguins <- read.csv("~/Sta302/penguins.csv")
1632359704018:penguins
1632359704088:penguins <- penguins %>%
1632359704108:select(bill_length_mm, bill_depth_mm, year) %>%
1632359704127:filter(penguins$year == 2009) %>%
1632359704148:filter(!is.na(penguins$bill_length_mm)) %>%
1632359704168:filter(!is.na(penguins$bill_depth_mm))
1632359706900:# load dataset here
1632359706921:library(readr)
1632359706944:library(tidyverse)
1632359706963:library(ggplot2)
1632359706988:cleaning_sim <- read_csv("~/Sta302/cleaning_sim.csv")
1632359707033:head(cleaning_sim)
1632359707115:# find and print the mean and standard deviations here
1632359707139:crews_mean <- mean(cleaning_sim$Crews)
1632359707163:room_mean <- mean(cleaning_sim$Rooms)
1632359707185:crews_mean
1632359707214:room_mean
1632359707243:crews_std <- sd(cleaning_sim$Crews)
1632359707262:room_std <- sd(cleaning_sim$Rooms)
1632359707283:crews_std
1632359707310:room_std
1632359707348:boxplot1 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Crews)) +
1632359707365:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632359707385:labs(y='Distribution of Crew Members', title = "Boxplot of Crew Members")
1632359707441:boxplot1
1632359707583:boxplot2 <- cleaning_sim %>% ggplot(aes(y=cleaning_sim$Rooms)) +
1632359707604:geom_boxplot(color = 'blue', fill = 'lightblue') +
1632359707624:labs(y='Distribution of Rooms', title = "Boxplot of Rooms")
1632359707680:boxplot2
1632359708009:# add your plot code here
1632359708055:scatterplot1 <- cleaning_sim %>% ggplot(aes(x=cleaning_sim$Crews, y=cleaning_sim$Rooms)) +
1632359708078:geom_point(color = 'blue') +
1632359708098:labs(x= 'Crews', y='Rooms', title = "Scatterplot of Crew Members and Rooms")
1632359708152:scatterplot1
1632359708379:# create your variable here
1632359708414:unique_crews <- unique(cleaning_sim$Crews)
1632359708434:unique_crews
1632359708523:# modify this code based on your variable names
1632359708556:ymeans <- NULL  # initialize your storage
1632359708574:for(i in unique_crews){
1632359708597:values <- cleaning_sim$Rooms[cleaning_sim$Crews==i]
1632359708616:ymeans <- c(ymeans, mean(values))
1632359708637:}
1632359708669:ymeans
1632359708778:# add previous plot code here
1632359708820:# add points using the code below and feel free to change the color and dot type
1632359708839:# (look up pch or points in the help file to see how)
1632359708878:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632359708898:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632359708931:points(ymeans~unique_crews, col="red", pch=19)
1632359709030:sorted <- sort(ymeans)
1632359709071:diffs <- NULL
1632359709090:for(i in 1:(length(sorted)-1)){
1632359709106:diffs <- c(diffs, sorted[i+1]-sorted[i])
1632359709122:}
1632359709421:diffs
1632359709530:# compute the mean here
1632359709556:mean(diffs)
1632359709628:# add your previous plot code here with the points added
1632359709667:# uncomment below and replace the words slope and intercept with the values abova
1632359709690:plot(cleaning_sim$Crews, cleaning_sim$Rooms, main="Scatterplot of Crews and Rooms with red dots signifying their means",
1632359709717:xlab="Crews", ylab="Rooms", pch=19, col='lightblue')
1632359709748:points(ymeans~unique_crews, col="red", pch=19)
1632359709770:abline(a = -0.61, b = 3.79, col= 'purple')
1632359709865:penguins <- read.csv("~/Sta302/penguins.csv")
1632359709899:penguins
1632359709966:penguins <- penguins %>%
1632359709983:select(bill_length_mm, bill_depth_mm, year) %>%
1632359710002:filter(penguins$year == 2009) %>%
1632359710021:filter(!is.na(penguins$bill_length_mm)) %>%
1632359710041:filter(!is.na(penguins$bill_depth_mm))
1632359718646:penguins <- read.csv("~/Sta302/penguins.csv")
1632359718674:penguins
1632359718738:penguins <- penguins %>%
1632359718754:select(bill_length_mm, bill_depth_mm, year) %>%
1632359718772:filter(penguins$year == 2009) %>%
1632359718789:filter(!is.na(penguins$bill_length_mm)) %>%
1632359718810:filter(!is.na(penguins$bill_depth_mm))
1632359746647:penguins
1632359748355:penguins <- penguins %>%
1632359748371:select(year, bill_length_mm, bill_depth_mm) %>%
1632359748389:filter(penguins$year == 2009) %>%
1632359748409:filter(!is.na(penguins$bill_length_mm)) %>%
1632359748425:filter(!is.na(penguins$bill_depth_mm))
1632359751407:penguins
1632359755685:penguins <- penguins %>%
1632359760554:select(year, bill_length_mm, bill_depth_mm) %>%
1632359764268:filter(penguins$year == 2009) %>%
1632359768327:filter(!is.na(penguins$bill_length_mm)) %>%
1632359771190:filter(!is.na(penguins$bill_depth_mm))
1632359799802:penguins <- penguins %>%
1632359799830:select(year, bill_length_mm, bill_depth_mm) %>%
1632359799844:filter(penguins$year == 2009) %>%
1632359799862:filter(!is.na(penguins$bill_length_mm) && !is.na(penguins$bill_depth_mm))
1632359799888:penguins
1632359962669:penguins
1632359967784:penguins <- read.csv("~/Sta302/penguins.csv")
1632359967813:penguins
1632360181812:penguins <- read.csv("~/Sta302/penguins.csv")
1632360181841:penguins
1632360181914:penguins1 <- penguins %>%
1632360181932:select(year, bill_length_mm, bill_depth_mm) %>%
1632360181951:filter(penguins$year == 2009) %>%
1632360181969:filter(!is.na(penguins$bill_length_mm) && !is.na(penguins$bill_depth_mm))
1632360181997:penguins1
1632360203821:penguins <- read.csv("~/Sta302/penguins.csv")
1632360203851:penguins
1632360203926:penguins1 <- penguins %>%
1632360203945:select(year, bill_length_mm, bill_depth_mm) %>%
1632360203964:filter(penguins$year == 2009) %>%
1632360203987:filter(!is.na(penguins$bill_length_mm) && !is.na(penguins$bill_depth_mm))
1632360204017:penguins1
1632360204092:write.csv(penguins1, file=newpenguins.csv)
1632360217276:penguins <- read.csv("~/Sta302/penguins.csv")
1632360217308:penguins
1632360217386:penguins1 <- penguins %>%
1632360217404:select(year, bill_length_mm, bill_depth_mm) %>%
1632360217423:filter(penguins$year == 2009) %>%
1632360217442:filter(!is.na(penguins$bill_length_mm) && !is.na(penguins$bill_depth_mm))
1632360217472:penguins1
1632360217549:write.csv(penguins1, file="newpenguins.csv")
1632838581919:knitr::opts_chunk$set(echo = TRUE)
1632838582087:nyc <- read.csv(file="nyc.csv", header=T)
1632838595405:library(readr)
1632838595423:nyc <- read_csv("Sta302/nyc.csv")
1632838595934:View(nyc)
1632838613620:library(readr)
1632838613639:nyc <- read_csv("Sta302/nyc.csv")
1632838613759:View(nyc)
1632838618265:library(readr)
1632838618288:nyc <- read_csv("Sta302/nyc.csv")
1632838618369:View(nyc)
1632838647350:library(readr)
1632838647370:library(tidyverse)
1632838647392:nyc <- read_csv("Sta302/nyc.csv")
1632838647478:glimpse(nyc)
1633027820008:library(readr)
1633027820033:How_do_you_consume_music_ <- read_csv("Sta304/STA304-F21-Assignment1.git/How do you consume music?.csv")
1633027820574:View(How_do_you_consume_music_)
1633027842990:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027843030:library(readr)
1633027843049:How_do_you_consume_music <- read_csv("Sta304/STA304-F21-Assignment1.git/How do you consume music?.csv")
1633027859288:library(readr)
1633027859306:How_do_you_consume_music_ <- read_csv("Sta304/STA304-F21-Assignment1.git/How do you consume music?.csv")
1633027859431:View(How_do_you_consume_music_)
1633027868588:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027868628:library(readr)
1633027868681:How_do_you_consume_music_ <- read_csv("Sta304/STA304-F21-Assignment1.git/How do you consume music?.csv")
1633027889330:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027889368:library(readr)
1633027889387:How_do_you_consume_music_ <- read_csv("Sta304/How do you consume music?.csv")
1633027890829:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027890872:library(readr)
1633027890897:How_do_you_consume_music_ <- read_csv("Sta304/How do you consume music?.csv")
1633027909549:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027909586:library(readr)
1633027909609:How_do_you_consume_music_ <- read_csv("Sta304/How do you consume music?.csv")
1633027925625:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027925662:library(readr)
1633027925684:How_do_you_consume_music_ <- read.csv("Sta304/How do you consume music?.csv")
1633027934995:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027935033:library(readr)
1633027935055:How_do_you_consume_music_ <- read.csv("How do you consume music?.csv")
1633027953100:library(readr)
1633027953121:How_do_you_consume_music_ <- read_csv("Sta304/How do you consume music?.csv")
1633027953218:View(How_do_you_consume_music_)
1633027960795:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633027960848:library(readr)
1633027960873:How_do_you_consume_music_ <- read_csv("Sta304/How do you consume music?.csv")
1633028028862:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028028897:library(readr)
1633028028919:data <- read_csv("Sta304/How do you consume music?.csv")
1633028051215:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028051249:library(readr)
1633028051273:data <- read_csv("music.csv")
1633028067738:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028067775:library(readr)
1633028067796:data <- read_csv("music.csv")
1633028067908:glimpse(data)
1633028067993:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028079804:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028079845:library(readr)
1633028079870:library(tidyverse)
1633028079892:data <- read_csv("music.csv")
1633028080051:glimpse(data)
1633028080141:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028086600:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028086635:library(readr)
1633028086659:library(tidyverse)
1633028086680:data <- read_csv("music.csv")
1633028087089:glimpse(data)
1633028087181:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028097605:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028097648:library(readr)
1633028097672:library(tidyverse)
1633028097695:data <- read_csv("music.csv")
1633028097807:view(data)
1633028097859:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028103675:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028103712:library(readr)
1633028103733:library(tidyverse)
1633028103752:data <- read_csv("music.csv")
1633028103870:View(data)
1633028103907:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028743093:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028743132:library(readr)
1633028743155:library(tidyverse)
1633028743175:music <- read_csv("music.csv")
1633028743292:View(music)
1633028743330:hist(music$Do)
1633028751350:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028751388:library(readr)
1633028751414:library(tidyverse)
1633028751438:music <- read_csv("music.csv")
1633028751553:glimpse(music)
1633028751630:hist(music$Do)
1633028761408:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028761453:library(readr)
1633028761479:library(tidyverse)
1633028761502:music <- read_csv("music.csv")
1633028761615:head(music)
1633028761686:#hist(music$Do)
1633028761727:# You may need additional chunks, in case you want to include some of the cleaning output.
1633028808863:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028808895:library(readr)
1633028808917:library(tidyverse)
1633028808942:music <- read_csv("music.csv")
1633028809071:head(music)
1633028809306:hist(music$Where do you purchase your music from? (Select your most frequented retailer and streaming services do not apply))
1633028840131:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028840173:library(readr)
1633028840196:library(tidyverse)
1633028840218:music <- read_csv("music.csv")
1633028840322:head(music)
1633028840401:hist(music$Where_do_you_purchase_your_music_from? (Select your most frequented retailer and streaming services do not apply))
1633028890988:?ls
1633028900185:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633028900225:library(readr)
1633028900251:library(tidyverse)
1633028900276:music <- read_csv("music.csv")
1633028900378:head(music)
1633028900445:ls(music)
1633028900578:#hist(music$Where_do_you_purchase_your_music_from? (Select your most frequented retailer and streaming services do not apply))
1633028900622:# You may need additional chunks, in case you want to include some of the cleaning output.
1633029257612:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029257645:library(readr)
1633029257674:library(tidyverse)
1633029257694:music <- read_csv("music.csv")
1633029257805:head(music)
1633029257876:ls(music)
1633029257981:hist(music$"What is your primary way to discover new music from new artists? (Select one that best answers the question)")
1633029275910:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029275945:library(readr)
1633029275966:library(tidyverse)
1633029275989:music <- read_csv("music.csv")
1633029276102:head(music)
1633029276168:ls(music)
1633029276292:hist(music$[6])
1633029290397:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029290435:library(readr)
1633029290454:library(tidyverse)
1633029290474:music <- read_csv("music.csv")
1633029290592:head(music)
1633029290656:ls(music)
1633029290766:hist(music$"What is your primary way to discover new music from new artists? (Select one that best answers the question)")
1633029310172:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029310216:library(readr)
1633029310240:library(tidyverse)
1633029310265:music <- read_csv("music.csv")
1633029310369:head(music)
1633029310451:ls(music)
1633029310578:hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633029502461:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029502500:library(readr)
1633029502520:library(tidyverse)
1633029502541:music <- read_csv("music.csv")
1633029502642:glimpse(music)
1633029502733:ls(music)
1633029502882:hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633029936357:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633029936400:library(readr)
1633029936424:library(tidyverse)
1633029936446:music <- read_csv("music.csv")
1633029936572:glimpse(music)
1633029936660:ls(music)
1633029936772:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633029936812:# You may need additional chunks, in case you want to include some of the cleaning output.
1633113371638:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633113371672:library(readr)
1633113371689:library(tidyverse)
1633113371706:music <- read_csv("music.csv")
1633113372134:glimpse(music)
1633113372215:pie(music)
1633113811005:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633113811038:library(readr)
1633113811061:library(tidyverse)
1633113811082:music <- read_csv("music.csv")
1633113811223:glimpse(music)
1633113811291:slices <- c(18,3)
1633113811326:pie(slices)
1633113811456:#ls(music)
1633113811478:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633113811517:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114026479:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114026517:library(readr)
1633114026537:library(tidyverse)
1633114026562:music <- read_csv("music.csv")
1633114026649:glimpse(music)
1633114026729:slices <- c(18,3)
1633114026789:lbls <- c("A streaming service (Spotify, Apple Music, Pandora, Deezer, etc...)", "Personal recommendations from friends/family")
1633114026830:pie(slices, labels = lbls)
1633114026897:#ls(music)
1633114026920:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114026957:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114039326:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114039361:library(readr)
1633114039385:library(tidyverse)
1633114039411:music <- read_csv("music.csv")
1633114039513:glimpse(music)
1633114039599:slices <- c(18,3)
1633114039638:lbls <- c("A streaming service", "Personal recommendations from friends/family")
1633114039682:pie(slices, labels = lbls)
1633114039728:#ls(music)
1633114039753:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114039790:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114056454:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114056491:library(readr)
1633114056510:library(tidyverse)
1633114056529:music <- read_csv("music.csv")
1633114056617:glimpse(music)
1633114056701:slices <- c(18,3)
1633114056739:lbls <- c("A Streaming Service", "Personal recommendations \n from friends/family")
1633114056777:pie(slices, labels = lbls)
1633114056831:#ls(music)
1633114056852:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114056899:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114069303:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114069344:library(readr)
1633114069366:library(tidyverse)
1633114069390:music <- read_csv("music.csv")
1633114069479:glimpse(music)
1633114069562:slices <- c(18,3)
1633114069602:lbls <- c("A streaming service \n(Spotify, Apple Music, Pandora, Deezer, etc...)", "Personal recommendations from friends/family")
1633114069643:pie(slices, labels = lbls)
1633114069689:#ls(music)
1633114069710:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114069744:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114085181:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114085215:library(readr)
1633114085235:library(tidyverse)
1633114085254:music <- read_csv("music.csv")
1633114085339:glimpse(music)
1633114085416:slices <- c(18,3)
1633114085459:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, Deezer, etc...)", "Personal recommendations from friends/family")
1633114085503:pie(slices, labels = lbls)
1633114085558:#ls(music)
1633114085580:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114085624:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114093663:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114093698:library(readr)
1633114093717:library(tidyverse)
1633114093735:music <- read_csv("music.csv")
1633114093836:glimpse(music)
1633114093915:slices <- c(18,3)
1633114093951:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc...)", "Personal recommendations from friends/family")
1633114093998:pie(slices, labels = lbls)
1633114094045:#ls(music)
1633114094067:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114094104:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114101583:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114101626:library(readr)
1633114101648:library(tidyverse)
1633114101672:music <- read_csv("music.csv")
1633114101771:glimpse(music)
1633114101850:slices <- c(18,3)
1633114101888:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal recommendations from friends/family")
1633114101932:pie(slices, labels = lbls)
1633114101978:#ls(music)
1633114101997:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114102037:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114149288:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114149326:library(readr)
1633114149348:library(tidyverse)
1633114149368:music <- read_csv("music.csv")
1633114149464:glimpse(music)
1633114149535:slices <- c(18,3)
1633114149577:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal recommendations \nfrom friends/family")
1633114149615:pie(slices, labels = lbls)
1633114149658:#ls(music)
1633114149678:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114149714:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114163583:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114163624:library(readr)
1633114163643:library(tidyverse)
1633114163664:music <- read_csv("music.csv")
1633114163750:glimpse(music)
1633114163821:slices <- c(18,3)
1633114163858:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \n From Friends/Family")
1633114163896:pie(slices, labels = lbls)
1633114163941:#ls(music)
1633114163960:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114163994:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114169408:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114169439:library(readr)
1633114169460:library(tidyverse)
1633114169479:music <- read_csv("music.csv")
1633114169572:glimpse(music)
1633114169664:slices <- c(18,3)
1633114169705:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nFrom Friends/Family")
1633114169744:pie(slices, labels = lbls)
1633114169789:#ls(music)
1633114169809:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114169852:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114176038:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114176073:library(readr)
1633114176092:library(tidyverse)
1633114176113:music <- read_csv("music.csv")
1633114176204:glimpse(music)
1633114176286:slices <- c(18,3)
1633114176325:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114176360:pie(slices, labels = lbls)
1633114176409:#ls(music)
1633114176437:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114176472:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114442344:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114442373:library(readr)
1633114442392:library(tidyverse)
1633114442411:music <- read_csv("music.csv")
1633114442512:glimpse(music)
1633114442587:slices <- c(18,3)
1633114442629:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114442669:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? (Select one that best answers the question)")
1633114442757:#ls(music)
1633114442777:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114442815:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114455661:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114455697:library(readr)
1633114455718:library(tidyverse)
1633114455738:music <- read_csv("music.csv")
1633114455834:glimpse(music)
1633114455911:slices <- c(18,3)
1633114455961:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114455999:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114456055:#ls(music)
1633114456075:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114456110:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114664878:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114664911:library(readr)
1633114664933:library(tidyverse)
1633114664954:music <- read_csv("music.csv")
1633114665039:glimpse(music)
1633114665123:slices <- c(18,3)
1633114665166:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114665207:pie3d(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114670236:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114670272:library(readr)
1633114670294:library(tidyverse)
1633114670320:music <- read_csv("music.csv")
1633114670411:glimpse(music)
1633114670492:slices <- c(18,3)
1633114670532:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114670572:pie3D(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114674401:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114674443:library(readr)
1633114674465:library(tidyverse)
1633114674489:music <- read_csv("music.csv")
1633114674586:glimpse(music)
1633114674662:slices <- c(18,3)
1633114674702:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114674742:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114674788:#ls(music)
1633114674812:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114674852:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114804179:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114804215:library(readr)
1633114804232:library(tidyverse)
1633114804250:music <- read_csv("music.csv")
1633114804359:glimpse(music)
1633114804438:slices <- c(18,3)
1633114804473:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114804495:lbls <- paste(lbls, pct) # add percents to labels
1633114820422:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114820456:library(readr)
1633114820477:library(tidyverse)
1633114820496:music <- read_csv("music.csv")
1633114820594:glimpse(music)
1633114820670:slices <- c(18,3)
1633114820709:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.)", "Personal Recommendations \nfrom Friends/Family")
1633114820732:pct <- round(slices/sum(slices)*100)
1633114820758:lbls <- paste(lbls, pct) # add percents to labels
1633114820781:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114820826:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114820877:#ls(music)
1633114820897:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114820938:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114842696:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114842735:library(readr)
1633114842758:library(tidyverse)
1633114842781:music <- read_csv("music.csv")
1633114842867:glimpse(music)
1633114842949:slices <- c(18,3)
1633114843000:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family")
1633114843024:pct <- round(slices/sum(slices)*100)
1633114843049:lbls <- paste(lbls, pct) # add percents to labels
1633114843071:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114843111:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114843156:#ls(music)
1633114843175:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114843214:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114860457:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114860491:library(readr)
1633114860512:library(tidyverse)
1633114860534:music <- read_csv("music.csv")
1633114860629:glimpse(music)
1633114860704:slices <- c(18,3)
1633114860743:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family \n")
1633114860764:pct <- round(slices/sum(slices)*100)
1633114860786:lbls <- paste(lbls, pct) # add percents to labels
1633114860815:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114860852:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114860902:#ls(music)
1633114860925:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114860964:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114872060:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114872095:library(readr)
1633114872117:library(tidyverse)
1633114872140:music <- read_csv("music.csv")
1633114872229:glimpse(music)
1633114872314:slices <- c(18,3)
1633114872354:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114872376:pct <- round(slices/sum(slices)*100)
1633114872396:lbls <- paste(lbls, pct) # add percents to labels
1633114872418:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114872454:pie(slices, labels = lbls, main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114872501:#ls(music)
1633114872521:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114872555:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114911110:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114911143:library(readr)
1633114911162:library(tidyverse)
1633114911181:music <- read_csv("music.csv")
1633114911294:glimpse(music)
1633114911367:slices <- c(18,3)
1633114911412:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114911432:pct <- round(slices/sum(slices)*100)
1633114911453:lbls <- paste(lbls, pct) # add percents to labels
1633114911475:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114911514:pie(slices, labels = lbls, col= "rainbow" main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114919716:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114919751:library(readr)
1633114919771:library(tidyverse)
1633114919794:music <- read_csv("music.csv")
1633114919887:glimpse(music)
1633114919975:slices <- c(18,3)
1633114920010:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114920035:pct <- round(slices/sum(slices)*100)
1633114920055:lbls <- paste(lbls, pct) # add percents to labels
1633114920079:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114920113:pie(slices, labels = lbls, col= "rainbow", main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114935750:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114935793:library(readr)
1633114935815:library(tidyverse)
1633114935838:music <- read_csv("music.csv")
1633114935971:glimpse(music)
1633114936054:slices <- c(18,3)
1633114936093:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114936115:pct <- round(slices/sum(slices)*100)
1633114936138:lbls <- paste(lbls, pct) # add percents to labels
1633114936174:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114936216:pie(slices, labels = lbls, col= "blue, red", main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114949892:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114949932:library(readr)
1633114949953:library(tidyverse)
1633114949973:music <- read_csv("music.csv")
1633114950079:glimpse(music)
1633114950170:slices <- c(18,3)
1633114950222:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114950249:pct <- round(slices/sum(slices)*100)
1633114950275:lbls <- paste(lbls, pct) # add percents to labels
1633114950298:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114950334:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114950385:#ls(music)
1633114950406:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114950442:# You may need additional chunks, in case you want to include some of the cleaning output.
1633114958308:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633114958343:library(readr)
1633114958364:library(tidyverse)
1633114958385:music <- read_csv("music.csv")
1633114958489:glimpse(music)
1633114958563:slices <- c(18,3)
1633114958603:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633114958626:pct <- round(slices/sum(slices)*100)
1633114958647:lbls <- paste(lbls, pct) # add percents to labels
1633114958672:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633114958711:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633114958770:#ls(music)
1633114958797:#hist(music$as.numeric("What is your primary way to discover new music from new artists? (Select one that best answers the question)"))
1633114958837:# You may need additional chunks, in case you want to include some of the cleaning output.
1633116582651:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633116582683:library(readr)
1633116582703:library(tidyverse)
1633116582720:music <- read_csv("music.csv")
1633116582830:glimpse(music)
1633116582895:slices <- c(18,3)
1633116582931:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633116582954:pct <- round(slices/sum(slices)*100)
1633116582975:lbls <- paste(lbls, pct) # add percents to labels
1633116582998:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633116583039:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633116583090:# You may need additional chunks, in case you want to include some of the cleaning output.
1633116817440:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633116817475:library(readr)
1633116817494:library(tidyverse)
1633116817515:music <- read_csv("music.csv")
1633116817620:glimpse(music)
1633116817703:slices <- c(18,3)
1633116817744:lbls <- c("Streaming Services \n (Spotify, Apple Music, Pandora, etc.) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633116817768:pct <- round(slices/sum(slices)*100)
1633116817800:lbls <- paste(lbls, pct) # add percents to labels
1633116817823:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633116817862:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633116817912:# You may need additional chunks, in case you want to include some of the cleaning output.
1633124028654:glimpse(music)
1633124096924:view(music)
1633124111804:View(music)
1633124120461:head(music)
1633124253952:glimpse(music)
1633124601620:library(readr)
1633124601633:music <- read_csv("Sta304/STA304-F21-Assignment1.git/music.csv")
1633124601714:View(music)
1633124613183:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633124613223:library(readr)
1633124613246:music <- read_csv("Sta304/STA304-F21-Assignment1.git/music.csv")
1633124622818:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633124622858:library(readr)
1633124622877:music <- read.csv("music.csv")
1633124622915:View(music)
1633124622947:slices <- c(18,3)
1633124622984:lbls <- c("Streaming Services\n(Spotify, Apple Music, Deezer...) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633124623005:pct <- round(slices/sum(slices)*100)
1633124623031:lbls <- paste(lbls, pct) # add percents to labels
1633124623054:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633124623094:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633124623144:# You may need additional chunks, in case you want to include some of the cleaning output.
1633124631510:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633124631543:library(readr)
1633124631561:music <- read.csv("music.csv")
1633124631621:head(music)
1633124631774:slices <- c(18,3)
1633124631816:lbls <- c("Streaming Services\n(Spotify, Apple Music, Deezer...) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633124631837:pct <- round(slices/sum(slices)*100)
1633124631860:lbls <- paste(lbls, pct) # add percents to labels
1633124631883:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633124631923:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633124631975:# You may need additional chunks, in case you want to include some of the cleaning output.
1633124642104:#music <- musix %&% mutate(music, )
1633124642143:glimpse(music)
1633124669598:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1633124669619:library(openintro)
1633124669752:# Here you can load in (or simulate) and clean the data (you may need to do the cleaning in a separate R script - this is up to you).
1633124669791:library(readr)
1633124669810:library(tidyverse)
1633124669827:music <- read.csv("music.csv")
1633124669872:slices <- c(18,3)
1633124669918:lbls <- c("Streaming Services\n(Spotify, Apple Music, Deezer...) \n", "Personal Recommendations \nfrom Friends/Family\n")
1633124669969:pct <- round(slices/sum(slices)*100)
1633124669991:lbls <- paste(lbls, pct) # add percents to labels
1633124670010:lbls <- paste(lbls,"%",sep="") # ad % to labels
1633124670054:pie(slices, labels = lbls, col=rainbow(length(lbls)), main= "What is your primary way to discover new music from new artists? \n (Select one that best answers the question)")
1633124670105:# You may need additional chunks, in case you want to include some of the cleaning output.
1633124670227:# Use this to calculate some summary measures.
1633124670320:# Use this to create some plots.
1633124670396:# Here you can run a your HT/CIs.
1633124670436:# Here you can derive the CIs of interest.
1633124670530:#music <- musix %&% mutate(music, )
1633124670571:glimpse(music)
1633124673744:#music <- musix %&% mutate(music, )
1633124673785:glimpse(music)
1633125371334:# Use this to calculate some summary measures.
1633125371377:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125371402:mean_vol <- mean(vol)
1633125376435:# Use this to calculate some summary measures.
1633125376467:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125376491:mean_vol <- mean(vol)
1633125378853:# Use this to calculate some summary measures.
1633125378892:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125378915:mean_vol <- mean(vol)
1633125384113:# Use this to calculate some summary measures.
1633125384151:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125384174:mean_vol <- mean(vol)
1633125384198:mean_vol
1633125607324:# Use this to calculate some summary measures.
1633125607364:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125607385:mean_vol <- mean(vol)
1633125607405:mean_vol
1633125607433:sd_vol <- sd(vol)
1633125607452:sd_vol
1633125791487:# Use this to calculate some summary measures.
1633125791522:vol <- c(25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 75, 75, 75, 100, 100, 100, 100, 100, 100, 100)
1633125791543:mean_vol <- mean(vol)
1633125791561:mean_vol
1633125791592:sd_vol <- sd(vol)
1633125791614:sd_vol
1633126096538:# Here you can calculate your test stats, critical values, etc.
1633126096577:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1633126096613:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1633126328635:# Here you can run a your HT/CIs.
1633126328667:# Here you can derive the CIs of interest.
1633126328683:pnorm(-1.98)+ pnorm(1.98, lower.tail = FALSE)
1633126355167:# Here you can run a your HT/CIs.
1633126355204:# Here you can derive the CIs of interest.
1633126355224:pnorm(-5.12363)+ pnorm(5.12363, lower.tail = FALSE)
1633126496539:# Here you can calculate your CIs, run a bootstrap, etc.
1633126496588:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1633126496637:femalepop %>%
1633126496656:summarise(
1633126496676:mean_pop = mean(Population),
1633126496696:sd_pop = sd(Population),
1633126496716:n_cal = n())
1633126500545:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1633126500564:library(openintro)
1633126500583:library(tidyverse)
1633126500602:library(dplyr)
1633126500639:fertility <- read_csv("Fertility.csv")
1633126500793:femalepop <- read_csv("FemalePopulation.csv")
1633126500967:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1633126501007:# You may need additional chunks, in case you want to include some of the cleaning output.
1633126501047:fertility <- fertility %>%
1633126501068:select(`Data Source` ,X63) %>%
1633126501091:filter(!is.na(X63)) %>%
1633126501114:rename(Country = `Data Source`)%>%
1633126501135:rename(Fertility_Rate = X63) %>%
1633126501156:filter(Country != "Country Name") %>%
1633126501178:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1633126509738:# Here you can calculate your CIs, run a bootstrap, etc.
1633126509789:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1633126509840:femalepop %>%
1633126509861:summarise(
1633126509879:mean_pop = mean(Population),
1633126509902:sd_pop = sd(Population),
1633126509922:n_cal = n())
1633126512900:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1633126512919:library(openintro)
1633126512938:library(tidyverse)
1633126512961:library(dplyr)
1633126513010:fertility <- read_csv("Fertility.csv")
1633126513142:femalepop <- read_csv("FemalePopulation.csv")
1633126513291:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1633126513336:# You may need additional chunks, in case you want to include some of the cleaning output.
1633126513376:fertility <- fertility %>%
1633126513394:select(`Data Source` ,X63) %>%
1633126513413:filter(!is.na(X63)) %>%
1633126513432:rename(Country = `Data Source`)%>%
1633126513452:rename(Fertility_Rate = X63) %>%
1633126513473:filter(Country != "Country Name") %>%
1633126513498:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1633126521609:fertility <- read_csv("Fertility.csv")
1633126521720:femalepop <- read_csv("FemalePopulation.csv")
1633126527833:# Here you can calculate your CIs, run a bootstrap, etc.
1633126527882:# (maybe you want to use the MLE to find the CI or your test stat. That sounds like a good way to order the analysis... I don't know, just spit balling here.)
1633126527932:femalepop %>%
1633126527953:summarise(
1633126527977:mean_pop = mean(Population),
1633126527998:sd_pop = sd(Population),
1633126528021:n_cal = n())
1633126569252:# Here you can run a your HT/CIs.
1633126569284:# Here you can derive the CIs of interest.
1633126569306:pnorm(-5.12363)+ pnorm(5.12363, lower.tail = FALSE)
1633126569350:22017735+ qnorm(0.975)*(79062105/sqrt(195))
1633126569379:22017735- qnorm(0.975)*(79062105/sqrt(195))
1633126656893:# Here you can run a your HT/CIs.
1633126656932:# Here you can derive the CIs of interest.
1633126656953:pnorm(-5.12363)+ pnorm(5.12363, lower.tail = FALSE)
1633126656995:0.75+ qnorm(0.975)*(0.2236/sqrt(21))
1633126657027:0.75- qnorm(0.975)*(0.2236/sqrt(21))
1633443096033:nyc <- read.csv(file="nyc.csv", header=T)
1633443099805:model <- lm(Price ~ Food + Decor + Service + East, data=nyc)
1633443099892:model
1633443379141:summary(model)
1633443527120:output <- summary(model)
1633443527169:output$coefficients
1633443527315:# To extract just the coefficients in a vector:
1633443527336:model$coefficients
1633443527408:coef(model)
1633443527469:output$coefficients[,1]
1633443527554:# To extract the estimated standard errors of the coefficients:
1633443527576:output$coefficients[,2]
1633443527662:# To extract the fitted values from the model
1633443527685:# these are your y-hat values (plugging in the predictor values
1633443527707:# for each observations into the model and getting the conditional mean estimate)
1633443527729:yhat <- fitted(model)
1633443527754:head(yhat)
1633443527852:yhat <- model$fitted.values
1633443527872:head(yhat)
1633443527950:# To extract the residuals from the model
1633443527967:e <- residuals(model)
1633443527991:head(e)
1633443528087:e <- model$residuals
1633443528106:head(e)
1633443528184:# To extract the estimated error variance
1633443528200:output$sigma     # this actually gives the square root of the estimate
1633443528231:output$sigma^2
1634657342032:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634657342075:# You may need additional chunks.
1634657342108:# I would recommend not including any of the Cleaning process output here.
1634657342149:# get package
1634657342170:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634657349598:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634657349632:# You may need additional chunks.
1634657349667:# I would recommend not including any of the Cleaning process output here.
1634657349724:# get package
1634657349743:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634657357844:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634657357884:# You may need additional chunks.
1634657357922:# I would recommend not including any of the Cleaning process output here.
1634657357957:# get package
1634657357974:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634657361933:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1634657361979:library(openintro)
1634657362059:library(opendatatoronto)
1634657362090:library(dplyr)
1634657362111:library(patchwork)
1634657362172:library(tidyverse)
1634657378823:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634657378858:# You may need additional chunks.
1634657378892:# I would recommend not including any of the Cleaning process output here.
1634657378931:# get package
1634657378950:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634657379398:package
1634657379466:# get all resources for this package
1634657379489:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634657379582:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634657379604:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634657379677:# load the first datastore resource as a sample
1634657379698:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634657381530:data
1634676567371:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1634676567407:library(openintro)
1634676567482:library(opendatatoronto)
1634676590830:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1634676590870:library(openintro)
1634676590895:library(opendatatoronto)
1634676590926:library(dplyr)
1634676590947:library(patchwork)
1634676591002:library(tidyverse)
1634676591069:set.seed(899)
1634676591105:mse1 = numeric(10)
1634676591128:mse2 = numeric(10)
1634676591160:for(i in 1:100){
1634676591181:sigma_sq = i
1634676591200:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676591220:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676591252:n <- 100
1634676591273:M <- 1000
1634676591324:sim <- list(
1634676591346:T1 = numeric(M),
1634676591366:T2 = numeric(M)
1634676591386:)
1634676591405:for (j in 1:M) {
1634676591423:# Sample from Normal
1634676591442:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676591464:# Record the values of the two estimators:
1634676591484:sim$T1[j] <- T1(thesample)
1634676591504:sim$T2[j] <- T2(thesample)
1634676591527:}
1634676591566:#MSE
1634676591586:MSE_T1 <- var(sim$T1) + (mean(sim$T1) - sigma_sq)^2
1634676591619:MSE_T2 <- var(sim$T2) + (mean(sim$T2) - sigma_sq)^2
1634676591675:mse1[i] = MSE_T1
1634676591707:mse2[i] = MSE_T2
1634676591724:}
1634676594121:## Create your plots below. (I recommend using ggplot)
1634676594163:leftplot <- tibble(T1 = mse1) %>%
1634676594184:ggplot(aes(x = T1)) +
1634676594204:theme_classic() +
1634676594227:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634676594245:theme(plot.title = element_text(size=8))+
1634676594264:xlab("MSE of estimator T1")+
1634676594284:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676594600:rightplot <- tibble(T2 = mse2) %>%
1634676594619:ggplot(aes(x = T2)) +
1634676594640:theme_classic() +
1634676594671:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634676594693:theme(plot.title = element_text(size=8))+
1634676594712:xlab("MSE of estimator T2")+
1634676594732:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676595008:leftplot | rightplot
1634676595541:set.seed(899)
1634676595572:bias1 = numeric(10)
1634676595596:bias2 = numeric(10)
1634676595633:for(a in 1:100){
1634676595654:sigma_sq = a
1634676595673:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676595693:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676595732:n <- 100
1634676595759:M <- 1000
1634676595812:sim <- list(
1634676595839:T1 = numeric(M),
1634676595857:T2 = numeric(M)
1634676595878:)
1634676595898:for (b in 1:M) {
1634676595919:# Sample from Normal
1634676595939:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676595956:# Record the values of the two estimators:
1634676595981:sim$T1[b] <- T1(thesample)
1634676596002:sim$T2[b] <- T2(thesample)
1634676596023:}
1634676596064:#Bias
1634676596102:Bias_T1 <- mean(sim$T1) - sigma_sq
1634676596128:Bias_T2 <- mean(sim$T2) - sigma_sq
1634676596168:bias1[a] = Bias_T1
1634676596187:bias2[a] = Bias_T2
1634676596212:}
1634676598563:leftplotbias <- tibble(T1 = bias1) %>%
1634676598596:ggplot(aes(x = bias1)) +
1634676598621:theme_classic() +
1634676598644:ggtitle("Histogram of bias for multiple sigma squared values")+
1634676598663:theme(plot.title = element_text(size=8))+
1634676598684:xlab("Bias of estimator T1")+
1634676598706:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676598979:rightplotbias <- tibble(T2 = bias2) %>%
1634676598997:ggplot(aes(x = bias2)) +
1634676599016:theme_classic() +
1634676599036:ggtitle("Histogram of bias for multiple sigma squared values")+
1634676599059:theme(plot.title = element_text(size=8))+
1634676599081:xlab("Bias of estimator T2")+
1634676599104:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676599367:leftplotbias | rightplotbias
1634676599714:set.seed(899)
1634676599742:var1 = numeric(10)
1634676599764:var2 = numeric(10)
1634676599797:for(c in 1:100){
1634676599815:sigma_sq = c
1634676599837:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676599858:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676599898:n <- 100
1634676599919:M <- 1000
1634676599966:sim <- list(
1634676599986:T1 = numeric(M),
1634676600020:T2 = numeric(M)
1634676600036:)
1634676600055:for (d in 1:M) {
1634676600072:# Sample from Normal
1634676600087:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676600103:# Record the values of the two estimators:
1634676600118:sim$T1[d] <- T1(thesample)
1634676600135:sim$T2[d] <- T2(thesample)
1634676600150:}
1634676600181:#Bias
1634676600212:Var_T1 <- var(sim$T1)
1634676600229:Var_T2 <- var(sim$T2)
1634676600259:var1[c] = Var_T1
1634676600281:var2[c] = Var_T2
1634676600302:}
1634676602399:leftplotvar <- tibble(T1 = var1) %>%
1634676602435:ggplot(aes(x = var1)) +
1634676602456:theme_classic() +
1634676602473:xlab("Variance of estimator T1")+
1634676602491:ggtitle("Histogram of variance for multiple sigma squared values")+
1634676602510:theme(plot.title = element_text(size=7))+
1634676602531:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676602804:rightplotvar <- tibble(T2 = var2) %>%
1634676602823:ggplot(aes(x = var2)) +
1634676602845:theme_classic() +
1634676602868:ggtitle("Histogram of variance for multiple sigma squared values")+
1634676602892:theme(plot.title = element_text(size=7))+
1634676602924:xlab("Variance of estimator T2")+
1634676602964:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676603232:leftplotvar | rightplotvar
1634676603611:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634676603649:# You may need additional chunks.
1634676603684:# I would recommend not including any of the Cleaning process output here.
1634676603724:# get package
1634676603745:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634676604144:package
1634676604219:# get all resources for this package
1634676604237:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634676604308:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634676604331:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634676604379:# load the first datastore resource as a sample
1634676604400:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634676606095:data
1634676606290:data %>%
1634676606319:ggplot(aes(x = Population, y=AutoTheft_AVG))+
1634676606341:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1634676606365:theme(plot.title = element_text(size=12))+
1634676606386:geom_point(col = "blue")
1634676652922:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1634676652955:library(openintro)
1634676652975:library(opendatatoronto)
1634676652998:library(dplyr)
1634676653021:library(patchwork)
1634676653043:library(tidyverse)
1634676653090:set.seed(899)
1634676653115:mse1 = numeric(10)
1634676653133:mse2 = numeric(10)
1634676653167:for(i in 1:100){
1634676653185:sigma_sq = i
1634676653203:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676653221:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676653253:n <- 100
1634676653273:M <- 1000
1634676653333:sim <- list(
1634676653351:T1 = numeric(M),
1634676653385:T2 = numeric(M)
1634676653404:)
1634676653421:for (j in 1:M) {
1634676653442:# Sample from Normal
1634676653463:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676653483:# Record the values of the two estimators:
1634676653501:sim$T1[j] <- T1(thesample)
1634676653520:sim$T2[j] <- T2(thesample)
1634676653541:}
1634676653569:#MSE
1634676653586:MSE_T1 <- var(sim$T1) + (mean(sim$T1) - sigma_sq)^2
1634676653606:MSE_T2 <- var(sim$T2) + (mean(sim$T2) - sigma_sq)^2
1634676653640:mse1[i] = MSE_T1
1634676653659:mse2[i] = MSE_T2
1634676653678:}
1634676655845:## Create your plots below. (I recommend using ggplot)
1634676655887:leftplot <- tibble(T1 = mse1) %>%
1634676655903:ggplot(aes(x = T1)) +
1634676655924:theme_classic() +
1634676655944:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634676655963:theme(plot.title = element_text(size=8))+
1634676655981:xlab("MSE of estimator T1")+
1634676656000:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676656272:rightplot <- tibble(T2 = mse2) %>%
1634676656293:ggplot(aes(x = T2)) +
1634676656312:theme_classic() +
1634676656331:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634676656350:theme(plot.title = element_text(size=8))+
1634676656367:xlab("MSE of estimator T2")+
1634676656385:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676656677:leftplot | rightplot
1634676657065:set.seed(899)
1634676657100:bias1 = numeric(10)
1634676657131:bias2 = numeric(10)
1634676657189:for(a in 1:100){
1634676657239:sigma_sq = a
1634676657268:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676657299:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676657355:n <- 100
1634676657392:M <- 1000
1634676657470:sim <- list(
1634676657520:T1 = numeric(M),
1634676657552:T2 = numeric(M)
1634676657577:)
1634676657618:for (b in 1:M) {
1634676657646:# Sample from Normal
1634676657681:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676657725:# Record the values of the two estimators:
1634676657750:sim$T1[b] <- T1(thesample)
1634676657776:sim$T2[b] <- T2(thesample)
1634676657808:}
1634676657859:#Bias
1634676657911:Bias_T1 <- mean(sim$T1) - sigma_sq
1634676657967:Bias_T2 <- mean(sim$T2) - sigma_sq
1634676658056:bias1[a] = Bias_T1
1634676658099:bias2[a] = Bias_T2
1634676658138:}
1634676660388:leftplotbias <- tibble(T1 = bias1) %>%
1634676660436:ggplot(aes(x = bias1)) +
1634676660481:theme_classic() +
1634676660535:ggtitle("Histogram of bias for multiple sigma squared values")+
1634676660571:theme(plot.title = element_text(size=8))+
1634676660611:xlab("Bias of estimator T1")+
1634676660646:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676660941:rightplotbias <- tibble(T2 = bias2) %>%
1634676660977:ggplot(aes(x = bias2)) +
1634676661012:theme_classic() +
1634676661047:ggtitle("Histogram of bias for multiple sigma squared values")+
1634676661090:theme(plot.title = element_text(size=8))+
1634676661128:xlab("Bias of estimator T2")+
1634676661162:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676661450:leftplotbias | rightplotbias
1634676661832:set.seed(899)
1634676661891:var1 = numeric(10)
1634676661924:var2 = numeric(10)
1634676661992:for(c in 1:100){
1634676662039:sigma_sq = c
1634676662089:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634676662117:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634676662173:n <- 100
1634676662203:M <- 1000
1634676662274:sim <- list(
1634676662303:T1 = numeric(M),
1634676662339:T2 = numeric(M)
1634676662380:)
1634676662426:for (d in 1:M) {
1634676662459:# Sample from Normal
1634676662499:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634676662531:# Record the values of the two estimators:
1634676662562:sim$T1[d] <- T1(thesample)
1634676662601:sim$T2[d] <- T2(thesample)
1634676662627:}
1634676662709:#Bias
1634676662770:Var_T1 <- var(sim$T1)
1634676662794:Var_T2 <- var(sim$T2)
1634676662839:var1[c] = Var_T1
1634676662899:var2[c] = Var_T2
1634676662923:}
1634676665089:leftplotvar <- tibble(T1 = var1) %>%
1634676665112:ggplot(aes(x = var1)) +
1634676665130:theme_classic() +
1634676665150:xlab("Variance of estimator T1")+
1634676665170:ggtitle("Histogram of variance for multiple sigma squared values")+
1634676665191:theme(plot.title = element_text(size=7))+
1634676665212:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676665490:rightplotvar <- tibble(T2 = var2) %>%
1634676665507:ggplot(aes(x = var2)) +
1634676665527:theme_classic() +
1634676665544:ggtitle("Histogram of variance for multiple sigma squared values")+
1634676665562:theme(plot.title = element_text(size=7))+
1634676665583:xlab("Variance of estimator T2")+
1634676665603:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634676665903:leftplotvar | rightplotvar
1634676666271:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634676666320:# You may need additional chunks.
1634676666357:# I would recommend not including any of the Cleaning process output here.
1634676666394:# get package
1634676666419:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634676666489:package
1634676666548:# get all resources for this package
1634676666566:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634676666628:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634676666648:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634676666694:# load the first datastore resource as a sample
1634676666710:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634676668028:data
1634676668232:data %>%
1634676668260:ggplot(aes(x = Population, y=AutoTheft_AVG))+
1634676668284:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1634676668304:theme(plot.title = element_text(size=12))+
1634676668325:geom_point(col = "blue")
1634676730779:data %>%
1634676730798:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_AVG))+
1634676730819:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1634676730842:theme(plot.title = element_text(size=12))+
1634676730859:geom_point(col = "blue")
1634687931696:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1634687931729:library(openintro)
1634687931834:library(opendatatoronto)
1634687931861:library(dplyr)
1634687931883:library(patchwork)
1634687931941:library(tidyverse)
1634687932065:set.seed(899)
1634687932086:mse1 = numeric(10)
1634687932105:mse2 = numeric(10)
1634687932139:for(i in 1:100){
1634687932156:sigma_sq = i
1634687932175:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634687932194:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634687932229:n <- 100
1634687932246:M <- 1000
1634687932296:sim <- list(
1634687932315:T1 = numeric(M),
1634687932333:T2 = numeric(M)
1634687932350:)
1634687932379:for (j in 1:M) {
1634687932400:# Sample from Normal
1634687932427:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634687932447:# Record the values of the two estimators:
1634687932468:sim$T1[j] <- T1(thesample)
1634687932488:sim$T2[j] <- T2(thesample)
1634687932511:}
1634687932549:#MSE
1634687932570:MSE_T1 <- var(sim$T1) + (mean(sim$T1) - sigma_sq)^2
1634687932592:MSE_T2 <- var(sim$T2) + (mean(sim$T2) - sigma_sq)^2
1634687932633:mse1[i] = MSE_T1
1634687932652:mse2[i] = MSE_T2
1634687932672:}
1634687935114:## Create your plots below. (I recommend using ggplot)
1634687935156:leftplot <- tibble(T1 = mse1) %>%
1634687935174:ggplot(aes(x = T1)) +
1634687935195:theme_classic() +
1634687935216:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634687935241:theme(plot.title = element_text(size=8))+
1634687935265:xlab("MSE of estimator T1")+
1634687935285:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687935577:rightplot <- tibble(T2 = mse2) %>%
1634687935595:ggplot(aes(x = T2)) +
1634687935615:theme_classic() +
1634687935637:ggtitle("Histogram of MSE for multiple sigma squared values")+
1634687935660:theme(plot.title = element_text(size=8))+
1634687935682:xlab("MSE of estimator T2")+
1634687935703:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687935986:leftplot | rightplot
1634687936518:set.seed(899)
1634687936544:bias1 = numeric(10)
1634687936567:bias2 = numeric(10)
1634687936605:for(a in 1:100){
1634687936627:sigma_sq = a
1634687936648:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634687936670:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634687936704:n <- 100
1634687936722:M <- 1000
1634687936774:sim <- list(
1634687936795:T1 = numeric(M),
1634687936815:T2 = numeric(M)
1634687936835:)
1634687936859:for (b in 1:M) {
1634687936882:# Sample from Normal
1634687936904:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634687936923:# Record the values of the two estimators:
1634687936946:sim$T1[b] <- T1(thesample)
1634687936966:sim$T2[b] <- T2(thesample)
1634687936983:}
1634687937020:#Bias
1634687937056:Bias_T1 <- mean(sim$T1) - sigma_sq
1634687937076:Bias_T2 <- mean(sim$T2) - sigma_sq
1634687937110:bias1[a] = Bias_T1
1634687937127:bias2[a] = Bias_T2
1634687937152:}
1634687939459:leftplotbias <- tibble(T1 = bias1) %>%
1634687939488:ggplot(aes(x = bias1)) +
1634687939508:theme_classic() +
1634687939534:ggtitle("Histogram of bias for multiple sigma squared values")+
1634687939557:theme(plot.title = element_text(size=8))+
1634687939577:xlab("Bias of estimator T1")+
1634687939599:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687939881:rightplotbias <- tibble(T2 = bias2) %>%
1634687939902:ggplot(aes(x = bias2)) +
1634687939929:theme_classic() +
1634687939953:ggtitle("Histogram of bias for multiple sigma squared values")+
1634687939976:theme(plot.title = element_text(size=8))+
1634687939997:xlab("Bias of estimator T2")+
1634687940014:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687940284:leftplotbias | rightplotbias
1634687940624:set.seed(899)
1634687940652:var1 = numeric(10)
1634687940675:var2 = numeric(10)
1634687940714:for(c in 1:100){
1634687940737:sigma_sq = c
1634687940759:T1 <- function(x) (1/(n-1)) * ((sum(x-mean(x)^2)))
1634687940781:T2 <- function(x) (1/n) * (sum(x-mean(x)^2))
1634687940822:n <- 100
1634687940844:M <- 1000
1634687940914:sim <- list(
1634687940932:T1 = numeric(M),
1634687940950:T2 = numeric(M)
1634687940973:)
1634687940993:for (d in 1:M) {
1634687941016:# Sample from Normal
1634687941038:thesample <- rnorm(n, mean=0, sd=sqrt(sigma_sq))
1634687941058:# Record the values of the two estimators:
1634687941080:sim$T1[d] <- T1(thesample)
1634687941098:sim$T2[d] <- T2(thesample)
1634687941115:}
1634687941151:#Bias
1634687941189:Var_T1 <- var(sim$T1)
1634687941205:Var_T2 <- var(sim$T2)
1634687941238:var1[c] = Var_T1
1634687941258:var2[c] = Var_T2
1634687941279:}
1634687943394:leftplotvar <- tibble(T1 = var1) %>%
1634687943422:ggplot(aes(x = var1)) +
1634687943445:theme_classic() +
1634687943469:xlab("Variance of estimator T1")+
1634687943493:ggtitle("Histogram of variance for multiple sigma squared values")+
1634687943516:theme(plot.title = element_text(size=7))+
1634687943541:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687943835:rightplotvar <- tibble(T2 = var2) %>%
1634687943854:ggplot(aes(x = var2)) +
1634687943874:theme_classic() +
1634687943893:ggtitle("Histogram of variance for multiple sigma squared values")+
1634687943914:theme(plot.title = element_text(size=7))+
1634687943934:xlab("Variance of estimator T2")+
1634687943952:geom_histogram(aes(y = ..count..),bins = 15,colour = "black",fill = "light blue")
1634687944215:leftplotvar | rightplotvar
1634687944581:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634687944622:# You may need additional chunks.
1634687944663:# I would recommend not including any of the Cleaning process output here.
1634687944701:# get package
1634687944724:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634687945139:package
1634687945203:# get all resources for this package
1634687945226:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634687945307:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634687945330:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634687945384:# load the first datastore resource as a sample
1634687945409:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634687947014:data
1634687947212:data %>%
1634687947239:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_Rate2020))+
1634687947258:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1634687947279:theme(plot.title = element_text(size=12))+
1634687947304:geom_point(col = "blue")
1634687947551:# Here you can run a linear regression on your two variables of interest.
1634687947593:lm(AutoTheft_AVG ~ Population, data = data)
1634687984718:# Here you can run a linear regression on your two variables of interest.
1634687984750:lm(AutoTheft_Rate2020 ~ F2020_Population_Projection, data = data)
1634688005843:# Here you can run a linear regression on your two variables of interest.
1634688005880:lm(AutoTheft_Rate2019 ~ F2020_Population_Projection, data = data)
1634688011345:# Here you can run a linear regression on your two variables of interest.
1634688011384:lm(AutoTheft_Rate2018 ~ F2020_Population_Projection, data = data)
1634688017847:# Here you can run a linear regression on your two variables of interest.
1634688017885:lm(AutoTheft_Rate2020 ~ F2020_Population_Projection, data = data)
1634744541107:knitr::opts_chunk$set(echo = TRUE)
1634744541135:library(openintro)
1634744541221:library(opendatatoronto)
1634744565236:knitr::opts_chunk$set(echo = TRUE)
1634744565256:library(openintro)
1634744565275:library(opendatatoronto)
1634744565312:library(dplyr)
1634744565331:library(patchwork)
1634744565389:library(tidyverse)
1634744569320:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634744569359:# You may need additional chunks.
1634744569395:# I would recommend not including any of the Cleaning process output here.
1634744569437:# get package
1634744569456:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634744569854:package
1634744569925:# get all resources for this package
1634744569944:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634744570031:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634744570050:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634744570104:# load the first datastore resource as a sample
1634744570122:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634744572384:data
1634745546320:summary(data$F2020_Population_Projection)
1634745546397:summary(data$AutoTheft_Rate2020)
1634745664327:summary(data$F2020_Population_Projection)
1634745664423:sqrt(var(data$F2020_Population_Projection))
1634745664461:summary(data$AutoTheft_Rate2020)
1634745664555:sqrt(var(data$AutoTheft_Rate2020))
1634745751997:knitr::opts_chunk$set(echo = TRUE)
1634745752026:library(openintro)
1634745752045:library(opendatatoronto)
1634745752064:library(dplyr)
1634745752083:library(patchwork)
1634745752101:library(tidyverse)
1634746627400:summary(data$F2020_Population_Projection)
1634746627473:sqrt(var(data$F2020_Population_Projection))
1634746627507:sqrt(var(data$AutoTheft_Rate2020))
1634746627541:summary(data$AutoTheft_Rate2020)
1634747968282:knitr::opts_chunk$set(echo = TRUE)
1634747968330:library(openintro)
1634747968351:library(opendatatoronto)
1634747968373:library(dplyr)
1634747968396:library(patchwork)
1634747968419:library(tidyverse)
1634747968498:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634747968573:# You may need additional chunks.
1634747968614:# I would recommend not including any of the Cleaning process output here.
1634747968650:# get package
1634747968667:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634747968943:package
1634747969009:# get all resources for this package
1634747969026:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634747969132:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634747969154:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634747969200:# load the first datastore resource as a sample
1634747969221:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634747971356:data
1634747971576:summary(data$F2020_Population_Projection)
1634747971660:sqrt(var(data$F2020_Population_Projection))
1634747971695:sqrt(var(data$AutoTheft_Rate2020))
1634747971769:summary(data$AutoTheft_Rate2020)
1634750466013:data %>%
1634750466030:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_Rate2020))+
1634750466051:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1634750466075:theme(plot.title = element_text(size=12))+
1634750466099:geom_point(col = "blue")
1634757958835:View(data)
1634931225502:knitr::opts_chunk$set(echo = TRUE)
1634931225546:library(openintro)
1634931225661:library(opendatatoronto)
1634931225710:library(dplyr)
1634931225730:library(patchwork)
1634931225787:library(tidyverse)
1634931225973:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634931226019:# You may need additional chunks.
1634931226085:# I would recommend not including any of the Cleaning process output here.
1634931226123:# get package
1634931226145:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634931226609:package
1634931226671:# get all resources for this package
1634931226706:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634931226815:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634931226837:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634931226897:# load the first datastore resource as a sample
1634931226917:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634931229406:data
1634931229621:summary(data$F2020_Population_Projection)
1634931229706:sqrt(var(data$F2020_Population_Projection))
1634931229738:sqrt(var(data$AutoTheft_Rate2020))
1634931229772:summary(data$AutoTheft_Rate2020)
1634931640386:knitr::opts_chunk$set(echo = TRUE)
1634931640419:library(openintro)
1634931640436:library(opendatatoronto)
1634931640455:library(dplyr)
1634931640477:library(patchwork)
1634931640498:library(tidyverse)
1634931640582:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1634931640622:# You may need additional chunks.
1634931640652:# I would recommend not including any of the Cleaning process output here.
1634931640710:# get package
1634931640730:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634931640914:package
1634931640976:# get all resources for this package
1634931640996:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1634931641144:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1634931641165:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1634931641222:# load the first datastore resource as a sample
1634931641242:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1634931642964:data
1634931643162:summary(data$F2020_Population_Projection)
1634931643240:sqrt(var(data$F2020_Population_Projection))
1634931643269:sqrt(var(data$AutoTheft_Rate2020))
1634931643296:summary(data$AutoTheft_Rate2020)
1634933310995:echo "# linear-regression" >> README.md
1634933311009:git init
1634933311055:git add README.md
1634933311072:git commit -m "first commit"
1634933311085:git branch -M main
1634933311101:git remote add origin https://github.com/ChristopherChifor/linear-regression.git
1634933311119:git push -u origin main
1634933321959:foo <- 12
1634933322686:doo
1634933323507:doo
1634933324786:foo
1635014183442:knitr::opts_chunk$set(echo = TRUE)
1635014183497:library(openintro)
1635014183613:library(opendatatoronto)
1635014195142:knitr::opts_chunk$set(echo = TRUE)
1635014195183:library(openintro)
1635014195209:library(opendatatoronto)
1635014195254:library(dplyr)
1635014195275:library(patchwork)
1635014195358:library(tidyverse)
1635014195453:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635014195519:# You may need additional chunks.
1635014195557:# I would recommend not including any of the Cleaning process output here.
1635014195595:# get package
1635014195615:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635014196071:package
1635014196129:# get all resources for this package
1635014196149:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635014196236:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635014196259:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635014196311:# load the first datastore resource as a sample
1635014196333:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635014198578:data
1635014198810:summary(data$F2020_Population_Projection)
1635014198898:sqrt(var(data$F2020_Population_Projection))
1635014198935:sqrt(var(data$AutoTheft_Rate2020))
1635014198965:summary(data$AutoTheft_Rate2020)
1635014239150:knitr::opts_chunk$set(echo = TRUE)
1635014239189:library(openintro)
1635014239213:library(opendatatoronto)
1635014239240:library(dplyr)
1635014239266:library(patchwork)
1635014239288:library(tidyverse)
1635014239376:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635014239420:# You may need additional chunks.
1635014239489:# I would recommend not including any of the Cleaning process output here.
1635014239529:# get package
1635014239553:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635014239651:package
1635014239715:# get all resources for this package
1635014239739:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635014239806:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635014239829:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635014239876:# load the first datastore resource as a sample
1635014239893:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635014241276:data
1635014241507:summary(data$F2020_Population_Projection)
1635014241602:sqrt(var(data$F2020_Population_Projection))
1635014241636:sqrt(var(data$AutoTheft_Rate2020))
1635014241672:summary(data$AutoTheft_Rate2020)
1635014518297:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635014518321:library(tidyverse)
1635014518342:library(opendatatoronto)
1635014518362:library(dplyr)
1635014521536:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635014521578:# You may need additional chunks, in case you want to include some of the cleaning output.
1635014521617:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635014521709:# get package
1635014521735:package <- show_package("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635014522005:package
1635014522073:# get all resources for this package
1635014522115:resources <- list_package_resources("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635014522205:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635014522225:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635014522272:# load the first datastore resource as a sample
1635014522293:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635014543095:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635014543119:library(tidyverse)
1635014543143:library(opendatatoronto)
1635014543166:library(dplyr)
1635014543247:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635014543292:# You may need additional chunks, in case you want to include some of the cleaning output.
1635014543331:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635014543418:# get package
1635014543441:package <- show_package("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635014543501:package
1635014543566:# get all resources for this package
1635014543591:resources <- list_package_resources("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635014543659:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635014543686:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635014543735:# load the first datastore resource as a sample
1635014543757:bicycle <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635015110096:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635015110113:library(tidyverse)
1635015110134:library(opendatatoronto)
1635015110154:library(dplyr)
1635015110223:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015110260:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015110293:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015110384:# get package
1635015110403:package <- show_package("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635015110635:package
1635015110696:# get all resources for this package
1635015110716:resources <- list_package_resources("c7d34d9b-23d2-44fe-8b3b-cd82c8b38978")
1635015110780:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635015110799:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635015110844:# load the first datastore resource as a sample
1635015110863:bicycle <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635015221925:library(readr)
1635015221939:bicycle_thefts <- read_csv("Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015222545:View(bicycle_thefts)
1635015250146:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635015250163:library(tidyverse)
1635015250178:library(readr)
1635015250223:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015250261:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015250295:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015250338:bicycle_thefts <- read_csv("Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015283218:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015283251:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015283289:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015283340:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015283485:View(bicycle_thefts)
1635015311588:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635015311607:library(tidyverse)
1635015311628:library(readr)
1635015311645:library(dplyr)
1635015313508:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015313537:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015313569:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015313641:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015313776:glimpse(bicycle_thefts)
1635015323445:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015323479:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015323511:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015323564:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015323683:glimpse(bicycle_thefts)
1635015443197:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015443231:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015443266:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015443311:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015443429:glimpse(bicycle_thefts)
1635015443522:plot(bicycle_thefts)
1635015457761:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635015457794:# You may need additional chunks, in case you want to include some of the cleaning output.
1635015457830:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635015457879:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635015457995:glimpse(bicycle_thefts)
1635015458089:plot(bicycle_thefts$Cost_of_Bike)
1635016874024:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635016874064:# You may need additional chunks, in case you want to include some of the cleaning output.
1635016874099:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635016874154:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635016874407:glimpse(bicycle_thefts)
1635017147703:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017147742:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017147779:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017147828:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017147948:glimpse(bicycle_thefts)
1635017148045:lm(bicycle_thefts$Occurrence_DayOfYear ~ bicycle_thefts$Cost_of_Bike)
1635017181780:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017181817:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017181856:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017181916:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017182036:# glimpse(bicycle_thefts)
1635017182070:lm(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635017204949:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017204991:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017205030:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017205094:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017205219:# glimpse(bicycle_thefts)
1635017205255:plot(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635017205800:lm(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635017239759:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017239797:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017239831:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017239880:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017240003:# glimpse(bicycle_thefts)
1635017240035:plot(bicycle_thefts$Occurrence_DayOfYear ~ bicycle_thefts$Cost_of_Bike)
1635017240586:lm(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635017256628:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017256669:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017256710:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017256771:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017256901:glimpse(bicycle_thefts)
1635017257005:plot(bicycle_thefts$Occurrence_DayOfYear ~ bicycle_thefts$Cost_of_Bike)
1635017257537:lm(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635017291865:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635017291901:# You may need additional chunks, in case you want to include some of the cleaning output.
1635017291939:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635017291991:bicycle_thefts <- read_csv("~/Sta304/STA304-F21-Assignment2.git/bicycle-thefts.csv")
1635017292115:glimpse(bicycle_thefts)
1635017292200:#
1635017292222:# plot(bicycle_thefts$Occurrence_DayOfYear ~ bicycle_thefts$Cost_of_Bike)
1635017292247:#
1635017292269:# lm(bicycle_thefts$Cost_of_Bike ~ bicycle_thefts$Occurrence_DayOfYear)
1635018057652:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635018057678:library(tidyverse)
1635018057699:library(readr)
1635018057721:library(dplyr)
1635018057740:library(opendatatoronto)
1635018060499:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635018060533:# You may need additional chunks, in case you want to include some of the cleaning output.
1635018060574:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635018060593:# get package
1635018060616:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635018060952:package
1635018061016:# get all resources for this package
1635018061037:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635018061106:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635018061124:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635018061172:# load the first datastore resource as a sample
1635018061193:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635018063840:data
1635018584153:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635018584183:# You may need additional chunks, in case you want to include some of the cleaning output.
1635018584220:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635018584241:# get package
1635018584260:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635018584471:package
1635018584526:# get all resources for this package
1635018584545:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635018584617:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635018584639:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635018584682:# load the first datastore resource as a sample
1635018584700:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635018587672:glimpse(data)
1635018606022:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635018606055:# You may need additional chunks, in case you want to include some of the cleaning output.
1635018606083:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635018606099:# get package
1635018606123:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635018606171:package
1635018606227:# get all resources for this package
1635018606245:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635018606316:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635018606334:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635018606378:# load the first datastore resource as a sample
1635018606394:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635018607997:glimpse(data)
1635018647411:View(data)
1635019346766:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019346797:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019346834:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019346858:# get package
1635019346878:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019347169:package
1635019347227:# get all resources for this package
1635019347246:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019347314:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019347334:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019347380:# load the first datastore resource as a sample
1635019347398:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019349780:glimpse(data)
1635019349862:lm(data$volume ~ data$pct_50)
1635019350519:plot()
1635019363934:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019363970:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019364005:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019364023:# get package
1635019364047:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019364121:package
1635019364175:# get all resources for this package
1635019364194:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019364262:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019364279:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019364317:# load the first datastore resource as a sample
1635019364341:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019366163:# glimpse(data)
1635019366194:lm(data$volume ~ data$pct_50)
1635019388033:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019388065:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019388106:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019388130:# get package
1635019388152:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019388223:package
1635019388298:# get all resources for this package
1635019388319:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019388402:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019388421:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019388464:# load the first datastore resource as a sample
1635019388482:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019390178:# glimpse(data)
1635019390218:plot(data$volume ~ data$pct_50)
1635019412225:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019412264:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019412296:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019412315:# get package
1635019412332:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019412388:package
1635019412455:# get all resources for this package
1635019412476:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019412560:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019412583:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019412630:# load the first datastore resource as a sample
1635019412652:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019414246:# glimpse(data)
1635019414282:plot(data$pct_50 ~ data$volume)
1635019425057:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019425087:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019425127:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019425149:# get package
1635019425172:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019425240:package
1635019425304:# get all resources for this package
1635019425324:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019425387:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019425408:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019425455:# load the first datastore resource as a sample
1635019425477:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019427167:# glimpse(data)
1635019427204:plot(data$volume ~ data$pct_50)
1635019471464:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019471496:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019471530:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019471550:# get package
1635019471568:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019471639:package
1635019471697:# get all resources for this package
1635019471716:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019471778:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019471799:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019471847:# load the first datastore resource as a sample
1635019471867:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019474071:# glimpse(data)
1635019474099:plot(data$volume ~ data$pct_50 + data$direction)
1635019491729:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019491767:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019491799:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019491818:# get package
1635019491837:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019491906:package
1635019491968:# get all resources for this package
1635019491989:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019492064:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019492088:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019492131:# load the first datastore resource as a sample
1635019492155:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019493738:# glimpse(data)
1635019493769:lm(data$volume ~ data$pct_50 + data$direction)
1635019571757:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019571788:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019571828:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019571846:# get package
1635019571866:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019571928:package
1635019571987:# get all resources for this package
1635019572007:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019572066:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019572084:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019572130:# load the first datastore resource as a sample
1635019572149:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019573749:# glimpse(data)
1635019573786:lm(data$volume ~ data$pct_50)
1635019624126:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019624169:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019624205:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019624226:# get package
1635019624253:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019624323:package
1635019624389:# get all resources for this package
1635019624407:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019624467:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019624483:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019624525:# load the first datastore resource as a sample
1635019624540:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019626336:# glimpse(data)
1635019626374:lm(data$volume ~ data$spd_50)
1635019696224:lm(data$volume ~ data$spd_50)
1635019835976:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635019836012:# You may need additional chunks, in case you want to include some of the cleaning output.
1635019836050:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635019836068:# get package
1635019836087:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635019836362:package
1635019836422:# get all resources for this package
1635019836447:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635019836517:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635019836540:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635019836587:# load the first datastore resource as a sample
1635019836610:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635019839292:# glimpse(data)
1635019839337:lm(data$spd_50 ~ data$volume)
1635020107421:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635020107455:# You may need additional chunks, in case you want to include some of the cleaning output.
1635020107483:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635020107502:# get package
1635020107520:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635020111741:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635020111764:library(tidyverse)
1635020111785:library(readr)
1635020111804:library(dplyr)
1635020111828:library(opendatatoronto)
1635020114113:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635020114147:# You may need additional chunks, in case you want to include some of the cleaning output.
1635020114179:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635020114196:# get package
1635020114217:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635020114515:package
1635020114691:# get all resources for this package
1635020114710:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635020114831:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635020114851:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635020114903:# load the first datastore resource as a sample
1635020114938:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635020117718:# glimpse(data)
1635020117757:plot(data$spd_50 ~ data$volume)
1635020144327:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635020144366:# You may need additional chunks, in case you want to include some of the cleaning output.
1635020144399:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635020144417:# get package
1635020144438:package <- show_package("058236d2-d26e-4622-9665-941b9e7a5229")
1635020144654:package
1635020144719:# get all resources for this package
1635020144742:resources <- list_package_resources("058236d2-d26e-4622-9665-941b9e7a5229")
1635020144814:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635020144834:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635020144880:# load the first datastore resource as a sample
1635020144900:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635020147020:# glimpse(data)
1635020147063:plot(data$volume ~ data$spd_50)
1635021058735:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635021058765:# You may need additional chunks, in case you want to include some of the cleaning output.
1635021058801:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635021058819:# get package\
1635021058851:# get package
1635021058871:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635021059151:package
1635021059207:# get all resources for this package
1635021059225:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635021059303:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635021059323:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635021059369:# load the first datastore resource as a sample
1635021059390:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635021061345:data
1635021199736:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635021199770:# You may need additional chunks, in case you want to include some of the cleaning output.
1635021199802:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635021199822:# get package\
1635021199855:# get package
1635021199872:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635021199974:package
1635021200033:# get all resources for this package
1635021200049:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635021200113:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635021200130:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635021200203:# load the first datastore resource as a sample
1635021200222:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635021201631:# data
1635021201672:lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood)
1635021802958:View(data)
1635022301181:knitr::opts_chunk$set(echo = TRUE)
1635022301239:library(tidyverse)
1635022301293:starwars<-starwars
1635022301560:glimpse(starwars)
1635022301644:head(starwars)
1635022301740:#install.packages("survey")
1635022301767:library(survey)
1635022312729:install.packages("survey")
1635022320705:knitr::opts_chunk$set(echo = TRUE)
1635022320761:library(tidyverse)
1635022320849:starwars<-starwars
1635022320884:glimpse(starwars)
1635022320960:head(starwars)
1635022321051:#install.packages("survey")
1635022321073:library(survey)
1635022322060:## Using the Survey Library
1635022322079:n=87
1635022322101:N=200
1635022322125:fpc.srs = rep(N, n)
1635022322167:starwars.design <- svydesign(id=~1, data=starwars, fpc=fpc.srs)
1635022322207:mysvylm <- svyglm(mass ~ height, starwars.design)
1635022322237:summary(mysvylm)
1635022322480:#install.packages("survey")
1635022322507:library(survey)
1635022322539:## Using the Survey Library
1635022322559:summary(lm(mass ~ height, data=starwars))
1635022322881:## Using the Survey Library
1635022322910:n=87
1635022322934:N=200
1635022322955:fpc.srs = rep(N, n)
1635022322992:starwars.design <- svydesign(id=~1, data=starwars, fpc=fpc.srs)
1635022323046:mysvylm <- svyglm(mass ~ height + sex, starwars.design)
1635022323077:summary(mysvylm)
1635022323353:## Using lm
1635022323373:summary(lm(mass ~ height + sex, data=starwars))
1635022323851:## Using the Survey Library
1635022323900:## Remove missing mass
1635022323931:starwars <- starwars %>% filter(!is.na(mass))
1635022324070:## Create a new variable called `mass_over100`.
1635022324106:starwars <- starwars %>%  mutate(
1635022324127:mass_over100 = case_when(
1635022324147:mass > 100 ~ 1, ## 1 = Yes, over 100lbs
1635022324169:mass <= 100 ~ 0)
1635022324196:)
1635022324527:## Using lm
1635022324543:summary(glm(mass_over100 ~ height + sex, data=starwars, family = "binomial"))
1635022324956:pred_odds <- -28.90236+0.0604*170+15.8338*1
1635022324984:exp(pred_odds)/(1+exp(pred_odds))
1635023033339:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635023033377:# You may need additional chunks, in case you want to include some of the cleaning output.
1635023033415:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635023033435:# get package\
1635023033473:# get package
1635023033492:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635023033815:package
1635023033879:# get all resources for this package
1635023033897:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635023034002:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635023034020:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635023034064:# load the first datastore resource as a sample
1635023034087:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635023036393:# data
1635023036428:lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood)
1635028373394:# Use this to calculate some summary measures.
1635028373436:summary(data$AutoTheft_2020)
1635028373511:summary(data$F2020_Population_Projection)
1635028373599:summary(data$Neighbourhood)
1635028379431:# Use this to calculate some summary measures.
1635028379467:summary(data$AutoTheft_2020)
1635028379540:summary(data$F2020_Population_Projection)
1635028379615:summary(data$Neighbourhood)
1635028387135:# Use this to calculate some summary measures.
1635028387171:# summary(data$AutoTheft_2020)
1635028387189:# summary(data$F2020_Population_Projection)
1635028387209:summary(data$Neighbourhood)
1635028395500:# Use this to calculate some summary measures.
1635028395536:summary(data$AutoTheft_2020)
1635028395608:summary(data$F2020_Population_Projection)
1635028395677:summary(data$Neighbourhood)
1635028579546:# Use this to calculate some summary measures.
1635028579583:summary(data$AutoTheft_2020)
1635028579670:summary(data$F2020_Population_Projection)
1635035409679:# Use this to calculate some summary measures.
1635035409713:summary(data$AutoTheft_2020)
1635035409787:summary(data$F2020_Population_Projection)
1635035409863:sd(data$AutoTheft_2020)
1635035409897:sd(data$F2020_Population_Projection)
1635038358891:# Use this to create some plots.
1635038358924:data %>%
1635038358944:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635038358964:geom_point(col = "blue")+
1635038359009:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1635038359027:theme(plot.title = element_text(size=12))+
1635038359049:geom_abline(slope = 0.001457, intercept = -0.598671, col="red")
1635038370225:# Use this to create some plots.
1635038370262:data %>%
1635038370280:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635038370298:geom_point(col = "blue")+
1635038370315:ggtitle("Scatterplot of average auto thefts per neighbourhood to population in Toronto")+
1635038370334:theme(plot.title = element_text(size=12))
1635038401925:# Use this to create some plots.
1635038401960:data %>%
1635038401978:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635038401999:geom_point(col = "blue")+
1635038402030:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635038402052:theme(plot.title = element_text(size=12))
1635038507675:# Use this to create some plots.
1635038507706:data %>%
1635038507729:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635038507751:geom_point(col = "blue")+
1635038507775:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635038507795:labs(x="poo")+
1635038507817:theme(plot.title = element_text(size=12))
1635038533317:# Use this to create some plots.
1635038533354:data %>%
1635038533375:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635038533398:geom_point(col = "blue")+
1635038533423:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635038533447:labs(x="Neighbourhood Population in 2020")+
1635038533466:theme(plot.title = element_text(size=12))
1635041073183:# Use this to create some plots.
1635041073211:data %>%
1635041073228:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635041073245:geom_point(col = "blue")+
1635041073262:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635041073279:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635041073298:theme(plot.title = element_text(size=12))
1635044855066:View(data)
1635179432511:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635179432542:library(tidyverse)
1635179432563:library(readr)
1635179432583:library(dplyr)
1635179432605:library(opendatatoronto)
1635179432814:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179432866:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179432910:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179432949:# get package
1635179432970:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179433262:package
1635179433412:# get all resources for this package
1635179433434:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179433513:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179433533:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179433602:# load the first datastore resource as a sample
1635179433620:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179435482:# data
1635179435518:lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood)
1635179438028:# Use this to calculate some summary measures.
1635179438065:summary(data$AutoTheft_2020)
1635179438141:summary(data$F2020_Population_Projection)
1635179438226:sd(data$AutoTheft_2020)
1635179438259:sd(data$F2020_Population_Projection)
1635179438340:# Use this to create some plots.
1635179438380:data %>%
1635179438400:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635179438423:geom_point(col = "blue")+
1635179438445:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635179438471:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635179438491:theme(plot.title = element_text(size=12))
1635179438959:# Here you can load in and clean the data.
1635179439003:# You may need additional chunks.
1635179439037:# I would recommend not including any of the Cleaning process output in the pdf - hence the "include = FALSE" at the start of the chunk.
1635179439115:# Here you can run a linear regression on your two variables of interest.
1635179439157:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635179439251:# Use this to calculate generate a scatterplot of your variables if desired.
1635179439283:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635179449804:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179449837:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179449880:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179449912:# get package
1635179449931:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179450158:package
1635179450220:# get all resources for this package
1635179450243:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179450310:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179450332:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179450381:# load the first datastore resource as a sample
1635179450412:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179451948:# data
1635179451983:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635179593470:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179593511:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179593546:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179593586:# get package
1635179593606:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179593714:package
1635179593776:# get all resources for this package
1635179593798:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179593865:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179593884:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179593929:# load the first datastore resource as a sample
1635179593955:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179595477:data <- filter(data, Neighbourhood = "Yorkdale-Glen Park")
1635179606471:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179606509:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179606553:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179606590:# get package
1635179606609:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179606680:package
1635179606746:# get all resources for this package
1635179606769:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179606840:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179606859:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179606907:# load the first datastore resource as a sample
1635179606926:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179608301:data <- filter(data, Neighbourhood == "Yorkdale-Glen Park")
1635179608417:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635179614944:View(data)
1635179664654:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179664688:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179664718:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179664748:# get package
1635179664769:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179664820:package
1635179664883:# get all resources for this package
1635179664899:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179664961:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179664977:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179665013:# load the first datastore resource as a sample
1635179665031:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179666397:data <- filter(data, Neighbourhood != "Yorkdale-Glen Park")
1635179666447:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635179719178:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179719216:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179719261:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179719304:# get package
1635179719325:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179719390:package
1635179719456:# get all resources for this package
1635179719474:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179719534:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179719554:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179719599:# load the first datastore resource as a sample
1635179719621:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179721010:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635179728613:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179728645:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179728680:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179728709:# get package
1635179728729:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179728781:package
1635179728839:# get all resources for this package
1635179728858:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179728921:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179728941:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179728986:# load the first datastore resource as a sample
1635179729006:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179730378:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection))
1635179757131:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635179757184:# You may need additional chunks, in case you want to include some of the cleaning output.
1635179757216:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635179757247:# get package
1635179757268:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179758190:package
1635179758259:# get all resources for this package
1635179758276:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635179758342:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635179758364:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635179758416:# load the first datastore resource as a sample
1635179758439:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635179760606:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635184093055:# Here you can load in and clean the data.
1635184093095:# You may need additional chunks.
1635184093130:# I would recommend not including any of the Cleaning process output in the pdf - hence the "include = FALSE" at the start of the chunk.
1635184093182:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635184117526:# Here you can run a linear regression on your two variables of interest.
1635184117562:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635184117617:lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood)
1635184124037:# Here you can run a linear regression on your two variables of interest.
1635184124069:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635184124122:lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood)
1635184219855:# Here you can run a linear regression on your two variables of interest.
1635184219890:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635184219940:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635184259165:# Here you can run a linear regression on your two variables of interest.
1635184259202:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635184259260:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection))
1635184272000:# Here you can run a linear regression on your two variables of interest.
1635184272044:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635184272101:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635193085308:# Use this to create some plots.
1635193085344:data %>%
1635193085361:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193085379:geom_point(col = "purple")+
1635193085404:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193085427:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193085446:theme(plot.title = element_text(size=12))
1635193088056:# Use this to create some plots.
1635193088087:data %>%
1635193088108:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193088123:geom_point(col = "purple")+
1635193088142:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193088159:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193088177:theme(plot.title = element_text(size=12))
1635193094024:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635193094040:library(tidyverse)
1635193094056:library(readr)
1635193094071:library(dplyr)
1635193094090:library(opendatatoronto)
1635193094161:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635193094196:# You may need additional chunks, in case you want to include some of the cleaning output.
1635193094222:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635193094252:# get package
1635193094270:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635193094715:package
1635193094859:# get all resources for this package
1635193094876:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635193094956:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635193094972:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635193095014:# load the first datastore resource as a sample
1635193095030:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635193096813:# Use this to calculate some summary measures.
1635193096848:summary(data$AutoTheft_2020)
1635193096914:summary(data$F2020_Population_Projection)
1635193096982:sd(data$AutoTheft_2020)
1635193097006:sd(data$F2020_Population_Projection)
1635193097075:# Use this to create some plots.
1635193097108:data %>%
1635193097125:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193097143:geom_point(col = "blue")+
1635193097161:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193097179:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193097197:theme(plot.title = element_text(size=12))
1635193097577:# Here you can load in and clean the data.
1635193097618:# You may need additional chunks.
1635193097651:# I would recommend not including any of the Cleaning process output in the pdf - hence the "include = FALSE" at the start of the chunk.
1635193097729:# Here you can run a linear regression on your two variables of interest.
1635193097768:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635193097826:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection + data$Neighbourhood))
1635193100732:# Use this to calculate generate a scatterplot of your variables if desired.
1635193100759:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635193104885:# Use this to create some plots.
1635193104919:data %>%
1635193104939:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193104957:geom_point(col = "purple")+
1635193104973:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193104992:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193105014:theme(plot.title = element_text(size=12))
1635193116606:# Use this to create some plots.
1635193116637:data %>%
1635193116653:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193116672:geom_point(col = "dark purple")+
1635193116699:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193116716:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193116735:theme(plot.title = element_text(size=12))
1635193121363:# Use this to create some plots.
1635193121396:data %>%
1635193121411:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193121432:geom_point(col = "darkpurple")+
1635193121451:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193121471:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193121489:theme(plot.title = element_text(size=12))
1635193126539:# Use this to create some plots.
1635193126575:data %>%
1635193126595:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193126615:geom_point(col = "purple")+
1635193126633:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193126658:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193126678:theme(plot.title = element_text(size=12))
1635193908775:# Use this to calculate generate a scatterplot of your variables if desired.
1635193908793:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635193908820:data %>%
1635193908834:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193908850:geom_point(col = "purple")+
1635193908867:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193908885:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193908904:theme(plot.title = element_text(size=12))+
1635193908921:geom_abline(slope = 0.002063, intercept = 123.2, col="red")
1635193925587:# Here you can run a linear regression on your two variables of interest.
1635193925619:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635193925663:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection))
1635193938756:# Use this to calculate generate a scatterplot of your variables if desired.
1635193938774:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635193938803:data %>%
1635193938820:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193938835:geom_point(col = "purple")+
1635193938852:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193938868:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193938890:theme(plot.title = element_text(size=12))+
1635193938905:geom_abline(slope = 0.002063, intercept = 5.0293846, col="red")
1635193964600:# Use this to calculate generate a scatterplot of your variables if desired.
1635193964620:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635193964651:data %>%
1635193964669:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635193964684:geom_point(col = "purple")+
1635193964701:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635193964719:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635193964735:theme(plot.title = element_text(size=12))+
1635193964753:geom_abline(slope = 0.0016173, intercept = 5.0293846, col="red")
1635195195100:# Use this to calculate generate a scatterplot of your variables if desired.
1635195195118:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635195195148:data %>%
1635195195168:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635195195186:geom_point(col = "purple")+
1635195195205:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635195195224:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635195195244:theme(plot.title = element_text(size=12))+
1635195195265:geom_abline(slope = 0.0016173, intercept = 5.0293846, col="red")
1635196144425:# Here you can run a linear regression on your two variables of interest.
1635196144454:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635196144521:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection))
1635196157800:# Here you can run a linear regression on your two variables of interest.
1635196157832:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635196157876:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection+ data$Neighbourhood))
1635200115455:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635200115472:library(tidyverse)
1635200115488:library(readr)
1635200115506:library(dplyr)
1635200115521:library(opendatatoronto)
1635200115572:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635200115607:# You may need additional chunks, in case you want to include some of the cleaning output.
1635200115636:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635200115669:# get package
1635200115688:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635200115786:package
1635200115832:# get all resources for this package
1635200115848:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635200115909:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635200115926:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635200115962:# load the first datastore resource as a sample
1635200115982:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635200117162:# Use this to calculate some summary measures.
1635200117203:summary(data$AutoTheft_2020)
1635200117273:summary(data$F2020_Population_Projection)
1635200117354:sd(data$AutoTheft_2020)
1635200117385:sd(data$F2020_Population_Projection)
1635200117449:# Use this to create some plots.
1635200117486:data %>%
1635200117508:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635200117528:geom_point(col = "purple")+
1635200117546:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635200117565:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635200117583:theme(plot.title = element_text(size=12))
1635200117813:# Here you can run a linear regression on your two variables of interest.
1635200117858:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635200117915:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection+ data$Neighbourhood))
1635200120932:# Use this to calculate generate a scatterplot of your variables if desired.
1635200120953:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635200120990:data %>%
1635200121009:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635200121030:geom_point(col = "purple")+
1635200121050:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635200121069:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635200121087:theme(plot.title = element_text(size=12))+
1635200121105:geom_abline(slope = 0.0016173, intercept = 5.0293846, col="red")
1635201585109:# Here you can run a linear regression on your two variables of interest.
1635201585142:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635201585164:cor(data$AutoTheft_2020, data$F2020_Population_Projection)
1635201585210:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection+ data$Neighbourhood))
1635202646760:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1635202646783:library(tidyverse)
1635202646813:library(readr)
1635202646836:library(dplyr)
1635202646860:library(opendatatoronto)
1635202646909:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1635202646946:# You may need additional chunks, in case you want to include some of the cleaning output.
1635202646979:# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
1635202647017:# get package
1635202647037:package <- show_package("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635202647376:package
1635202647456:# get all resources for this package
1635202647474:resources <- list_package_resources("fc4d95a6-591f-411f-af17-327e6c5d03c7")
1635202647554:# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
1635202647574:datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
1635202647616:# load the first datastore resource as a sample
1635202647637:data <- filter(datastore_resources, row_number()==1) %>% get_resource()
1635202651020:# Use this to calculate some summary measures.
1635202651058:summary(data$AutoTheft_2020)
1635202651127:summary(data$F2020_Population_Projection)
1635202651201:sd(data$AutoTheft_2020)
1635202651247:sd(data$F2020_Population_Projection)
1635202651355:# Use this to create some plots.
1635202651395:data %>%
1635202651417:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635202651434:geom_point(col = "purple")+
1635202651454:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635202651472:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635202651488:theme(plot.title = element_text(size=12))
1635202651729:# Here you can run a linear regression on your two variables of interest.
1635202651786:#lm(y~x, data = your_data)  # This is for a simple linear regression.
1635202651804:cor(data$AutoTheft_2020, data$F2020_Population_Projection)
1635202651843:summary(lm(data$AutoTheft_2020 ~ data$F2020_Population_Projection+ data$Neighbourhood))
1635202655287:# Use this to calculate generate a scatterplot of your variables if desired.
1635202655308:# You can use abline to overlay the scatterplot with the regression line (again, if desired).
1635202655338:data %>%
1635202655355:ggplot(aes(x = F2020_Population_Projection, y=AutoTheft_2020))+
1635202655388:geom_point(col = "purple")+
1635202655421:ggtitle("Scatterplot of Auto Thefts per Neighbourhood to Population in Toronto")+
1635202655446:labs(x="Neighbourhood Population in 2020", y="Number of Auto Thefts")+
1635202655461:theme(plot.title = element_text(size=12))+
1635202655479:geom_abline(slope = 0.0016173, intercept = 5.0293846, col="red")
1636051197048:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636051197078:library(openintro)
1636051197167:library(tidyverse)
1636051197313:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636051197362:census_data <- read_csv("gss_clean.csv")
1636051197744:# You may need additional chunks, in case you want to include some of the cleaning output.
1636051197819:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636051197843:# First, if you don't already have it, install the devtools package:
1636051197862:# install.packages("devtools")
1636051197906:# Now use devtools to install the cesR package directly from Github:
1636051197927:# devtools::install_github("hodgettsp/cesR")
1636051198146:# Load it like any other package:
1636051198167:#library(cesR)
1636051198232:# There are many different CES datasets, and they have unique codes.
1636051198250:# See them with the get_cescodes() function:
1636051198287:#get_cescodes()
1636051198322:# Now pick one, let's try ces2019_phone
1636051198355:#get_ces("ces2019_phone")
1636051198391:#survey_data <- ces2019_phone
1636051198464:# Alternative to what is in the comments above, I have locally loaded
1636051198487:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636051198509:# We can load it in:
1636051198527:survey_data <- read_csv("ces2019-phone_clean.csv")
1636051199097:#Cleaning Process:
1636051199150:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636051199186:survey_data <-
1636051199205:survey_data %>%
1636051199224:mutate(age = 2019-q2) %>%
1636051199246:select(age, p3,q3,q4)
1636051199305:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636051199354:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636051199376:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636051199434:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636051199472:survey_data <-
1636051199494:survey_data %>%
1636051199514:filter(q4 %in% (1:10))
1636051199541:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636051199587:survey_data <-
1636051199609:survey_data %>%
1636051199634:filter(p3 %in% (1:8))
1636051199679:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636051199710:census_data <- census_data %>%
1636051199728:mutate(age=round(age)) %>%
1636051199747:filter(province == "Newfoundland and Labrador"|
1636051199768:province == "Prince Edward Island"|
1636051199787:province == "Nova Scotia"| province == "New Brunswick"|
1636051199806:province == "Quebec"| province == "Ontario"|
1636051199826:province == "Manitoba"| province == "Saskatchewan"|
1636051199846:province == "Alberta"| province == "British Columbia") %>%
1636051199865:filter(sex == "Female" | sex == "Male") %>%
1636051199885:select(age, sex, province)
1636051208205:#Cleaning Process:
1636051208260:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636051208310:survey_data <-
1636051208332:survey_data %>%
1636051208349:mutate(age = 2019-q2) %>%
1636051208369:select(age, p3,q3,q4)
1636051214225:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636051214252:library(openintro)
1636051214268:library(tidyverse)
1636051214326:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636051214366:census_data <- read_csv("gss_clean.csv")
1636051214520:# You may need additional chunks, in case you want to include some of the cleaning output.
1636051214594:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636051214621:# First, if you don't already have it, install the devtools package:
1636051214641:# install.packages("devtools")
1636051214676:# Now use devtools to install the cesR package directly from Github:
1636051214694:# devtools::install_github("hodgettsp/cesR")
1636051214868:# Load it like any other package:
1636051214891:#library(cesR)
1636051214932:# There are many different CES datasets, and they have unique codes.
1636051214949:# See them with the get_cescodes() function:
1636051215016:#get_cescodes()
1636051215055:# Now pick one, let's try ces2019_phone
1636051215095:#get_ces("ces2019_phone")
1636051215139:#survey_data <- ces2019_phone
1636051215210:# Alternative to what is in the comments above, I have locally loaded
1636051215234:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636051215256:# We can load it in:
1636051215274:survey_data <- read_csv("ces2019-phone_clean.csv")
1636051215536:#Cleaning Process:
1636051215599:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636051215643:survey_data <-
1636051215667:survey_data %>%
1636051215687:mutate(age = 2019-q2) %>%
1636051215713:select(age, p3,q3,q4)
1636051215748:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636051215789:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636051215808:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636051215855:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636051215889:survey_data <-
1636051215906:survey_data %>%
1636051215926:filter(q4 %in% (1:10))
1636051215957:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636051215996:survey_data <-
1636051216017:survey_data %>%
1636051216038:filter(p3 %in% (1:8))
1636051216089:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636051216136:census_data <- census_data %>%
1636051216163:mutate(age=round(age)) %>%
1636051216186:filter(province == "Newfoundland and Labrador"|
1636051216205:province == "Prince Edward Island"|
1636051216230:province == "Nova Scotia"| province == "New Brunswick"|
1636051216251:province == "Quebec"| province == "Ontario"|
1636051216275:province == "Manitoba"| province == "Saskatchewan"|
1636051216300:province == "Alberta"| province == "British Columbia") %>%
1636051216325:filter(sex == "Female" | sex == "Male") %>%
1636051216341:select(age, sex, province)
1636052101400:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636052101429:library(openintro)
1636052101447:library(tidyverse)
1636052101471:library(dplyr)
1636052101512:fertility <- read_csv("Fertility.csv")
1636052101642:femalepop <- read_csv("FemalePopulation.csv")
1636052101860:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1636052101900:# You may need additional chunks, in case you want to include some of the cleaning output.
1636052101934:fertility <- fertility %>%
1636052101978:select(`Data Source` ,X63) %>%
1636052101996:filter(!is.na(X63)) %>%
1636052102014:rename(Country = `Data Source`)%>%
1636052102034:rename(Fertility_Rate = X63) %>%
1636052102052:filter(Country != "Country Name") %>%
1636052102072:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1636052106829:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636052106853:library(openintro)
1636052106870:library(tidyverse)
1636052106890:library(dplyr)
1636052106934:fertility <- read_csv("Fertility.csv")
1636052107040:femalepop <- read_csv("FemalePopulation.csv")
1636052107184:# Here you can load in and clean the data (you may need to do the cleaning in a separate R script).
1636052107224:# You may need additional chunks, in case you want to include some of the cleaning output.
1636052107265:fertility <- fertility %>%
1636052107285:select(`Data Source` ,X63) %>%
1636052107303:filter(!is.na(X63)) %>%
1636052107328:rename(Country = `Data Source`)%>%
1636052107348:rename(Fertility_Rate = X63) %>%
1636052107366:filter(Country != "Country Name") %>%
1636052107385:filter(Country != "Bermuda" & Country != "Eritrea" & Country != "Faroe Islands" & Country != "Greenland" & Country != "Liechtenstein" & Country != "St. Martin (French part)" & Country != "Kosovo" & Country != "World" & Country != "Arab World" & Country != "Central Europe and the Baltics" & Country != "East Asia & Pacific (excluding high income)" & Country != "Early-demographic dividend" & Country != "East Asia & Pacific" & Country != "Europe & Central Asia (excluding high income)" & Country != "Europe & Central Asia" & Country != "Euro area" & Country != "European Union" & Country != "Fragile and conflict affected situations" & Country != "High income" & Country != "Heavily indebted poor countries (HIPC)" & Country != "IBRD only" & Country != "IDA total" & Country != "IDA blend" & Country != "IDA only" & Country != "Latin America & Caribbean (excluding high income)" & Country != "Latin America & Caribbean" & Country != "Least developed countries: UN classification" & Country != "Low income" & Country != "Lower middle income" & Country != "Low & middle income" & Country != "Late-demographic dividend" & Country != "Middle East & North Africa" & Country != "Middle income" & Country != "Middle East & North Africa (excluding high income)" & Country != "North America" & Country != "OECD members" & Country != "" & Country != "Other small states" & Country != "Pre-demographic dividend" & Country != "Pacific island small states" & Country != "Post-demographic dividend" & Country != "Sub-Saharan Africa (excluding high income)" & Country != "Small states" & Country != "East Asia & Pacific (IDA & IBRD countries)" & Country != "Europe & Central Asia (IDA & IBRD countries)" & Country != "Latin America & the Caribbean (IDA & IBRD countries)" & Country != "Middle East & North Africa (IDA & IBRD countries)" & Country != "South Asia (IDA & IBRD)" & Country != "Sub-Saharan Africa (IDA & IBRD countries)" & Country != "Upper middle income" & Country != "IDA & IBRD total" & Country != "South Asia")
1636052116903:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636052116934:library(openintro)
1636052116954:library(tidyverse)
1636052117010:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636052117045:census_data <- read_csv("gss_clean.csv")
1636052117140:# You may need additional chunks, in case you want to include some of the cleaning output.
1636052117212:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636052117236:# First, if you don't already have it, install the devtools package:
1636052117258:# install.packages("devtools")
1636052117297:# Now use devtools to install the cesR package directly from Github:
1636052117318:# devtools::install_github("hodgettsp/cesR")
1636052117490:# Load it like any other package:
1636052117511:#library(cesR)
1636052117551:# There are many different CES datasets, and they have unique codes.
1636052117570:# See them with the get_cescodes() function:
1636052117610:#get_cescodes()
1636052117651:# Now pick one, let's try ces2019_phone
1636052117685:#get_ces("ces2019_phone")
1636052117727:#survey_data <- ces2019_phone
1636052117793:# Alternative to what is in the comments above, I have locally loaded
1636052117812:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636052117836:# We can load it in:
1636052117856:survey_data <- read_csv("ces2019-phone_clean.csv")
1636052118293:#Cleaning Process:
1636052118345:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636052118375:survey_data <-
1636052118397:survey_data %>%
1636052118419:mutate(age = 2019-q2) %>%
1636052118439:select(age, p3,q3,q4)
1636052118473:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636052118513:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636052118538:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636052118595:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636052118630:survey_data <-
1636052118648:survey_data %>%
1636052118665:filter(q4 %in% (1:10))
1636052118693:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636052118732:survey_data <-
1636052118752:survey_data %>%
1636052118772:filter(p3 %in% (1:8))
1636052118815:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636052118852:census_data <- census_data %>%
1636052118871:mutate(age=round(age)) %>%
1636052118893:filter(province == "Newfoundland and Labrador"|
1636052118917:province == "Prince Edward Island"|
1636052118937:province == "Nova Scotia"| province == "New Brunswick"|
1636052118953:province == "Quebec"| province == "Ontario"|
1636052118974:province == "Manitoba"| province == "Saskatchewan"|
1636052118993:province == "Alberta"| province == "British Columbia") %>%
1636052119012:filter(sex == "Female" | sex == "Male") %>%
1636052119030:select(age, sex, province)
1636052262077:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636052262109:library(openintro)
1636052262138:library(tidyverse)
1636052262219:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636052262275:census_data <- read_csv("gss_clean.csv")
1636052262368:# You may need additional chunks, in case you want to include some of the cleaning output.
1636052262444:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636052262468:# First, if you don't already have it, install the devtools package:
1636052262488:# install.packages("devtools")
1636052262518:# Now use devtools to install the cesR package directly from Github:
1636052262536:# devtools::install_github("hodgettsp/cesR")
1636052262736:# Load it like any other package:
1636052262755:#library(cesR)
1636052262790:# There are many different CES datasets, and they have unique codes.
1636052262811:# See them with the get_cescodes() function:
1636052262843:#get_cescodes()
1636052262874:# Now pick one, let's try ces2019_phone
1636052262912:#get_ces("ces2019_phone")
1636052262949:#survey_data <- ces2019_phone
1636052263012:# Alternative to what is in the comments above, I have locally loaded
1636052263029:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636052263046:# We can load it in:
1636052263067:survey_data <- read_csv("ces2019-phone_clean.csv")
1636052263329:#Cleaning Process:
1636052263381:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636052263416:survey_data <-
1636052263434:survey_data %>%
1636052263459:mutate(age = 2019-q2) %>%
1636052263483:select(age, p3,q3,q4)
1636052263552:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636052263597:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636052263619:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636052263681:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636052263716:survey_data <-
1636052263742:survey_data %>%
1636052263771:filter(q4 %in% (1:10))
1636052263817:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636052263858:survey_data <-
1636052263878:survey_data %>%
1636052263904:filter(p3 %in% (1:8))
1636052263954:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636052263994:census_data <- census_data %>%
1636052264018:mutate(age=round(age)) %>%
1636052264037:filter(province == "Newfoundland and Labrador"|
1636052264057:province == "Prince Edward Island"|
1636052264078:province == "Nova Scotia"| province == "New Brunswick"|
1636052264114:province == "Quebec"| province == "Ontario"|
1636052264140:province == "Manitoba"| province == "Saskatchewan"|
1636052264163:province == "Alberta"| province == "British Columbia") %>%
1636052264186:filter(sex == "Female" | sex == "Male") %>%
1636052264212:select(age, sex, province)
1636052798289:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636052798318:library(openintro)
1636052798338:library(tidyverse)
1636052798389:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636052798460:census_data <- read_csv("gss_clean.csv")
1636052798554:# You may need additional chunks, in case you want to include some of the cleaning output.
1636052798637:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636052798656:# First, if you don't already have it, install the devtools package:
1636052798678:# install.packages("devtools")
1636052798715:# Now use devtools to install the cesR package directly from Github:
1636052798735:# devtools::install_github("hodgettsp/cesR")
1636052798930:# Load it like any other package:
1636052798952:#library(cesR)
1636052798986:# There are many different CES datasets, and they have unique codes.
1636052799004:# See them with the get_cescodes() function:
1636052799035:#get_cescodes()
1636052799063:# Now pick one, let's try ces2019_phone
1636052799096:#get_ces("ces2019_phone")
1636052799130:#survey_data <- ces2019_phone
1636052799195:# Alternative to what is in the comments above, I have locally loaded
1636052799216:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636052799237:# We can load it in:
1636052799258:survey_data <- read_csv("ces2019-phone_clean.csv")
1636052799534:#Cleaning Process:
1636052799585:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636052799616:survey_data <-
1636052799634:survey_data %>%
1636052799658:mutate(age = 2019-q2) %>%
1636052799679:select(age, p3,q3,q4)
1636052799713:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636052799747:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636052799776:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636052799837:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636052799871:survey_data <-
1636052799891:survey_data %>%
1636052799914:filter(q4 %in% (1:10))
1636052799944:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636052799976:survey_data <-
1636052799993:survey_data %>%
1636052800014:filter(p3 %in% (1:8))
1636052800054:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636052800082:census_data <- census_data %>%
1636052800100:mutate(age=round(age)) %>%
1636052800119:filter(province == "Newfoundland and Labrador"|
1636052800135:province == "Prince Edward Island"|
1636052800152:province == "Nova Scotia"| province == "New Brunswick"|
1636052800170:province == "Quebec"| province == "Ontario"|
1636052800188:province == "Manitoba"| province == "Saskatchewan"|
1636052800205:province == "Alberta"| province == "British Columbia") %>%
1636052800220:filter(sex == "Female" | sex == "Male") %>%
1636052800238:select(age, sex, province)
1636055772824:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636055772847:library(openintro)
1636055772863:library(tidyverse)
1636055772895:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636055772920:census_data <- read_csv("gss_clean.csv")
1636055773012:# You may need additional chunks, in case you want to include some of the cleaning output.
1636055773051:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636055773075:# First, if you don't already have it, install the devtools package:
1636055773094:# install.packages("devtools")
1636055773119:# Now use devtools to install the cesR package directly from Github:
1636055773143:# devtools::install_github("hodgettsp/cesR")
1636055773303:# Load it like any other package:
1636055773322:#library(cesR)
1636055773342:# There are many different CES datasets, and they have unique codes.
1636055773364:# See them with the get_cescodes() function:
1636055773385:#get_cescodes()
1636055773406:# Now pick one, let's try ces2019_phone
1636055773423:#get_ces("ces2019_phone")
1636055773439:#survey_data <- ces2019_phone
1636055773458:# Alternative to what is in the comments above, I have locally loaded
1636055773480:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636055773504:# We can load it in:
1636055773525:survey_data <- read_csv("ces2019-phone_clean.csv")
1636055773778:#Cleaning Process:
1636055773805:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636055773827:survey_data <-
1636055773849:survey_data %>%
1636055773874:mutate(age = 2019-q2) %>%
1636055773894:select(age, p3,q3,q4)
1636055773932:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636055773956:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636055773978:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636055774011:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636055774029:survey_data <-
1636055774047:survey_data %>%
1636055774068:filter(q4 %in% (1:10))
1636055774092:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636055774133:survey_data <-
1636055774153:survey_data %>%
1636055774172:filter(p3 %in% (1:8))
1636055774212:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636055774237:census_data <- census_data %>%
1636055774262:mutate(age=round(age)) %>%
1636055774282:filter(province == "Newfoundland and Labrador"|
1636055774303:province == "Prince Edward Island"|
1636055774324:province == "Nova Scotia"| province == "New Brunswick"|
1636055774342:province == "Quebec"| province == "Ontario"|
1636055774368:province == "Manitoba"| province == "Saskatchewan"|
1636055774389:province == "Alberta"| province == "British Columbia") %>%
1636055774408:filter(sex == "Female" | sex == "Male") %>%
1636055774427:select(age, sex, province)
1636056103731:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636056103764:library(openintro)
1636056103785:library(tidyverse)
1636056103827:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636056103855:census_data <- read_csv("gss_clean.csv")
1636056104043:# You may need additional chunks, in case you want to include some of the cleaning output.
1636056104080:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636056104103:# First, if you don't already have it, install the devtools package:
1636056104126:# install.packages("devtools")
1636056104146:# Now use devtools to install the cesR package directly from Github:
1636056104165:# devtools::install_github("hodgettsp/cesR")
1636056104328:# Load it like any other package:
1636056104349:#library(cesR)
1636056104372:# There are many different CES datasets, and they have unique codes.
1636056104393:# See them with the get_cescodes() function:
1636056104411:#get_cescodes()
1636056104428:# Now pick one, let's try ces2019_phone
1636056104445:#get_ces("ces2019_phone")
1636056104467:#survey_data <- ces2019_phone
1636056104491:# Alternative to what is in the comments above, I have locally loaded
1636056104513:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636056104534:# We can load it in:
1636056104555:survey_data <- read_csv("ces2019-phone_clean.csv")
1636056104801:#Cleaning Process:
1636056104825:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636056104845:survey_data <-
1636056104867:survey_data %>%
1636056104891:mutate(age = 2019-q2) %>%
1636056104952:select(age, p3,q3,q4)
1636056105126:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636056105152:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636056105170:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636056105204:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636056105224:survey_data <-
1636056105244:survey_data %>%
1636056105265:filter(q4 %in% (1:10))
1636056105293:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636056105311:survey_data <-
1636056105328:survey_data %>%
1636056105349:filter(p3 %in% (1:8))
1636056105390:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636056105410:census_data <- census_data %>%
1636056105430:mutate(age=round(age)) %>%
1636056105448:filter(province == "Newfoundland and Labrador"|
1636056105467:province == "Prince Edward Island"|
1636056105487:province == "Nova Scotia"| province == "New Brunswick"|
1636056105507:province == "Quebec"| province == "Ontario"|
1636056105527:province == "Manitoba"| province == "Saskatchewan"|
1636056105545:province == "Alberta"| province == "British Columbia") %>%
1636056105565:filter(sex == "Female" | sex == "Male") %>%
1636056105584:select(age, sex, province)
1636056105730:#update sex to survey sex code
1636056105748:census_data$sex[census_data$sex == "Male"] <- 1
1636056105787:census_data$sex[census_data$sex == "Female"] <- 2
1636056105809:#change province names to survey province code
1636056105834:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636056105873:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636056105911:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636056105937:census_data$province[census_data$province == "New Brunswick"] <- 4
1636056105961:census_data$province[census_data$province == "Quebec"] <- 5
1636056105988:census_data$province[census_data$province == "Ontario"] <- 6
1636056106012:census_data$province[census_data$province == "Manitoba"] <- 7
1636056106037:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636056106064:census_data$province[census_data$province == "Alberta"] <- 9
1636056106094:census_data$province[census_data$province == "British Columbia"] <- 10
1636056106124:#convert char columns in census to numeric
1636056106143:census_data$sex <- as.numeric(as.character(census_data$sex))
1636056106174:census_data$province <- as.numeric(as.character(census_data$province))
1636056106229:# Use this to calculate some summary measures.
1636056106251:library(readr)
1636056106274:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636056106294:summary(survey_data$age)
1636056106381:table(survey_data$q3)
1636056106441:table(survey_data$q4)
1636056106582:# Use this to create some plots. Should probably describe both the sample and population.
1636056106604:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636056106624:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636056106645:#
1636056106661:# par(las=2)
1636056106680:#
1636056106700:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636056106722:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636056106764:liberal_data <- survey_data %>%
1636056106783:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636056106806:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636056106853:summary(liberal_model)
1636056107398:conservative_data <- survey_data %>%
1636056107419:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636056107446:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636056107496:summary(conservative_model)
1636056108028:ndp_data <- survey_data %>%
1636056108049:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636056108076:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636056108117:summary(ndp_model)
1636056108683:blocq_data <- survey_data %>%
1636056108706:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636056108732:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636056108804:summary(blocq_model)
1636056109347:green_data <- survey_data %>%
1636056109365:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636056109402:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636056109455:summary(green_model)
1636056110005:people_data <- survey_data %>%
1636056110025:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636056110055:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636056110160:summary(people_model)
1636056110705:other_data <- survey_data %>%
1636056110725:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636056110751:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636056110820:summary(other_model)
1636056111267:## Model Selection
1636056111287:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636056111559:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636056111832:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636056112104:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636056112559:step(green_model, trace = 0, k = log(nrow(green_data)))
1636056112882:step(people_model, trace = 0, k = log(nrow(people_data)))
1636056113162:step(other_model, trace = 0, k = log(nrow(other_data)))
1636056113697:### Don't show the results/output here...
1636056113740:# Creating the Model
1636056113771:model <- glm(vote_liberal ~ age, data=survey_data, family="binomial")
1636058911363:liberal_data <- survey_data %>%
1636058911383:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636058911412:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636058911456:summary(liberal_model)
1636058912048:conservative_data <- survey_data %>%
1636058912068:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636058912097:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636058912144:summary(conservative_model)
1636058912730:ndp_data <- survey_data %>%
1636058912752:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636058912780:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636058912824:summary(ndp_model)
1636058913385:blocq_data <- survey_data %>%
1636058913409:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636058913438:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636058913515:summary(blocq_model)
1636058914103:green_data <- survey_data %>%
1636058914127:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636058914155:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636058914197:summary(green_model)
1636058914779:people_data <- survey_data %>%
1636058914803:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636058914831:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636058914892:summary(people_model)
1636058915485:other_data <- survey_data %>%
1636058915510:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636058915538:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636058915607:summary(other_model)
1636058916108:## Model Selection
1636058916131:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636058916606:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636058916868:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636058917177:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636058917780:step(green_model, trace = 0, k = log(nrow(green_data)))
1636058918081:step(people_model, trace = 0, k = log(nrow(people_data)))
1636058918394:step(other_model, trace = 0, k = log(nrow(other_data)))
1636058918878:### Don't show the results/output here...
1636058919221:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636058919243:library(openintro)
1636058919266:library(tidyverse)
1636058919315:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636058919341:census_data <- read_csv("gss_clean.csv")
1636058919485:# You may need additional chunks, in case you want to include some of the cleaning output.
1636058919538:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636058919567:# First, if you don't already have it, install the devtools package:
1636058919589:# install.packages("devtools")
1636058919615:# Now use devtools to install the cesR package directly from Github:
1636058919634:# devtools::install_github("hodgettsp/cesR")
1636058919794:# Load it like any other package:
1636058919815:#library(cesR)
1636058919832:# There are many different CES datasets, and they have unique codes.
1636058919851:# See them with the get_cescodes() function:
1636058919871:#get_cescodes()
1636058919893:# Now pick one, let's try ces2019_phone
1636058919921:#get_ces("ces2019_phone")
1636058919942:#survey_data <- ces2019_phone
1636058919963:# Alternative to what is in the comments above, I have locally loaded
1636058919986:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636058920008:# We can load it in:
1636058920025:survey_data <- read_csv("ces2019-phone_clean.csv")
1636058920460:#Cleaning Process:
1636058920486:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636058920507:survey_data <-
1636058920526:survey_data %>%
1636058920544:mutate(age = 2019-q2) %>%
1636058920563:select(age, p3,q3,q4)
1636058920594:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636058920614:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636058920630:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636058920677:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636058920697:survey_data <-
1636058920715:survey_data %>%
1636058920732:filter(q4 %in% (1:10))
1636058920756:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636058920774:survey_data <-
1636058920794:survey_data %>%
1636058920818:filter(p3 %in% (1:8))
1636058920863:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636058920885:census_data <- census_data %>%
1636058920907:mutate(age=round(age)) %>%
1636058920928:filter(province == "Newfoundland and Labrador"|
1636058920953:province == "Prince Edward Island"|
1636058920974:province == "Nova Scotia"| province == "New Brunswick"|
1636058920995:province == "Quebec"| province == "Ontario"|
1636058921022:province == "Manitoba"| province == "Saskatchewan"|
1636058921044:province == "Alberta"| province == "British Columbia") %>%
1636058921065:filter(sex == "Female" | sex == "Male") %>%
1636058921088:select(age, sex, province)
1636058921215:#update sex to survey sex code
1636058921240:census_data$sex[census_data$sex == "Male"] <- 1
1636058921277:census_data$sex[census_data$sex == "Female"] <- 2
1636058921303:#change province names to survey province code
1636058921325:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636058921365:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636058921396:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636058921426:census_data$province[census_data$province == "New Brunswick"] <- 4
1636058921454:census_data$province[census_data$province == "Quebec"] <- 5
1636058921482:census_data$province[census_data$province == "Ontario"] <- 6
1636058921508:census_data$province[census_data$province == "Manitoba"] <- 7
1636058921537:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636058921566:census_data$province[census_data$province == "Alberta"] <- 9
1636058921593:census_data$province[census_data$province == "British Columbia"] <- 10
1636058921619:#convert char columns in census to numeric
1636058921635:census_data$sex <- as.numeric(as.character(census_data$sex))
1636058921662:census_data$province <- as.numeric(as.character(census_data$province))
1636058921715:# Use this to calculate some summary measures.
1636058921735:library(readr)
1636058921752:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636058921772:summary(survey_data$age)
1636058921866:table(survey_data$q3)
1636058921928:table(survey_data$q4)
1636058922066:# Use this to create some plots. Should probably describe both the sample and population.
1636058922089:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636058922106:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636058922126:#
1636058922145:# par(las=2)
1636058922166:#
1636058922189:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636058922213:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636058922264:liberal_data <- survey_data %>%
1636058922290:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636058922320:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636058922358:summary(liberal_model)
1636058922955:conservative_data <- survey_data %>%
1636058922977:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636058923010:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636058923047:summary(conservative_model)
1636058923610:ndp_data <- survey_data %>%
1636058923630:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636058923656:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636058923703:summary(ndp_model)
1636058924267:blocq_data <- survey_data %>%
1636058924289:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636058924317:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636058924391:summary(blocq_model)
1636058925232:green_data <- survey_data %>%
1636058925269:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636058925304:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636058925347:summary(green_model)
1636058926347:people_data <- survey_data %>%
1636058926383:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636058926436:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636058926529:summary(people_model)
1636058927421:other_data <- survey_data %>%
1636058927441:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636058927471:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636058927543:summary(other_model)
1636058928247:## Model Selection
1636058928282:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636058928729:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636058929049:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636058929367:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636058929813:step(green_model, trace = 0, k = log(nrow(green_data)))
1636058930135:step(people_model, trace = 0, k = log(nrow(people_data)))
1636058930478:step(other_model, trace = 0, k = log(nrow(other_data)))
1636058930823:### Don't show the results/output here...
1636058930876:# Creating the Model
1636058930906:model <- glm(vote_liberal ~ age, data=survey_data, family="binomial")
1636058939698:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636058939723:library(openintro)
1636058939745:library(tidyverse)
1636058939789:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636058939816:census_data <- read_csv("gss_clean.csv")
1636058939957:# You may need additional chunks, in case you want to include some of the cleaning output.
1636058940009:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636058940031:# First, if you don't already have it, install the devtools package:
1636058940056:# install.packages("devtools")
1636058940074:# Now use devtools to install the cesR package directly from Github:
1636058940095:# devtools::install_github("hodgettsp/cesR")
1636058940259:# Load it like any other package:
1636058940280:#library(cesR)
1636058940300:# There are many different CES datasets, and they have unique codes.
1636058940319:# See them with the get_cescodes() function:
1636058940338:#get_cescodes()
1636058940360:# Now pick one, let's try ces2019_phone
1636058940379:#get_ces("ces2019_phone")
1636058940400:#survey_data <- ces2019_phone
1636058940418:# Alternative to what is in the comments above, I have locally loaded
1636058940437:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636058940459:# We can load it in:
1636058940482:survey_data <- read_csv("ces2019-phone_clean.csv")
1636058940752:#Cleaning Process:
1636058940781:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636058940803:survey_data <-
1636058940822:survey_data %>%
1636058940839:mutate(age = 2019-q2) %>%
1636058940856:select(age, p3,q3,q4)
1636058940890:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636058940913:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636058940936:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636058940977:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636058941001:survey_data <-
1636058941025:survey_data %>%
1636058941042:filter(q4 %in% (1:10))
1636058941070:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636058941094:survey_data <-
1636058941115:survey_data %>%
1636058941132:filter(p3 %in% (1:8))
1636058941181:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636058941200:census_data <- census_data %>%
1636058941221:mutate(age=round(age)) %>%
1636058941238:filter(province == "Newfoundland and Labrador"|
1636058941259:province == "Prince Edward Island"|
1636058941278:province == "Nova Scotia"| province == "New Brunswick"|
1636058941298:province == "Quebec"| province == "Ontario"|
1636058941321:province == "Manitoba"| province == "Saskatchewan"|
1636058941339:province == "Alberta"| province == "British Columbia") %>%
1636058941359:filter(sex == "Female" | sex == "Male") %>%
1636058941378:select(age, sex, province)
1636058941503:#update sex to survey sex code
1636058941523:census_data$sex[census_data$sex == "Male"] <- 1
1636058941557:census_data$sex[census_data$sex == "Female"] <- 2
1636058941577:#change province names to survey province code
1636058941600:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636058941642:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636058941666:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636058941696:census_data$province[census_data$province == "New Brunswick"] <- 4
1636058941723:census_data$province[census_data$province == "Quebec"] <- 5
1636058941748:census_data$province[census_data$province == "Ontario"] <- 6
1636058941772:census_data$province[census_data$province == "Manitoba"] <- 7
1636058941797:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636058941823:census_data$province[census_data$province == "Alberta"] <- 9
1636058941849:census_data$province[census_data$province == "British Columbia"] <- 10
1636058941872:#convert char columns in census to numeric
1636058941892:census_data$sex <- as.numeric(as.character(census_data$sex))
1636058941929:census_data$province <- as.numeric(as.character(census_data$province))
1636058941979:# Use this to calculate some summary measures.
1636058942000:library(readr)
1636058942018:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636058942038:summary(survey_data$age)
1636058942118:table(survey_data$q3)
1636058942174:table(survey_data$q4)
1636058942312:# Use this to create some plots. Should probably describe both the sample and population.
1636058942337:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636058942356:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636058942375:#
1636058942396:# par(las=2)
1636058942416:#
1636058942434:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636058942455:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636058942498:liberal_data <- survey_data %>%
1636058942522:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636058942547:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636058942583:summary(liberal_model)
1636058943135:conservative_data <- survey_data %>%
1636058943153:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636058943179:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636058943219:summary(conservative_model)
1636058943780:ndp_data <- survey_data %>%
1636058943797:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636058943821:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636058943861:summary(ndp_model)
1636058944469:blocq_data <- survey_data %>%
1636058944490:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636058944518:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636058944599:summary(blocq_model)
1636058945183:green_data <- survey_data %>%
1636058945206:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636058945234:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636058945289:summary(green_model)
1636058945900:people_data <- survey_data %>%
1636058945923:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636058945950:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636058946021:summary(people_model)
1636058946613:other_data <- survey_data %>%
1636058946634:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636058946665:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636058946736:summary(other_model)
1636058947258:## Model Selection
1636058947279:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636058947561:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636058947849:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636058948134:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636058948619:step(green_model, trace = 0, k = log(nrow(green_data)))
1636058948938:step(people_model, trace = 0, k = log(nrow(people_data)))
1636058949429:step(other_model, trace = 0, k = log(nrow(other_data)))
1636058949887:### Don't show the results/output here...
1636058949931:# Creating the Model
1636058949955:model <- glm(vote_liberal ~ age, data=survey_data, family="binomial")
1636059184798:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636059184818:library(openintro)
1636059184837:library(tidyverse)
1636059184881:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636059184904:census_data <- read_csv("gss_clean.csv")
1636059185060:# You may need additional chunks, in case you want to include some of the cleaning output.
1636059185101:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636059185123:# First, if you don't already have it, install the devtools package:
1636059185141:# install.packages("devtools")
1636059185159:# Now use devtools to install the cesR package directly from Github:
1636059185177:# devtools::install_github("hodgettsp/cesR")
1636059185358:# Load it like any other package:
1636059185378:#library(cesR)
1636059185398:# There are many different CES datasets, and they have unique codes.
1636059185417:# See them with the get_cescodes() function:
1636059185436:#get_cescodes()
1636059185455:# Now pick one, let's try ces2019_phone
1636059185475:#get_ces("ces2019_phone")
1636059185495:#survey_data <- ces2019_phone
1636059185515:# Alternative to what is in the comments above, I have locally loaded
1636059185535:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636059185555:# We can load it in:
1636059185576:survey_data <- read_csv("ces2019-phone_clean.csv")
1636059185995:#Cleaning Process:
1636059186021:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636059186040:survey_data <-
1636059186063:survey_data %>%
1636059186085:mutate(age = 2019-q2) %>%
1636059186108:select(age, p3,q3,q4)
1636059186156:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636059186177:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636059186201:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636059186231:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636059186249:survey_data <-
1636059186266:survey_data %>%
1636059186284:filter(q4 %in% (1:10))
1636059186309:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636059186330:survey_data <-
1636059186350:survey_data %>%
1636059186370:filter(p3 %in% (1:8))
1636059186427:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636059186446:census_data <- census_data %>%
1636059186472:mutate(age=round(age)) %>%
1636059186498:filter(province == "Newfoundland and Labrador"|
1636059186517:province == "Prince Edward Island"|
1636059186536:province == "Nova Scotia"| province == "New Brunswick"|
1636059186559:province == "Quebec"| province == "Ontario"|
1636059186581:province == "Manitoba"| province == "Saskatchewan"|
1636059186609:province == "Alberta"| province == "British Columbia") %>%
1636059186628:filter(sex == "Female" | sex == "Male") %>%
1636059186648:select(age, sex, province)
1636059186778:#update sex to survey sex code
1636059186800:census_data$sex[census_data$sex == "Male"] <- 1
1636059186841:census_data$sex[census_data$sex == "Female"] <- 2
1636059186863:#change province names to survey province code
1636059186882:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636059186921:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636059186947:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636059186975:census_data$province[census_data$province == "New Brunswick"] <- 4
1636059187006:census_data$province[census_data$province == "Quebec"] <- 5
1636059187037:census_data$province[census_data$province == "Ontario"] <- 6
1636059187064:census_data$province[census_data$province == "Manitoba"] <- 7
1636059187090:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636059187115:census_data$province[census_data$province == "Alberta"] <- 9
1636059187141:census_data$province[census_data$province == "British Columbia"] <- 10
1636059187166:#convert char columns in census to numeric
1636059187185:census_data$sex <- as.numeric(as.character(census_data$sex))
1636059187217:census_data$province <- as.numeric(as.character(census_data$province))
1636059187269:# Use this to calculate some summary measures.
1636059187294:library(readr)
1636059187315:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636059187335:summary(survey_data$age)
1636059187409:table(survey_data$q3)
1636059187461:table(survey_data$q4)
1636059187604:# Use this to create some plots. Should probably describe both the sample and population.
1636059187633:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636059187656:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636059187678:#
1636059187701:# par(las=2)
1636059187721:#
1636059187742:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636059187761:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636059187822:liberal_data <- survey_data %>%
1636059187851:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636059187878:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636059187916:summary(liberal_model)
1636059188441:conservative_data <- survey_data %>%
1636059188461:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636059188487:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636059188522:summary(conservative_model)
1636059189025:ndp_data <- survey_data %>%
1636059189043:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636059189070:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636059189107:summary(ndp_model)
1636059189611:blocq_data <- survey_data %>%
1636059189632:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636059189656:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636059189729:summary(blocq_model)
1636059190220:green_data <- survey_data %>%
1636059190239:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636059190264:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636059190302:summary(green_model)
1636059190776:people_data <- survey_data %>%
1636059190793:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636059190818:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636059190886:summary(people_model)
1636059191384:other_data <- survey_data %>%
1636059191403:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636059191431:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636059191501:summary(other_model)
1636059191970:## Model Selection
1636059191994:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636059192274:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636059192558:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636059192830:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636059193287:step(green_model, trace = 0, k = log(nrow(green_data)))
1636059193641:step(people_model, trace = 0, k = log(nrow(people_data)))
1636059193941:step(other_model, trace = 0, k = log(nrow(other_data)))
1636059194271:### Don't show the results/output here...
1636059194332:# Creating the Model
1636059194359:model <- glm(vote_liberal ~ age, data=survey_data, family="binomial")
1636062429791:# Here I will perform the post-stratification calculation
1636062429811:census_data_counts <- census_data %>%
1636062429831:group_by(age) %>%
1636062429850:summarise(n=n())
1636062429887:census_data_counts$estimate <-
1636062429908:model %>%
1636062429926:predict(newdata = census_data_counts)
1636062546049:# Creating the Model
1636062546069:model <- glm(p3 ~ age, data=survey_data, family="binomial")
1636062743972:# Creating the Model
1636062743996:model <- glm(votedliberal ~ age, data=survey_data, family="binomial")
1636062871333:# Creating the Model
1636062871357:model <- glm(votedliberal ~ age, data=liberal_data, family="binomial")
1636062871386:# Model Results (to Report in Results section)
1636062871406:# summary(model)
1636062871427:# OR
1636062871447:# broom::tidy(model)
1636062876597:# Creating the Model
1636062876621:model <- glm(votedliberal ~ age, data=liberal_data, family="binomial")
1636062876653:# Model Results (to Report in Results section)
1636062876675:# summary(model)
1636062876697:# OR
1636062876720:# broom::tidy(model)
1636062878530:# Creating the Model
1636062878555:model <- glm(votedliberal ~ age, data=liberal_data, family="binomial")
1636062878585:# Model Results (to Report in Results section)
1636062878609:# summary(model)
1636062878631:# OR
1636062878653:# broom::tidy(model)
1636062888241:# Creating the Model
1636062888262:model <- glm(votedliberal ~ age, data=liberal_data, family="binomial")
1636062888290:# Model Results (to Report in Results section)
1636062888315:summary(model)
1636062888647:# OR
1636062888670:# broom::tidy(model)
1636063330445:# Creating the Model
1636063330467:model_liberal <- glm(votedliberal ~ age + sex + province, data=liberal_data, family="binomial")
1636063572628:# Creating the Model
1636063572648:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636063572690:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636063572729:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636063572772:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636063572850:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636063572890:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636063572958:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636063573022:# Model Results (to Report in Results section)
1636063573043:summary(liberal_model)
1636063573572:# OR
1636063573592:# broom::tidy(model)
1636063652224:# Here I will perform the post-stratification calculation
1636063652245:census_data_counts <- census_data %>%
1636063652266:group_by(age) %>%
1636063652286:summarise(n=n())
1636063652317:census_data_counts$estimate <-
1636063652339:model %>%
1636063652363:predict(newdata = census_data_counts)
1636063652391:census_data_counts %>%
1636063652412:mutate(liberal_predict_prop = estimate*n) %>%
1636063652433:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636063712375:View(census_data_counts)
1636064391685:# Creating the Model
1636064391709:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636064391751:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636064391798:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636064391839:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636064391908:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636064391952:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636064392036:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636064392110:# Model Results (to Report in Results section)
1636064392129:#summary(liberal_model)
1636064392150:# OR
1636064392173:# broom::tidy(model)
1636064395906:# Here I will perform the post-stratification calculation
1636064395936:census_data_counts <- census_data %>%
1636064395955:group_by(age) %>%
1636064395977:summarise(n=n())
1636064396020:census_data_counts$estimate <-
1636064396038:model %>%
1636064396060:predict(newdata = census_data_counts)
1636064396082:census_data_counts %>%
1636064396104:mutate(liberal_predict_prop = estimate*n) %>%
1636064396122:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636064552612:# Here I will perform the post-stratification calculation
1636064552633:census_data_counts <- census_data %>%
1636064552658:group_by(age) %>%
1636064552682:summarise(n=n())
1636064552710:census_data_counts$estimate <-
1636064552729:liberal_model %>%
1636064552748:predict(newdata = census_data_counts)
1636064579645:# Here I will perform the post-stratification calculation
1636064579665:census_data_counts <- census_data %>%
1636064579684:group_by(age) %>%
1636064579703:summarise(n=n())
1636064579733:census_data_counts$estimate <-
1636064579754:liberal_model %>%
1636064579773:predict(newdata = census_data)
1636064581132:# Here I will perform the post-stratification calculation
1636064581154:census_data_counts <- census_data %>%
1636064581175:group_by(age) %>%
1636064581195:summarise(n=n())
1636064581225:census_data_counts$estimate <-
1636064581242:liberal_model %>%
1636064581263:predict(newdata = census_data)
1636064593017:# Creating the Model
1636064593042:liberal_model <- glm(votedliberal ~ age + q3 + as.factor(q4), data = liberal_data, family = binomial)
1636064593077:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636064593126:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636064593164:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636064593230:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636064593278:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636064593345:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636064593412:# Model Results (to Report in Results section)
1636064593434:#summary(liberal_model)
1636064593454:# OR
1636064593478:# broom::tidy(model)
1636064595307:# Here I will perform the post-stratification calculation
1636064595330:census_data_counts <- census_data %>%
1636064595353:group_by(age) %>%
1636064595376:summarise(n=n())
1636064595409:census_data_counts$estimate <-
1636064595429:liberal_model %>%
1636064595450:predict(newdata = census_data)
1636064617924:View(liberal_model)
1636064687632:# Here I will perform the post-stratification calculation
1636064687652:census_data_counts <- census_data %>%
1636064687673:group_by(age) %>%
1636064687694:summarise(n=n())
1636064687731:census_data_counts$estimate <-
1636064687751:liberal_model %>%
1636064687769:predict(newdata = census_data_counts)
1636064689432:# Here I will perform the post-stratification calculation
1636064689454:census_data_counts <- census_data %>%
1636064689474:group_by(age) %>%
1636064689493:summarise(n=n())
1636064689523:census_data_counts$estimate <-
1636064689544:liberal_model %>%
1636064689565:predict(newdata = census_data_counts)
1636064712916:# Creating the Model
1636064712939:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636064712976:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636064713025:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636064713065:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636064713162:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636064713202:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636064713268:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636064713340:# Model Results (to Report in Results section)
1636064713363:#summary(liberal_model)
1636064713386:# OR
1636064713406:# broom::tidy(model)
1636064715140:# Here I will perform the post-stratification calculation
1636064715162:census_data_counts <- census_data %>%
1636064715183:group_by(age) %>%
1636064715204:summarise(n=n())
1636064715236:census_data_counts$estimate <-
1636064715255:liberal_model %>%
1636064715275:predict(newdata = census_data_counts)
1636064727695:View(liberal_data)
1636065068822:View(census_data)
1636065128525:# Creating the Model
1636065128548:liberal_model <- glm(votedliberal ~ age + as.factor(sex) + as.factor(q4), data = liberal_data, family = binomial)
1636065134512:# Creating the Model
1636065134534:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636065134589:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636065134629:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636065134672:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636065134747:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636065134791:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636065134858:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636065135142:# Model Results (to Report in Results section)
1636065135167:#summary(liberal_model)
1636065135189:# OR
1636065135216:# broom::tidy(model)
1636065445735:View(liberal_data)
1636065471725:# Creating the Model
1636065471749:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = surveydata, family = binomial)
1636065477434:# Creating the Model
1636065477455:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = survey_data, family = binomial)
1636065977212:liberal_data <- survey_data %>%
1636065977232:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636065977257:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636065977295:summary(liberal_model)
1636065977831:conservative_data <- survey_data %>%
1636065977850:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636065977877:conservative_model <- glm(votedconservative ~ age + sex + as.factor(q4), data = conservative_data, family = binomial)
1636065995261:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636065995280:library(openintro)
1636065995299:library(tidyverse)
1636065995342:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636065995365:census_data <- read_csv("gss_clean.csv")
1636065995505:# You may need additional chunks, in case you want to include some of the cleaning output.
1636065995549:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636065995575:# First, if you don't already have it, install the devtools package:
1636065995595:# install.packages("devtools")
1636065995613:# Now use devtools to install the cesR package directly from Github:
1636065995636:# devtools::install_github("hodgettsp/cesR")
1636065995805:# Load it like any other package:
1636065995824:#library(cesR)
1636065995848:# There are many different CES datasets, and they have unique codes.
1636065995867:# See them with the get_cescodes() function:
1636065995888:#get_cescodes()
1636065995906:# Now pick one, let's try ces2019_phone
1636065995926:#get_ces("ces2019_phone")
1636065995945:#survey_data <- ces2019_phone
1636065995967:# Alternative to what is in the comments above, I have locally loaded
1636065995988:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636065996008:# We can load it in:
1636065996027:survey_data <- read_csv("ces2019-phone_clean.csv")
1636065996477:#Cleaning Process:
1636065996501:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636065996520:survey_data <-
1636065996542:survey_data %>%
1636065996561:mutate(age = 2019-q2) %>%
1636065996581:select(age, p3,q3,q4)
1636065996613:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636065996632:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636065996654:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636065996690:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636065996712:survey_data <-
1636065996732:survey_data %>%
1636065996752:filter(q4 %in% (1:10))
1636065996777:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636065996795:survey_data <-
1636065996816:survey_data %>%
1636065996836:filter(p3 %in% (1:8))
1636065996882:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636065996904:census_data <- census_data %>%
1636065996926:mutate(age=round(age)) %>%
1636065996945:filter(province == "Newfoundland and Labrador"|
1636065996965:province == "Prince Edward Island"|
1636065996986:province == "Nova Scotia"| province == "New Brunswick"|
1636065997009:province == "Quebec"| province == "Ontario"|
1636065997028:province == "Manitoba"| province == "Saskatchewan"|
1636065997049:province == "Alberta"| province == "British Columbia") %>%
1636065997065:filter(sex == "Female" | sex == "Male") %>%
1636065997089:select(age, sex, province)
1636065997207:#update sex to survey sex code
1636065997226:census_data$sex[census_data$sex == "Male"] <- 1
1636065997260:census_data$sex[census_data$sex == "Female"] <- 2
1636065997284:#change province names to survey province code
1636065997302:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636065997339:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636065997369:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636065997395:census_data$province[census_data$province == "New Brunswick"] <- 4
1636065997424:census_data$province[census_data$province == "Quebec"] <- 5
1636065997450:census_data$province[census_data$province == "Ontario"] <- 6
1636065997475:census_data$province[census_data$province == "Manitoba"] <- 7
1636065997501:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636065997527:census_data$province[census_data$province == "Alberta"] <- 9
1636065997554:census_data$province[census_data$province == "British Columbia"] <- 10
1636065997583:#convert char columns in census to numeric
1636065997603:census_data$sex <- as.numeric(as.character(census_data$sex))
1636065997632:census_data$province <- as.numeric(as.character(census_data$province))
1636065997684:# Use this to calculate some summary measures.
1636065997709:library(readr)
1636065997730:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636065997753:summary(survey_data$age)
1636065997832:table(survey_data$q3)
1636065997883:table(survey_data$q4)
1636065998014:# Use this to create some plots. Should probably describe both the sample and population.
1636065998039:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636065998059:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636065998079:#
1636065998098:# par(las=2)
1636065998119:#
1636065998137:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636065998157:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636065998201:liberal_data <- survey_data %>%
1636065998225:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636065998253:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636065998303:summary(liberal_model)
1636065998840:conservative_data <- survey_data %>%
1636065998860:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636065998886:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636065998923:summary(conservative_model)
1636065999427:ndp_data <- survey_data %>%
1636065999444:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636065999469:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636065999533:summary(ndp_model)
1636066000092:blocq_data <- survey_data %>%
1636066000113:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636066000144:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636066000207:summary(blocq_model)
1636066000815:green_data <- survey_data %>%
1636066000836:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636066000863:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636066000900:summary(green_model)
1636066001454:people_data <- survey_data %>%
1636066001478:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636066001508:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636066001579:summary(people_model)
1636066002114:other_data <- survey_data %>%
1636066002132:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636066002157:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636066002226:summary(other_model)
1636066002714:## Model Selection
1636066002734:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636066002991:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636066003274:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636066003541:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636066003975:step(green_model, trace = 0, k = log(nrow(green_data)))
1636066004265:step(people_model, trace = 0, k = log(nrow(people_data)))
1636066004553:step(other_model, trace = 0, k = log(nrow(other_data)))
1636066004836:### Don't show the results/output here...
1636066004884:# Creating the Model
1636066004907:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636066004958:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636066004998:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636066005041:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636066005115:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636066005182:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636066005261:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636066005338:# Model Results (to Report in Results section)
1636066005361:#summary(liberal_model)
1636066005384:# OR
1636066005406:# broom::tidy(model)
1636066005456:# Here I will perform the post-stratification calculation
1636066005484:census_data_counts <- census_data %>%
1636066005504:group_by(age) %>%
1636066005524:summarise(n=n())
1636066005568:census_data_counts$estimate <-
1636066005588:liberal_model %>%
1636066005607:predict(newdata = census_data_counts)
1636067504176:View(survey_data)
1636067557938:View(survey_data)
1636067585648:View(survey_data)
1636067633837:View(census_data)
1636067751358:View(survey_data)
1636068732541:#Cleaning Process:
1636068732561:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068732581:survey_data <-
1636068732600:survey_data %>%
1636068732617:mutate(age = 2019-q2) %>%
1636068732637:select(age, p3,q3,q4) %>%
1636068732657:survey_data %>% rename(q3=sex , q4=province)
1636068737889:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636068737908:library(openintro)
1636068737927:library(tidyverse)
1636068737971:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636068737993:census_data <- read_csv("gss_clean.csv")
1636068738146:# You may need additional chunks, in case you want to include some of the cleaning output.
1636068738179:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636068738201:# First, if you don't already have it, install the devtools package:
1636068738222:# install.packages("devtools")
1636068738239:# Now use devtools to install the cesR package directly from Github:
1636068738256:# devtools::install_github("hodgettsp/cesR")
1636068738417:# Load it like any other package:
1636068738433:#library(cesR)
1636068738452:# There are many different CES datasets, and they have unique codes.
1636068738470:# See them with the get_cescodes() function:
1636068738486:#get_cescodes()
1636068738502:# Now pick one, let's try ces2019_phone
1636068738521:#get_ces("ces2019_phone")
1636068738545:#survey_data <- ces2019_phone
1636068738563:# Alternative to what is in the comments above, I have locally loaded
1636068738581:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636068738601:# We can load it in:
1636068738620:survey_data <- read_csv("ces2019-phone_clean.csv")
1636068739024:#Cleaning Process:
1636068739064:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068739084:survey_data <-
1636068739102:survey_data %>%
1636068739119:mutate(age = 2019-q2) %>%
1636068739137:select(age, p3,q3,q4) %>%
1636068739153:survey_data %>% rename(q3=sex , q4=province)
1636068750693:#Cleaning Process:
1636068750712:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068750729:survey_data <-
1636068750748:survey_data %>%
1636068750768:mutate(age = 2019-q2) %>%
1636068750786:select(age, p3,q3,q4) %>%
1636068750805:rename(q3=sex , q4=province)
1636068775214:#Cleaning Process:
1636068775231:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068775247:survey_data <-
1636068775263:survey_data %>%
1636068775278:mutate(age = 2019-q2) %>%
1636068775298:select(age, p3,q3,q4) %>%
1636068775316:rename(sex=q3 , province=q4)
1636068775360:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636068775378:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636068775395:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636068781020:View(survey_data)
1636068837712:#Cleaning Process:
1636068837735:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068837756:survey_data <-
1636068837774:survey_data %>%
1636068837793:mutate(age = 2019-q2) %>%
1636068837815:select(age, p3,q3,q4) %>%
1636068837836:rename(sex=q3 , province=q4)
1636068843622:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636068843638:library(openintro)
1636068843652:library(tidyverse)
1636068843697:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636068843720:census_data <- read_csv("gss_clean.csv")
1636068843895:# You may need additional chunks, in case you want to include some of the cleaning output.
1636068843939:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636068843965:# First, if you don't already have it, install the devtools package:
1636068843985:# install.packages("devtools")
1636068844007:# Now use devtools to install the cesR package directly from Github:
1636068844024:# devtools::install_github("hodgettsp/cesR")
1636068844202:# Load it like any other package:
1636068844223:#library(cesR)
1636068844243:# There are many different CES datasets, and they have unique codes.
1636068844262:# See them with the get_cescodes() function:
1636068844281:#get_cescodes()
1636068844300:# Now pick one, let's try ces2019_phone
1636068844317:#get_ces("ces2019_phone")
1636068844334:#survey_data <- ces2019_phone
1636068844351:# Alternative to what is in the comments above, I have locally loaded
1636068844367:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636068844383:# We can load it in:
1636068844398:survey_data <- read_csv("ces2019-phone_clean.csv")
1636068844629:#Cleaning Process:
1636068844653:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068844671:survey_data <-
1636068844690:survey_data %>%
1636068844707:mutate(age = 2019-q2) %>%
1636068844727:select(age, p3,q3,q4) %>%
1636068844745:rename(sex=q3 , province=q4)
1636068844805:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636068844824:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636068844842:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636068844877:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636068844895:survey_data <-
1636068844915:survey_data %>%
1636068844933:filter(q4 %in% (1:10))
1636068858133:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636068858152:library(openintro)
1636068858169:library(tidyverse)
1636068858209:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636068858233:census_data <- read_csv("gss_clean.csv")
1636068858370:# You may need additional chunks, in case you want to include some of the cleaning output.
1636068858415:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636068858436:# First, if you don't already have it, install the devtools package:
1636068858455:# install.packages("devtools")
1636068858472:# Now use devtools to install the cesR package directly from Github:
1636068858488:# devtools::install_github("hodgettsp/cesR")
1636068858646:# Load it like any other package:
1636068858666:#library(cesR)
1636068858684:# There are many different CES datasets, and they have unique codes.
1636068858702:# See them with the get_cescodes() function:
1636068858719:#get_cescodes()
1636068858737:# Now pick one, let's try ces2019_phone
1636068858758:#get_ces("ces2019_phone")
1636068858778:#survey_data <- ces2019_phone
1636068858797:# Alternative to what is in the comments above, I have locally loaded
1636068858816:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636068858837:# We can load it in:
1636068858855:survey_data <- read_csv("ces2019-phone_clean.csv")
1636068859083:#Cleaning Process:
1636068859106:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068859126:survey_data <-
1636068859148:survey_data %>%
1636068859171:mutate(age = 2019-q2) %>%
1636068859190:select(age, p3,q3,q4) %>%
1636068859208:rename(sex=q3 , province=q4)
1636068859252:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636068859272:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636068859293:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636068859325:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636068859346:survey_data <-
1636068859369:survey_data %>%
1636068859389:filter(province %in% (1:10))
1636068859414:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636068859435:survey_data <-
1636068859453:survey_data %>%
1636068859472:filter(p3 %in% (1:8))
1636068859512:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636068859531:census_data <- census_data %>%
1636068859549:mutate(age=round(age)) %>%
1636068859564:filter(province == "Newfoundland and Labrador"|
1636068859587:province == "Prince Edward Island"|
1636068859605:province == "Nova Scotia"| province == "New Brunswick"|
1636068859622:province == "Quebec"| province == "Ontario"|
1636068859640:province == "Manitoba"| province == "Saskatchewan"|
1636068859658:province == "Alberta"| province == "British Columbia") %>%
1636068859678:filter(sex == "Female" | sex == "Male") %>%
1636068859697:select(age, sex, province)
1636068859823:#update sex to survey sex code
1636068859841:census_data$sex[census_data$sex == "Male"] <- 1
1636068859875:census_data$sex[census_data$sex == "Female"] <- 2
1636068859894:#change province names to survey province code
1636068859913:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636068859951:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636068859976:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636068859999:census_data$province[census_data$province == "New Brunswick"] <- 4
1636068860022:census_data$province[census_data$province == "Quebec"] <- 5
1636068860047:census_data$province[census_data$province == "Ontario"] <- 6
1636068860072:census_data$province[census_data$province == "Manitoba"] <- 7
1636068860098:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636068860123:census_data$province[census_data$province == "Alberta"] <- 9
1636068860148:census_data$province[census_data$province == "British Columbia"] <- 10
1636068860172:#convert char columns in census to numeric
1636068860194:census_data$sex <- as.numeric(as.character(census_data$sex))
1636068860220:census_data$province <- as.numeric(as.character(census_data$province))
1636068860266:# Use this to calculate some summary measures.
1636068860288:library(readr)
1636068860309:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636068860329:summary(survey_data$age)
1636068860408:table(survey_data$q3)
1636068860452:table(survey_data$q4)
1636068860512:# Use this to create some plots. Should probably describe both the sample and population.
1636068860540:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636068860559:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636068860579:#
1636068860599:# par(las=2)
1636068860619:#
1636068860639:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636068860656:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636068860689:liberal_data <- survey_data %>%
1636068860711:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636068860734:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636068866488:liberal_data <- survey_data %>%
1636068866511:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636068866537:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636068908871:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636068908889:library(openintro)
1636068908907:library(tidyverse)
1636068908948:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636068908972:census_data <- read_csv("gss_clean.csv")
1636068909115:# You may need additional chunks, in case you want to include some of the cleaning output.
1636068909153:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636068909174:# First, if you don't already have it, install the devtools package:
1636068909204:# install.packages("devtools")
1636068909223:# Now use devtools to install the cesR package directly from Github:
1636068909242:# devtools::install_github("hodgettsp/cesR")
1636068909403:# Load it like any other package:
1636068909421:#library(cesR)
1636068909440:# There are many different CES datasets, and they have unique codes.
1636068909458:# See them with the get_cescodes() function:
1636068909474:#get_cescodes()
1636068909494:# Now pick one, let's try ces2019_phone
1636068909511:#get_ces("ces2019_phone")
1636068909530:#survey_data <- ces2019_phone
1636068909550:# Alternative to what is in the comments above, I have locally loaded
1636068909568:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636068909588:# We can load it in:
1636068909604:survey_data <- read_csv("ces2019-phone_clean.csv")
1636068909871:#Cleaning Process:
1636068909920:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636068909941:survey_data <-
1636068909960:survey_data %>%
1636068909978:mutate(age = 2019-q2) %>%
1636068909996:select(age, p3,q3,q4) %>%
1636068910013:rename(sex=q3 , province=q4)
1636068910044:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636068910063:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636068910079:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636068910110:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636068910130:survey_data <-
1636068910149:survey_data %>%
1636068910168:filter(province %in% (1:10))
1636068910194:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636068910213:survey_data <-
1636068910232:survey_data %>%
1636068910254:filter(p3 %in% (1:8))
1636068910289:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636068910306:census_data <- census_data %>%
1636068910325:mutate(age=round(age)) %>%
1636068910343:filter(province == "Newfoundland and Labrador"|
1636068910362:province == "Prince Edward Island"|
1636068910380:province == "Nova Scotia"| province == "New Brunswick"|
1636068910397:province == "Quebec"| province == "Ontario"|
1636068910415:province == "Manitoba"| province == "Saskatchewan"|
1636068910433:province == "Alberta"| province == "British Columbia") %>%
1636068910453:filter(sex == "Female" | sex == "Male") %>%
1636068910471:select(age, sex, province)
1636068910583:#update sex to survey sex code
1636068910602:census_data$sex[census_data$sex == "Male"] <- 1
1636068910634:census_data$sex[census_data$sex == "Female"] <- 2
1636068910654:#change province names to survey province code
1636068910673:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636068910706:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636068910730:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636068910755:census_data$province[census_data$province == "New Brunswick"] <- 4
1636068910780:census_data$province[census_data$province == "Quebec"] <- 5
1636068910805:census_data$province[census_data$province == "Ontario"] <- 6
1636068910829:census_data$province[census_data$province == "Manitoba"] <- 7
1636068910854:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636068910875:census_data$province[census_data$province == "Alberta"] <- 9
1636068910899:census_data$province[census_data$province == "British Columbia"] <- 10
1636068910921:#convert char columns in census to numeric
1636068910939:census_data$sex <- as.numeric(as.character(census_data$sex))
1636068910963:census_data$province <- as.numeric(as.character(census_data$province))
1636068911014:# Use this to calculate some summary measures.
1636068911047:library(readr)
1636068911065:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636068911086:summary(survey_data$age)
1636068911156:table(survey_data$q3)
1636068911200:table(survey_data$q4)
1636068911266:# Use this to create some plots. Should probably describe both the sample and population.
1636068911294:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636068911312:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636068911330:#
1636068911351:# par(las=2)
1636068911371:#
1636068911393:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636068911415:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636068911457:liberal_data <- survey_data %>%
1636068911479:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636068911506:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636068911550:summary(liberal_model)
1636068911909:conservative_data <- survey_data %>%
1636068911929:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636068911953:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636068911982:summary(conservative_model)
1636068912296:ndp_data <- survey_data %>%
1636068912313:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636068912337:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636068912366:summary(ndp_model)
1636068912690:blocq_data <- survey_data %>%
1636068912710:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636068912738:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636068912776:summary(blocq_model)
1636068913122:green_data <- survey_data %>%
1636068913142:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636068913172:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636068913222:summary(green_model)
1636068913548:people_data <- survey_data %>%
1636068913567:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636068913596:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636068913627:summary(people_model)
1636068913929:other_data <- survey_data %>%
1636068913947:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636068913974:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636068914027:summary(other_model)
1636068914310:## Model Selection
1636068914326:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636068914521:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636068914725:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636068914921:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636068915142:step(green_model, trace = 0, k = log(nrow(green_data)))
1636068915372:step(people_model, trace = 0, k = log(nrow(people_data)))
1636068915609:step(other_model, trace = 0, k = log(nrow(other_data)))
1636068916109:### Don't show the results/output here...
1636068916145:# Creating the Model
1636068916169:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636068916197:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636068916226:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636068916254:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636068916283:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636068916312:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636068916354:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636068916386:# Model Results (to Report in Results section)
1636068916402:#summary(liberal_model)
1636068916421:# OR
1636068916437:# broom::tidy(model)
1636068916474:# Here I will perform the post-stratification calculation
1636068916496:census_data_counts <- census_data %>%
1636068916512:group_by(age) %>%
1636068916529:summarise(n=n())
1636068916557:census_data_counts$estimate <-
1636068916575:liberal_model %>%
1636068916592:predict(newdata = census_data_counts)
1636068921082:# Here I will perform the post-stratification calculation
1636068921102:census_data_counts <- census_data %>%
1636068921123:group_by(age) %>%
1636068921145:summarise(n=n())
1636068921175:census_data_counts$estimate <-
1636068921195:liberal_model %>%
1636068921217:predict(newdata = census_data_counts)
1636070198383:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636070198403:library(openintro)
1636070198425:library(tidyverse)
1636070198463:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636070198491:census_data <- read_csv("gss_clean.csv")
1636070198636:# You may need additional chunks, in case you want to include some of the cleaning output.
1636070198673:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636070198695:# First, if you don't already have it, install the devtools package:
1636070198714:# install.packages("devtools")
1636070198732:# Now use devtools to install the cesR package directly from Github:
1636070198751:# devtools::install_github("hodgettsp/cesR")
1636070198933:# Load it like any other package:
1636070198952:#library(cesR)
1636070198972:# There are many different CES datasets, and they have unique codes.
1636070198990:# See them with the get_cescodes() function:
1636070199012:#get_cescodes()
1636070199029:# Now pick one, let's try ces2019_phone
1636070199047:#get_ces("ces2019_phone")
1636070199067:#survey_data <- ces2019_phone
1636070199092:# Alternative to what is in the comments above, I have locally loaded
1636070199117:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636070199142:# We can load it in:
1636070199161:survey_data <- read_csv("ces2019-phone_clean.csv")
1636070199565:#Cleaning Process:
1636070199601:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636070199619:survey_data <-
1636070199634:survey_data %>%
1636070199652:mutate(age = 2019-q2) %>%
1636070199670:select(age, p3,q3,q4) %>%
1636070199689:rename(sex=q3 , province=q4)
1636070199723:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636070199747:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636070199763:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636070199800:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636070199817:survey_data <-
1636070199838:survey_data %>%
1636070199856:filter(province %in% (1:10))
1636070199879:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636070199896:survey_data <-
1636070199912:survey_data %>%
1636070199928:filter(p3 %in% (1:8))
1636070199966:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636070199983:census_data <- census_data %>%
1636070200002:mutate(age=round(age)) %>%
1636070200021:filter(province == "Newfoundland and Labrador"|
1636070200042:province == "Prince Edward Island"|
1636070200063:province == "Nova Scotia"| province == "New Brunswick"|
1636070200080:province == "Quebec"| province == "Ontario"|
1636070200097:province == "Manitoba"| province == "Saskatchewan"|
1636070200114:province == "Alberta"| province == "British Columbia") %>%
1636070200132:filter(sex == "Female" | sex == "Male") %>%
1636070200148:select(age, sex, province)
1636070200311:#update sex to survey sex code
1636070200330:census_data$sex[census_data$sex == "Male"] <- 1
1636070200365:census_data$sex[census_data$sex == "Female"] <- 2
1636070200390:#change province names to survey province code
1636070200408:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636070200459:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636070200482:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636070200505:census_data$province[census_data$province == "New Brunswick"] <- 4
1636070200529:census_data$province[census_data$province == "Quebec"] <- 5
1636070200553:census_data$province[census_data$province == "Ontario"] <- 6
1636070200580:census_data$province[census_data$province == "Manitoba"] <- 7
1636070200605:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636070200630:census_data$province[census_data$province == "Alberta"] <- 9
1636070200652:census_data$province[census_data$province == "British Columbia"] <- 10
1636070200675:#convert char columns in census to numeric
1636070200697:census_data$sex <- as.numeric(as.character(census_data$sex))
1636070200721:census_data$province <- as.numeric(as.character(census_data$province))
1636070200763:# Use this to calculate some summary measures.
1636070200788:library(readr)
1636070200805:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636070200823:summary(survey_data$age)
1636070200894:table(survey_data$q3)
1636070200932:table(survey_data$q4)
1636070200989:# Use this to create some plots. Should probably describe both the sample and population.
1636070201012:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636070201029:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636070201047:#
1636070201067:# par(las=2)
1636070201085:#
1636070201104:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636070201123:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636070201161:liberal_data <- survey_data %>%
1636070201184:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636070201212:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636070201243:summary(liberal_model)
1636070201581:conservative_data <- survey_data %>%
1636070201599:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636070201625:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636070201670:summary(conservative_model)
1636070201997:ndp_data <- survey_data %>%
1636070202014:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636070202039:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636070202070:summary(ndp_model)
1636070202394:blocq_data <- survey_data %>%
1636070202412:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636070202440:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636070202473:summary(blocq_model)
1636070202817:green_data <- survey_data %>%
1636070202838:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636070202864:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636070202893:summary(green_model)
1636070203198:people_data <- survey_data %>%
1636070203217:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636070203240:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636070203282:summary(people_model)
1636070203578:other_data <- survey_data %>%
1636070203595:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636070203623:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636070203655:summary(other_model)
1636070203964:## Model Selection
1636070203981:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636070204156:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636070204335:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636070204753:View(census_data_counts)
1636070204801:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636070205002:step(green_model, trace = 0, k = log(nrow(green_data)))
1636070205220:step(people_model, trace = 0, k = log(nrow(people_data)))
1636070205449:step(other_model, trace = 0, k = log(nrow(other_data)))
1636070205697:### Don't show the results/output here...
1636070205734:# Creating the Model
1636070205760:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636070205795:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636070205832:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636070205860:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636070205894:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636070205923:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636070205963:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636070206001:# Model Results (to Report in Results section)
1636070206023:#summary(liberal_model)
1636070206043:# OR
1636070206064:# broom::tidy(model)
1636070206117:# Here I will perform the post-stratification calculation
1636070206145:census_data_counts <- census_data %>%
1636070206169:group_by(age) %>%
1636070206191:summarise(n=n())
1636070206225:census_data_counts$estimate <-
1636070206245:liberal_model %>%
1636070206262:predict(newdata = census_data_counts)
1636070236017:# Here I will perform the post-stratification calculation
1636070236042:census_data_counts <- census_data %>%
1636070236063:group_by(age) %>%
1636070236082:summarise(n=n())
1636070236119:census_data$estimate <-
1636070236140:liberal_model %>%
1636070236162:predict(newdata = census_data)
1636070236196:census_data_counts %>%
1636070236213:mutate(liberal_predict_prop = estimate*n) %>%
1636070236233:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636070263869:View(census_data)
1636070818239:# Here I will perform the post-stratification calculation
1636070818261:census_data_counts <- census_data %>%
1636070818280:group_by(age) %>%
1636070818301:summarise(n=n())
1636070818333:census_data$estimate <-
1636070818349:liberal_model %>%
1636070818366:predict(newdata = census_data)
1636070818407:census_data_counts %>%
1636070818430:mutate(liberal_predict_prop = census_data$estimate*n) %>%
1636070818451:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636071019995:# Here I will perform the post-stratification calculation
1636071020016:census_data_counts <- census_data %>%
1636071020042:group_by(age) %>%
1636071020067:summarise(n=n())
1636071020112:census_data$estimate <-
1636071020130:liberal_model %>%
1636071020151:predict(newdata = census_data)
1636071020195:census_data %>%
1636071020213:mutate(liberal_predict_prop = census_data$estimate*n) %>%
1636071020231:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636071032212:# Here I will perform the post-stratification calculation
1636071032234:census_data_counts <- census_data %>%
1636071032255:group_by(age) %>%
1636071032277:summarise(n=n())
1636071032309:census_data$estimate <-
1636071032331:liberal_model %>%
1636071032351:predict(newdata = census_data)
1636071032380:census_data %>%
1636071032405:mutate(liberal_predict_prop = census_data$estimate*n) %>%
1636071032425:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636072233137:View(blocq_data)
1636073313794:# Here I will perform the post-stratification calculation
1636073313815:census_data_counts <- census_data %>%
1636073313837:group_by(age) %>%
1636073313858:summarise(n=n())
1636073313888:census_data$estimate_liberals <-
1636073313909:liberal_model %>%
1636073313933:predict(newdata = census_data)
1636073313965:census_data %>%
1636073313986:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073314005:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073401780:# Here I will perform the post-stratification calculation
1636073401801:census_data_counts <- census_data %>%
1636073401816:group_by(age) %>%
1636073401835:summarise(n=n())
1636073401863:census_data$estimate_liberals <-
1636073401883:liberal_model %>%
1636073401902:predict(newdata = census_data)
1636073401928:census_data %>%
1636073401945:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073401961:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073402020:census_data$estimate_conservatives <-
1636073402039:conservative_model %>%
1636073402059:predict(newdata = census_data)
1636073402092:census_data %>%
1636073402110:mutate(conservative_predict_prop = census_data$estimate_conservative*n) %>%
1636073402133:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636073430796:# Here I will perform the post-stratification calculation
1636073430813:census_data_counts <- census_data %>%
1636073430832:group_by(age) %>%
1636073430855:summarise(n=n())
1636073430881:census_data$estimate_liberals <-
1636073430899:liberal_model %>%
1636073430916:predict(newdata = census_data)
1636073430952:census_data %>%
1636073430969:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073430990:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073431057:census_data$estimate_conservatives <-
1636073431075:conservative_model %>%
1636073431092:predict(newdata = census_data)
1636073431120:census_data %>%
1636073431160:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636073431179:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636073558663:# Here I will perform the post-stratification calculation
1636073558684:census_data_counts <- census_data %>%
1636073558706:group_by(age) %>%
1636073558725:summarise(n=n())
1636073558762:census_data$estimate_liberals <-
1636073558784:liberal_model %>%
1636073558804:predict(newdata = census_data)
1636073558835:census_data %>%
1636073558855:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073558875:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073558943:census_data$estimate_conservatives <-
1636073558967:conservative_model %>%
1636073558986:predict(newdata = census_data)
1636073559028:census_data %>%
1636073559048:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636073559071:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636073559135:census_data$estimate_ndp <-
1636073559157:ndp_model %>%
1636073559179:predict(newdata = census_data)
1636073559213:census_data %>%
1636073559232:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636073559248:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636073896949:# Here I will perform the post-stratification calculation
1636073896967:census_data_counts <- census_data %>%
1636073896985:group_by(age) %>%
1636073897008:summarise(n=n())
1636073897040:census_data$estimate_liberals <-
1636073897059:liberal_model %>%
1636073897079:predict(newdata = census_data)
1636073897118:census_data %>%
1636073897143:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073897166:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073897232:census_data$estimate_conservatives <-
1636073897252:conservative_model %>%
1636073897268:predict(newdata = census_data)
1636073897304:census_data %>%
1636073897325:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636073897348:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636073897418:census_data$estimate_ndp <-
1636073897442:ndp_model %>%
1636073897463:predict(newdata = census_data)
1636073897529:census_data %>%
1636073897550:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636073897570:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636073897642:census_data$estimate_blocq <-
1636073897665:blocq_model %>%
1636073897688:predict(newdata = census_data)
1636073897723:census_data %>%
1636073897747:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636073897768:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636073937501:# Here I will perform the post-stratification calculation
1636073937523:census_data_counts <- census_data %>%
1636073937545:group_by(age) %>%
1636073937565:summarise(n=n())
1636073937596:census_data$estimate_liberals <-
1636073937615:liberal_model %>%
1636073937635:predict(newdata = census_data)
1636073937676:census_data %>%
1636073937698:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636073937718:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636073937782:census_data$estimate_conservatives <-
1636073937800:conservative_model %>%
1636073937819:predict(newdata = census_data)
1636073937853:census_data %>%
1636073937875:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636073937893:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636073937953:census_data$estimate_ndp <-
1636073937972:ndp_model %>%
1636073937990:predict(newdata = census_data)
1636073938021:census_data %>%
1636073938041:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636073938064:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636073938132:census_data$estimate_blocq <-
1636073938154:blocq_model %>%
1636073938174:predict(newdata = census_data)
1636073938211:census_data %>%
1636073938232:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636073938252:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636073938320:census_data$estimate_green <-
1636073938338:green_model %>%
1636073938353:predict(newdata = census_data)
1636073938397:census_data %>%
1636073938416:mutate(green_predict_prop = census_data$estimate_green*n) %>%
1636073938436:summarise(green_predict = sum(green_predict_prop)/sum(n))
1636074037386:# Here I will perform the post-stratification calculation
1636074037406:census_data_counts <- census_data %>%
1636074037426:group_by(age) %>%
1636074037444:summarise(n=n())
1636074037475:census_data$estimate_liberals <-
1636074037497:liberal_model %>%
1636074037517:predict(newdata = census_data)
1636074037551:census_data %>%
1636074037573:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636074037593:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636074037654:census_data$estimate_conservatives <-
1636074037671:conservative_model %>%
1636074037688:predict(newdata = census_data)
1636074037722:census_data %>%
1636074037744:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636074037765:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636074037834:census_data$estimate_ndp <-
1636074037855:ndp_model %>%
1636074037879:predict(newdata = census_data)
1636074037914:census_data %>%
1636074037933:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636074037957:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636074038025:census_data$estimate_blocq <-
1636074038047:blocq_model %>%
1636074038073:predict(newdata = census_data)
1636074038107:census_data %>%
1636074038128:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636074038149:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636074038218:census_data$estimate_green <-
1636074038240:green_model %>%
1636074038262:predict(newdata = census_data)
1636074038311:census_data %>%
1636074038333:mutate(green_predict_prop = census_data$estimate_green*n) %>%
1636074038355:summarise(green_predict = sum(green_predict_prop)/sum(n))
1636074038419:census_data$estimate_people <-
1636074038439:people_model %>%
1636074038461:predict(newdata = census_data)
1636074038498:census_data %>%
1636074038518:mutate(people_predict_prop = census_data$estimate_people*n) %>%
1636074038538:summarise(people_predict = sum(people_predict_prop)/sum(n))
1636074038603:census_data$estimate_other <-
1636074038625:other_model %>%
1636074038645:predict(newdata = census_data)
1636074038681:census_data %>%
1636074038701:mutate(other_predict_prop = census_data$estimate_other*n) %>%
1636074038722:summarise(other_predict = sum(other_predict_prop)/sum(n))
1636075619729:# Creating the Model
1636075619757:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636075619793:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636075619830:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636075619867:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636075619914:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636075619947:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636075619980:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636075620030:# Model Results (to Report in Results section)
1636075620047:#summary(liberal_model)
1636075620066:# OR
1636075620086:# broom::tidy(model)
1636075623352:# Here I will perform the post-stratification calculation
1636075623374:census_data_counts <- census_data %>%
1636075623393:group_by(age) %>%
1636075623410:summarise(n=n())
1636075623437:census_data$estimate_liberals <-
1636075623456:liberal_model %>%
1636075623475:predict(newdata = census_data)
1636075623510:census_data %>%
1636075623531:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636075623556:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636075623613:census_data$estimate_conservatives <-
1636075623629:conservative_model %>%
1636075623645:predict(newdata = census_data)
1636075623699:census_data %>%
1636075623718:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636075623739:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636075623802:census_data$estimate_ndp <-
1636075623819:ndp_model %>%
1636075623842:predict(newdata = census_data)
1636075623882:census_data %>%
1636075623900:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636075623918:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636075623976:census_data$estimate_blocq <-
1636075623996:blocq_model %>%
1636075624014:predict(newdata = census_data)
1636075624052:census_data %>%
1636075624075:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636075624096:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636075624161:census_data$estimate_green <-
1636075624177:green_model %>%
1636075624193:predict(newdata = census_data)
1636075624247:census_data %>%
1636075624268:mutate(green_predict_prop = census_data$estimate_green*n) %>%
1636075624287:summarise(green_predict = sum(green_predict_prop)/sum(n))
1636075624354:census_data$estimate_people <-
1636075624375:people_model %>%
1636075624395:predict(newdata = census_data)
1636075624433:census_data %>%
1636075624456:mutate(people_predict_prop = census_data$estimate_people*n) %>%
1636075624478:summarise(people_predict = sum(people_predict_prop)/sum(n))
1636075624544:census_data$estimate_other <-
1636075624563:other_model %>%
1636075624581:predict(newdata = census_data)
1636075624621:census_data %>%
1636075624638:mutate(other_predict_prop = census_data$estimate_other*n) %>%
1636075624654:summarise(other_predict = sum(other_predict_prop)/sum(n))
1636075693114:View(survey_data)
1636076756541:View(liberal_data)
1636077630449:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636077630467:library(openintro)
1636077630494:library(tidyverse)
1636077630532:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636077630556:census_data <- read_csv("gss_clean.csv")
1636077630713:# You may need additional chunks, in case you want to include some of the cleaning output.
1636077630752:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636077630776:# First, if you don't already have it, install the devtools package:
1636077630795:# install.packages("devtools")
1636077630813:# Now use devtools to install the cesR package directly from Github:
1636077630829:# devtools::install_github("hodgettsp/cesR")
1636077631008:# Load it like any other package:
1636077631028:#library(cesR)
1636077631044:# There are many different CES datasets, and they have unique codes.
1636077631060:# See them with the get_cescodes() function:
1636077631076:#get_cescodes()
1636077631095:# Now pick one, let's try ces2019_phone
1636077631110:#get_ces("ces2019_phone")
1636077631128:#survey_data <- ces2019_phone
1636077631149:# Alternative to what is in the comments above, I have locally loaded
1636077631169:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636077631186:# We can load it in:
1636077631207:survey_data <- read_csv("ces2019-phone_clean.csv")
1636077631484:#Cleaning Process:
1636077631504:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636077631524:survey_data <-
1636077631545:survey_data %>%
1636077631564:mutate(age = 2019-q2) %>%
1636077631583:select(age, p3,q3,q4)
1636077631618:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636077631780:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636077631799:survey_data <- survey_data %>% filter(q3 == "1" | q3 == "2")
1636077631837:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636077631861:survey_data <-
1636077631887:survey_data %>%
1636077631905:filter(q4 %in% (1:10))
1636077631931:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636077631951:survey_data <-
1636077631967:survey_data %>%
1636077631988:filter(p3 %in% (1:8))
1636077632029:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636077632047:census_data <- census_data %>%
1636077632094:mutate(age=round(age)) %>%
1636077632115:filter(province == "Newfoundland and Labrador"|
1636077632136:province == "Prince Edward Island"|
1636077632157:province == "Nova Scotia"| province == "New Brunswick"|
1636077632176:province == "Quebec"| province == "Ontario"|
1636077632194:province == "Manitoba"| province == "Saskatchewan"|
1636077632215:province == "Alberta"| province == "British Columbia") %>%
1636077632236:filter(sex == "Female" | sex == "Male") %>%
1636077632257:select(age, sex, province)
1636077632417:#update sex to survey sex code
1636077632438:census_data$sex[census_data$sex == "Male"] <- 1
1636077632472:census_data$sex[census_data$sex == "Female"] <- 2
1636077632497:#change province names to survey province code
1636077632520:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636077632577:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636077632606:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636077632631:census_data$province[census_data$province == "New Brunswick"] <- 4
1636077632659:census_data$province[census_data$province == "Quebec"] <- 5
1636077632685:census_data$province[census_data$province == "Ontario"] <- 6
1636077632710:census_data$province[census_data$province == "Manitoba"] <- 7
1636077632748:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636077632774:census_data$province[census_data$province == "Alberta"] <- 9
1636077632811:census_data$province[census_data$province == "British Columbia"] <- 10
1636077632833:#convert char columns in census to numeric
1636077632849:census_data$sex <- as.numeric(as.character(census_data$sex))
1636077632874:census_data$province <- as.numeric(as.character(census_data$province))
1636077632917:# Use this to calculate some summary measures.
1636077632940:library(readr)
1636077632960:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636077632979:summary(survey_data$age)
1636077633055:table(survey_data$q3)
1636077633103:table(survey_data$q4)
1636077633244:# Use this to create some plots. Should probably describe both the sample and population.
1636077633268:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636077633288:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636077633311:#
1636077633331:# par(las=2)
1636077633350:#
1636077633368:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636077633388:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636077633429:liberal_data <- survey_data %>%
1636077633456:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636077633481:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636077633518:summary(liberal_model)
1636077634125:conservative_data <- survey_data %>%
1636077634145:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636077634170:conservative_model <- glm(votedconservative ~ age + as.factor(q3) + as.factor(q4), data = conservative_data, family = binomial)
1636077634237:summary(conservative_model)
1636077634811:ndp_data <- survey_data %>%
1636077634829:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636077634856:ndp_model <- glm(votedndp ~ age + as.factor(q3) + as.factor(q4), data = ndp_data, family = binomial)
1636077634895:summary(ndp_model)
1636077635435:blocq_data <- survey_data %>%
1636077635458:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636077635484:blocq_model <- glm(votedblocq ~ age + as.factor(q3) + as.factor(q4), data = blocq_data, family = binomial)
1636077635567:summary(blocq_model)
1636077636135:green_data <- survey_data %>%
1636077636159:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636077636187:green_model <- glm(votedgreen ~ age + as.factor(q3) + as.factor(q4), data = green_data, family = binomial)
1636077636232:summary(green_model)
1636077636803:people_data <- survey_data %>%
1636077636822:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636077636849:people_model <- glm(votedpeople ~ age + as.factor(q3) + as.factor(q4), data = people_data, family = binomial)
1636077637194:summary(people_model)
1636077637757:other_data <- survey_data %>%
1636077637779:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636077637810:other_model <- glm(votedother ~ age + as.factor(q3) + as.factor(q4), data = other_data, family = binomial)
1636077637881:summary(other_model)
1636077638406:## Model Selection
1636077638430:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636077638715:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636077638997:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636077639285:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636077639688:step(green_model, trace = 0, k = log(nrow(green_data)))
1636077640006:step(people_model, trace = 0, k = log(nrow(people_data)))
1636077640294:step(other_model, trace = 0, k = log(nrow(other_data)))
1636077640587:### Don't show the results/output here...
1636077640640:# Creating the Model
1636077640664:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636077717475:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636077717495:library(openintro)
1636077717518:library(tidyverse)
1636077717566:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636077717595:census_data <- read_csv("gss_clean.csv")
1636077717741:# You may need additional chunks, in case you want to include some of the cleaning output.
1636077717788:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636077717815:# First, if you don't already have it, install the devtools package:
1636077717832:# install.packages("devtools")
1636077717852:# Now use devtools to install the cesR package directly from Github:
1636077717873:# devtools::install_github("hodgettsp/cesR")
1636077718075:# Load it like any other package:
1636077718096:#library(cesR)
1636077718116:# There are many different CES datasets, and they have unique codes.
1636077718138:# See them with the get_cescodes() function:
1636077718157:#get_cescodes()
1636077718177:# Now pick one, let's try ces2019_phone
1636077718197:#get_ces("ces2019_phone")
1636077718220:#survey_data <- ces2019_phone
1636077718239:# Alternative to what is in the comments above, I have locally loaded
1636077718261:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636077718280:# We can load it in:
1636077718301:survey_data <- read_csv("ces2019-phone_clean.csv")
1636077718551:#Cleaning Process:
1636077718576:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636077718598:survey_data <-
1636077718620:survey_data %>%
1636077718640:mutate(age = 2019-q2) %>%
1636077718660:select(age, p3,q3,q4) %>%
1636077718681:rename(sex = q3, province = 4)
1636077718715:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636077718735:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636077718757:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636077718798:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636077718817:survey_data <-
1636077718836:survey_data %>%
1636077718856:filter(province %in% (1:10))
1636077718883:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636077718904:survey_data <-
1636077718925:survey_data %>%
1636077718944:filter(p3 %in% (1:8))
1636077718989:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636077719011:census_data <- census_data %>%
1636077719030:mutate(age=round(age)) %>%
1636077719051:filter(province == "Newfoundland and Labrador"|
1636077719078:province == "Prince Edward Island"|
1636077719098:province == "Nova Scotia"| province == "New Brunswick"|
1636077719117:province == "Quebec"| province == "Ontario"|
1636077719137:province == "Manitoba"| province == "Saskatchewan"|
1636077719159:province == "Alberta"| province == "British Columbia") %>%
1636077719180:filter(sex == "Female" | sex == "Male") %>%
1636077719202:select(age, sex, province)
1636077719334:#update sex to survey sex code
1636077719357:census_data$sex[census_data$sex == "Male"] <- 1
1636077719399:census_data$sex[census_data$sex == "Female"] <- 2
1636077719421:#change province names to survey province code
1636077719443:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636077719485:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636077719514:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636077719544:census_data$province[census_data$province == "New Brunswick"] <- 4
1636077719574:census_data$province[census_data$province == "Quebec"] <- 5
1636077719602:census_data$province[census_data$province == "Ontario"] <- 6
1636077719627:census_data$province[census_data$province == "Manitoba"] <- 7
1636077719652:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636077719678:census_data$province[census_data$province == "Alberta"] <- 9
1636077719705:census_data$province[census_data$province == "British Columbia"] <- 10
1636077719731:#convert char columns in census to numeric
1636077719758:census_data$sex <- as.numeric(as.character(census_data$sex))
1636077719789:census_data$province <- as.numeric(as.character(census_data$province))
1636077719845:# Use this to calculate some summary measures.
1636077719868:library(readr)
1636077719886:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636077719902:summary(survey_data$age)
1636077719970:table(survey_data$q3)
1636077720010:table(survey_data$q4)
1636077720073:# Use this to create some plots. Should probably describe both the sample and population.
1636077720095:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636077720113:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636077720129:#
1636077720147:# par(las=2)
1636077720165:#
1636077720182:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636077720199:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636077720234:liberal_data <- survey_data %>%
1636077720257:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636077720283:liberal_model <- glm(votedliberal ~ age + as.factor(q3) + as.factor(q4), data = liberal_data, family = binomial)
1636077734105:# Use this to calculate some summary measures.
1636077734126:library(readr)
1636077734148:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636077734170:summary(survey_data$age)
1636077734250:table(survey_data$sex)
1636077734305:table(survey_data$q4)
1636077742958:# Use this to calculate some summary measures.
1636077742977:library(readr)
1636077742996:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636077743017:summary(survey_data$age)
1636077743086:table(survey_data$sex)
1636077743135:table(survey_data$province)
1636077744701:View(survey_data)
1636077789292:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636077789313:library(openintro)
1636077789333:library(tidyverse)
1636077789372:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636077789396:census_data <- read_csv("gss_clean.csv")
1636077789532:# You may need additional chunks, in case you want to include some of the cleaning output.
1636077789572:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636077789598:# First, if you don't already have it, install the devtools package:
1636077789617:# install.packages("devtools")
1636077789635:# Now use devtools to install the cesR package directly from Github:
1636077789657:# devtools::install_github("hodgettsp/cesR")
1636077789876:# Load it like any other package:
1636077789898:#library(cesR)
1636077789918:# There are many different CES datasets, and they have unique codes.
1636077789935:# See them with the get_cescodes() function:
1636077789952:#get_cescodes()
1636077789968:# Now pick one, let's try ces2019_phone
1636077789987:#get_ces("ces2019_phone")
1636077790008:#survey_data <- ces2019_phone
1636077790024:# Alternative to what is in the comments above, I have locally loaded
1636077790045:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636077790062:# We can load it in:
1636077790077:survey_data <- read_csv("ces2019-phone_clean.csv")
1636077790299:#Cleaning Process:
1636077790327:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636077790344:survey_data <-
1636077790365:survey_data %>%
1636077790384:mutate(age = 2019-q2) %>%
1636077790407:select(age, p3,q3,q4) %>%
1636077790425:rename(sex = q3, province = 4)
1636077790456:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636077790475:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636077790492:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636077790521:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636077790538:survey_data <-
1636077790555:survey_data %>%
1636077790573:filter(province %in% (1:10))
1636077790595:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636077790614:survey_data <-
1636077790631:survey_data %>%
1636077790649:filter(p3 %in% (1:8))
1636077790690:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636077790709:census_data <- census_data %>%
1636077790729:mutate(age=round(age)) %>%
1636077790746:filter(province == "Newfoundland and Labrador"|
1636077790763:province == "Prince Edward Island"|
1636077790780:province == "Nova Scotia"| province == "New Brunswick"|
1636077790800:province == "Quebec"| province == "Ontario"|
1636077790822:province == "Manitoba"| province == "Saskatchewan"|
1636077790840:province == "Alberta"| province == "British Columbia") %>%
1636077790860:filter(sex == "Female" | sex == "Male") %>%
1636077790876:select(age, sex, province)
1636077790992:#update sex to survey sex code
1636077791015:census_data$sex[census_data$sex == "Male"] <- 1
1636077791045:census_data$sex[census_data$sex == "Female"] <- 2
1636077791066:#change province names to survey province code
1636077791082:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636077791118:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636077791145:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636077791172:census_data$province[census_data$province == "New Brunswick"] <- 4
1636077791195:census_data$province[census_data$province == "Quebec"] <- 5
1636077791220:census_data$province[census_data$province == "Ontario"] <- 6
1636077791246:census_data$province[census_data$province == "Manitoba"] <- 7
1636077791270:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636077791296:census_data$province[census_data$province == "Alberta"] <- 9
1636077791323:census_data$province[census_data$province == "British Columbia"] <- 10
1636077791353:#convert char columns in census to numeric
1636077791374:census_data$sex <- as.numeric(as.character(census_data$sex))
1636077791435:census_data$province <- as.numeric(as.character(census_data$province))
1636077791481:# Use this to calculate some summary measures.
1636077791506:library(readr)
1636077791529:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636077791547:summary(survey_data$age)
1636077791619:table(survey_data$sex)
1636077791668:table(survey_data$province)
1636077791802:# Use this to create some plots. Should probably describe both the sample and population.
1636077791827:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636077791845:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636077791863:#
1636077791884:# par(las=2)
1636077791912:#
1636077791933:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636077791954:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636077791994:liberal_data <- survey_data %>%
1636077792023:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636077792050:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636077792084:summary(liberal_model)
1636077792439:conservative_data <- survey_data %>%
1636077792462:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636077792493:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636077792530:summary(conservative_model)
1636077792937:ndp_data <- survey_data %>%
1636077792958:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636077792985:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636077793019:summary(ndp_model)
1636077793383:blocq_data <- survey_data %>%
1636077793405:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636077793437:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636077793731:summary(blocq_model)
1636077794108:green_data <- survey_data %>%
1636077794127:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636077794155:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636077794187:summary(green_model)
1636077794546:people_data <- survey_data %>%
1636077794569:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636077794599:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636077794646:summary(people_model)
1636077795023:other_data <- survey_data %>%
1636077795041:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636077795071:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636077795111:summary(other_model)
1636077795442:## Model Selection
1636077795459:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636077795659:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636077795866:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636077796048:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636077796301:step(green_model, trace = 0, k = log(nrow(green_data)))
1636077796508:step(people_model, trace = 0, k = log(nrow(people_data)))
1636077796720:step(other_model, trace = 0, k = log(nrow(other_data)))
1636077796970:### Don't show the results/output here...
1636077797012:# Creating the Model
1636077797039:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636077797076:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636077797108:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636077797140:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636077797178:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636077797212:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636077797247:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636077797292:# Model Results (to Report in Results section)
1636077797315:#summary(liberal_model)
1636077797337:# OR
1636077797358:# broom::tidy(model)
1636077797407:# Here I will perform the post-stratification calculation
1636077797438:census_data_counts <- census_data %>%
1636077797461:group_by(age) %>%
1636077797483:summarise(n=n())
1636077797513:census_data$estimate_liberals <-
1636077797534:liberal_model %>%
1636077797554:predict(newdata = census_data)
1636077797587:census_data %>%
1636077797609:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636077797627:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636077797694:census_data$estimate_conservatives <-
1636077797718:conservative_model %>%
1636077797738:predict(newdata = census_data)
1636077797767:census_data %>%
1636077797789:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636077797809:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636077797874:census_data$estimate_ndp <-
1636077797895:ndp_model %>%
1636077797917:predict(newdata = census_data)
1636077797949:census_data %>%
1636077797969:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636077797991:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636077798056:census_data$estimate_blocq <-
1636077798075:blocq_model %>%
1636077798091:predict(newdata = census_data)
1636077798122:census_data %>%
1636077798139:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636077798157:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636077798212:census_data$estimate_green <-
1636077798230:green_model %>%
1636077798252:predict(newdata = census_data)
1636077798285:census_data %>%
1636077798306:mutate(green_predict_prop = census_data$estimate_green*n) %>%
1636077798328:summarise(green_predict = sum(green_predict_prop)/sum(n))
1636077798391:census_data$estimate_people <-
1636077798414:people_model %>%
1636077798433:predict(newdata = census_data)
1636077798466:census_data %>%
1636077798483:mutate(people_predict_prop = census_data$estimate_people*n) %>%
1636077798502:summarise(people_predict = sum(people_predict_prop)/sum(n))
1636077798560:census_data$estimate_other <-
1636077798579:other_model %>%
1636077798603:predict(newdata = census_data)
1636077798642:census_data %>%
1636077798660:mutate(other_predict_prop = census_data$estimate_other*n) %>%
1636077798678:summarise(other_predict = sum(other_predict_prop)/sum(n))
1636077798775:# Here you can include some relevant visualizations.
1636078068998:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636078069019:library(openintro)
1636078069051:library(tidyverse)
1636078069115:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636078069143:census_data <- read_csv("gss_clean.csv")
1636078069286:# You may need additional chunks, in case you want to include some of the cleaning output.
1636078069328:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636078069357:# First, if you don't already have it, install the devtools package:
1636078069379:# install.packages("devtools")
1636078069399:# Now use devtools to install the cesR package directly from Github:
1636078069419:# devtools::install_github("hodgettsp/cesR")
1636078069591:# Load it like any other package:
1636078069613:#library(cesR)
1636078069631:# There are many different CES datasets, and they have unique codes.
1636078069650:# See them with the get_cescodes() function:
1636078069668:#get_cescodes()
1636078069689:# Now pick one, let's try ces2019_phone
1636078069710:#get_ces("ces2019_phone")
1636078069732:#survey_data <- ces2019_phone
1636078069750:# Alternative to what is in the comments above, I have locally loaded
1636078069767:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636078069790:# We can load it in:
1636078069809:survey_data <- read_csv("ces2019-phone_clean.csv")
1636078070065:#Cleaning Process:
1636078070086:#We use the select function to keep only the response and 3 predictor variables we will use in our model: age, q3/gender, q4/province or territory where the individual lives.
1636078070106:survey_data <-
1636078070124:survey_data %>%
1636078070141:mutate(age = 2019-q2) %>%
1636078070162:select(age, p3,q3,q4) %>%
1636078070184:rename(sex = q3, province = 4)
1636078070222:#Now, to be able to map survey data with census data we need to further clean our data to make sure the variable possible values are the same in both datasets.
1636078070242:#We start by reducing Gender into just male and female and then using this data to impute sex from gender. This wont result in any ethical or statistical malpractice as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female.
1636078070261:survey_data <- survey_data %>% filter(sex == "1" | sex == "2")
1636078070294:# Then for q4 which refers to the province in which the individual surveyed lives we get rid of all observations that fail to provide an answer as well as those provinces with no observations.
1636078070313:survey_data <-
1636078070333:survey_data %>%
1636078070355:filter(province %in% (1:10))
1636078070379:#Finally we filter for our response variable, this this part we are filtering out all the observations that failed to provide a correct answer for this question of the survey
1636078070402:survey_data <-
1636078070419:survey_data %>%
1636078070438:filter(p3 %in% (1:8))
1636078070478:#In a similar fashion we clean our census data to make sure it matches with what we just did with our survey data
1636078070497:census_data <- census_data %>%
1636078070519:mutate(age=round(age)) %>%
1636078070542:filter(province == "Newfoundland and Labrador"|
1636078070565:province == "Prince Edward Island"|
1636078070589:province == "Nova Scotia"| province == "New Brunswick"|
1636078070608:province == "Quebec"| province == "Ontario"|
1636078070627:province == "Manitoba"| province == "Saskatchewan"|
1636078070648:province == "Alberta"| province == "British Columbia") %>%
1636078070668:filter(sex == "Female" | sex == "Male") %>%
1636078070694:select(age, sex, province)
1636078070812:#update sex to survey sex code
1636078070831:census_data$sex[census_data$sex == "Male"] <- 1
1636078070864:census_data$sex[census_data$sex == "Female"] <- 2
1636078070884:#change province names to survey province code
1636078070909:census_data$province[census_data$province == "Newfoundland and Labrador"] <- 1
1636078070946:census_data$province[census_data$province == "Prince Edward Island"] <- 2
1636078070975:census_data$province[census_data$province == "Nova Scotia"] <- 3
1636078071004:census_data$province[census_data$province == "New Brunswick"] <- 4
1636078071027:census_data$province[census_data$province == "Quebec"] <- 5
1636078071056:census_data$province[census_data$province == "Ontario"] <- 6
1636078071078:census_data$province[census_data$province == "Manitoba"] <- 7
1636078071100:census_data$province[census_data$province == "Saskatchewan"] <- 8
1636078071125:census_data$province[census_data$province == "Alberta"] <- 9
1636078071148:census_data$province[census_data$province == "British Columbia"] <- 10
1636078071171:#convert char columns in census to numeric
1636078071188:census_data$sex <- as.numeric(as.character(census_data$sex))
1636078071215:census_data$province <- as.numeric(as.character(census_data$province))
1636078071263:# Use this to calculate some summary measures.
1636078071290:library(readr)
1636078071311:#For the summaries we will use the function table() for the categorical variables and summary for the numerical one.
1636078071330:summary(survey_data$age)
1636078071411:table(survey_data$sex)
1636078071465:table(survey_data$province)
1636078071600:# Use this to create some plots. Should probably describe both the sample and population.
1636078071625:#For the graphs of categorical variables we will use barplots and for the numerical variable an scatterplot.
1636078071645:# plot(age, p3 , main="Voted Party vs Age", xlab="Respondent Age ", ylab="Voted Party")
1636078071662:#
1636078071680:# par(las=2)
1636078071696:#
1636078071713:# barplot(table(survey_data$q3), main="Sex", horiz=TRUE)
1636078071730:# barplot(table(survey_data$q4), main="Province of Residence", horiz=TRUE)
1636078071768:liberal_data <- survey_data %>%
1636078071799:mutate(votedliberal = ifelse(survey_data$p3 == "1", 1, 0))
1636078071829:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636078071862:summary(liberal_model)
1636078072216:conservative_data <- survey_data %>%
1636078072235:mutate(votedconservative = ifelse(survey_data$p3 == "2", 1, 0))
1636078072263:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636078072295:summary(conservative_model)
1636078072621:ndp_data <- survey_data %>%
1636078072638:mutate(votedndp = ifelse(survey_data$p3 == "3", 1, 0))
1636078072665:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636078072696:summary(ndp_model)
1636078073047:blocq_data <- survey_data %>%
1636078073070:mutate(votedblocq = ifelse(survey_data$p3 == "4", 1, 0))
1636078073100:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636078073132:summary(blocq_model)
1636078073472:green_data <- survey_data %>%
1636078073493:mutate(votedgreen = ifelse(survey_data$p3 == "5", 1, 0))
1636078073525:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636078073559:summary(green_model)
1636078073912:people_data <- survey_data %>%
1636078073932:mutate(votedpeople = ifelse(survey_data$p3 == "6", 1, 0))
1636078073957:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636078073990:summary(people_model)
1636078074330:other_data <- survey_data %>%
1636078074351:mutate(votedother = ifelse(survey_data$p3 == "7", 1, 0))
1636078074379:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636078074419:summary(other_model)
1636078074760:## Model Selection
1636078074778:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636078074973:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636078075168:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636078075623:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636078075833:step(green_model, trace = 0, k = log(nrow(green_data)))
1636078076044:step(people_model, trace = 0, k = log(nrow(people_data)))
1636078076288:step(other_model, trace = 0, k = log(nrow(other_data)))
1636078076537:### Don't show the results/output here...
1636078076585:# Creating the Model
1636078076612:liberal_model <- glm(votedliberal ~ age + sex + province, data = liberal_data, family = binomial)
1636078076647:conservative_model <- glm(votedconservative ~ age + sex + province, data = conservative_data, family = binomial)
1636078076683:ndp_model <- glm(votedndp ~ age + sex + province, data = ndp_data, family = binomial)
1636078076715:blocq_model <- glm(votedblocq ~ age + sex + province, data = blocq_data, family = binomial)
1636078076753:green_model <- glm(votedgreen ~ age + sex + province, data = green_data, family = binomial)
1636078076782:people_model <- glm(votedpeople ~ age + sex + province, data = people_data, family = binomial)
1636078076829:other_model <- glm(votedother ~ age + sex + province, data = other_data, family = binomial)
1636078076864:# Model Results (to Report in Results section)
1636078076883:#summary(liberal_model)
1636078076901:# OR
1636078076916:# broom::tidy(model)
1636078077008:# Here I will perform the post-stratification calculation
1636078077034:census_data_counts <- census_data %>%
1636078077056:group_by(age) %>%
1636078077076:summarise(n=n())
1636078077111:census_data$estimate_liberals <-
1636078077132:liberal_model %>%
1636078077154:predict(newdata = census_data)
1636078077188:census_data %>%
1636078077209:mutate(liberal_predict_prop = census_data$estimate_liberals*n) %>%
1636078077229:summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
1636078077299:census_data$estimate_conservatives <-
1636078077322:conservative_model %>%
1636078077346:predict(newdata = census_data)
1636078077378:census_data %>%
1636078077402:mutate(conservative_predict_prop = census_data$estimate_conservatives*n) %>%
1636078077422:summarise(conservative_predict = sum(conservative_predict_prop)/sum(n))
1636078077483:census_data$estimate_ndp <-
1636078077503:ndp_model %>%
1636078077523:predict(newdata = census_data)
1636078077557:census_data %>%
1636078077578:mutate(ndp_predict_prop = census_data$estimate_ndp*n) %>%
1636078077599:summarise(ndp_predict = sum(ndp_predict_prop)/sum(n))
1636078077670:census_data$estimate_blocq <-
1636078077692:blocq_model %>%
1636078077715:predict(newdata = census_data)
1636078077748:census_data %>%
1636078077767:mutate(blocq_predict_prop = census_data$estimate_blocq*n) %>%
1636078077785:summarise(blocq_predict = sum(blocq_predict_prop)/sum(n))
1636078077854:census_data$estimate_green <-
1636078077877:green_model %>%
1636078077900:predict(newdata = census_data)
1636078077934:census_data %>%
1636078077956:mutate(green_predict_prop = census_data$estimate_green*n) %>%
1636078077974:summarise(green_predict = sum(green_predict_prop)/sum(n))
1636078078043:census_data$estimate_people <-
1636078078067:people_model %>%
1636078078090:predict(newdata = census_data)
1636078078123:census_data %>%
1636078078144:mutate(people_predict_prop = census_data$estimate_people*n) %>%
1636078078162:summarise(people_predict = sum(people_predict_prop)/sum(n))
1636078078229:census_data$estimate_other <-
1636078078250:other_model %>%
1636078078271:predict(newdata = census_data)
1636078078304:census_data %>%
1636078078326:mutate(other_predict_prop = census_data$estimate_other*n) %>%
1636078078345:summarise(other_predict = sum(other_predict_prop)/sum(n))
1636078078442:# Here you can include some relevant visualizations.
1636118863264:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636118863290:library(openintro)
1636118863376:library(tidyverse)
1636118863509:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636118863535:census_data <- read_csv("gss_clean.csv")
1636118863902:# You may need additional chunks, in case you want to include some of the cleaning output.
1636118863951:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636118863982:# First, if you don't already have it, install the devtools package:
1636118864003:# install.packages("devtools")
1636118864023:# Now use devtools to install the cesR package directly from Github:
1636118864044:# devtools::install_github("hodgettsp/cesR")
1636118864246:# Load it like any other package:
1636118864266:#library(cesR)
1636118864289:# There are many different CES datasets, and they have unique codes.
1636118864309:# See them with the get_cescodes() function:
1636118864331:#get_cescodes()
1636118864354:# Now pick one, let's try ces2019_phone
1636118864408:#get_ces("ces2019_phone")
1636118864427:#survey_data <- ces2019_phone
1636118864450:# Alternative to what is in the comments above, I have locally loaded
1636118864670:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636118864690:# We can load it in:
1636118864710:survey_data <- read_csv("ces2019-phone_clean.csv")
1636118864991:#select variables from data that we need for analysis
1636118865017:survey_data <-
1636118865036:survey_data %>%
1636118865055:select(age_range, p3, q3, q4) %>%
1636118865075:rename(sex = q3, province = q4, vote = p3)
1636118865109:#filter data
1636118865128:survey_data <-
1636118865152:survey_data %>%
1636118865172:filter(sex == "1" | sex == "2")
1636118865215:survey_data <-
1636118865234:survey_data %>%
1636118865252:filter(province %in% (1:10))
1636118865274:survey_data <-
1636118865293:survey_data %>%
1636118865310:filter(vote %in% (1:8))
1636118865336:#convert categorical data from numeric to string
1636118865354:survey_data$province <- as.character(survey_data$province)
1636118865376:survey_data$sex <- as.character(survey_data$sex)
1636118865398:survey_data$vote <- as.character(survey_data$vote)
1636118865420:#replace sex key with sex title
1636118865439:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636118865465:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636118865484:#replace province key with province name
1636118865504:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636118865530:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636118865557:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636118865578:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636118865601:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636118865623:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636118865643:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636118865665:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636118865684:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636118865705:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636118865727:#replace party key with party name
1636118865747:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636118865771:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636118865798:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636118865822:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636118865843:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636118865863:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636118865885:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636118865904:#replace age_range key with age range
1636118865925:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636118865950:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636118865979:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636118866024:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636118866056:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636118866111:#select age, province, and sex from census
1636118866132:#filter out data that does not include the province or the sex of the respondent
1636118866154:#filter out respondents who aren't old enough to vote
1636118866174:census_data <- census_data %>%
1636118866196:mutate(age=round(age)) %>%
1636118866216:filter(province == "Newfoundland and Labrador"|
1636118866236:province == "Prince Edward Island"|
1636118866256:province == "Nova Scotia"|
1636118866276:province == "New Brunswick"|
1636118866297:province == "Quebec"|
1636118866318:province == "Ontario"|
1636118866339:province == "Manitoba"|
1636118866359:province == "Saskatchewan"|
1636118866381:province == "Alberta"|
1636118866400:province == "British Columbia") %>%
1636118866419:filter(sex == "Female" | sex == "Male") %>%
1636118866438:filter(age >= 18) %>%
1636118866458:select(age, sex, province)%>%
1636118866480:rename(age_range = age)
1636118866639:#census_data$age_range <- as.character(census_data$age_range)
1636118866657:#replace age with age range
1636118866674:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636118866717:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636118866748:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636118866775:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636118866802:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636118866852:# Use this to calculate some summary measures.
1636118866876:library(readr)
1636118866897:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636118866918:prop.table(table(survey_data$age_range , survey_data$vote))
1636118867158:prop.table(table(survey_data$sex , survey_data$vote))
1636118867287:prop.table(table(survey_data$province , survey_data$vote))
1636118867734:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636118867755:ggplot(survey_data, aes(x = (vote))) +
1636118867772:xlab("Voted Party") +
1636118867789:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636118867808:facet_grid(~ age_range) +
1636118867829:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636118868296:ggplot(survey_data, aes(x = (vote))) +
1636118868313:xlab("Voted Party") +
1636118868330:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636118868349:facet_grid(~ sex) +
1636118868369:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636118868620:ggplot(survey_data, aes(x = (vote))) +
1636118868639:xlab("Voted Party") +
1636118868658:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636118868681:facet_grid(~ province) +
1636118868704:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636118869366:# Creating the Model
1636118869385:liberal_data <- survey_data %>%
1636118869408:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636118869441:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636118869480:conservative_data <- survey_data %>%
1636118869496:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636118869530:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636118869566:ndp_data <- survey_data %>%
1636118869588:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636118869624:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636118869660:blocq_data <- survey_data %>%
1636118869681:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636118869719:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636118869784:green_data <- survey_data %>%
1636118869804:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636118869841:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636118869884:people_data <- survey_data %>%
1636118869903:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636118869945:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636118870014:other_data <- survey_data %>%
1636118870035:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636118870068:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636118870164:census_data_counts <- census_data %>%
1636118870190:group_by(sex, province, age_range) %>%
1636118870211:summarise(n=n())
1636118870328:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636118870418:census_liberal <- census_data_counts
1636118870468:census_cons <- census_data_counts
1636118870515:census_ndp <- census_data_counts
1636118870564:census_green <- census_data_counts
1636118870625:census_quebec <- census_data_counts
1636118870673:census_people <- census_data_counts
1636118870723:census_other <- census_data_counts
1636118870769:##generate estimates of voting for liberal
1636118870790:census_liberal$liberal_estimate <- liberal_model %>%
1636118870808:predict(newdata=census_liberal)
1636118870857:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636118870913:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636118870958:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636118870980:#generate estimate for voting conservative
1636118871000:census_cons$estimate <- conservative_model %>%
1636118871016:predict(newdata=census_cons)
1636118871071:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636118871120:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636118871188:cons_pred <- sum(census_cons$predict_prop)
1636118871208:#generate estimate for voting ndp
1636118871226:census_ndp$estimate <- ndp_model %>%
1636118871246:predict(newdata=census_ndp)
1636118871302:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636118871347:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636118871395:ndp_pred <- sum(census_ndp$predict_prop)
1636118871417:#generate estimate for voting bloc quebecois
1636118871436:census_quebec$estimate <- blocq_model %>%
1636118871454:predict(newdata=census_quebec)
1636118871503:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636118871568:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636118871616:quebec_pred <- sum(census_quebec$predict_prop)
1636118871635:#generate estimate for voting green party
1636118871651:census_green$estimate <- green_model %>%
1636118871667:predict(newdata=census_green)
1636118871715:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636118871759:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636118871810:green_pred <- sum(census_green$predict_prop)
1636118871829:#generate estimate for voting people's party
1636118871846:census_people$estimate <- people_model %>%
1636118871866:predict(newdata=census_people)
1636118871937:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636118871981:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636118872031:people_pred <- sum(census_people$predict_prop)
1636118872050:#generate estimate for voting other
1636118872066:census_other$estimate <- other_model %>%
1636118872087:predict(newdata=census_other)
1636118872142:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636118872204:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636118872255:other_pred <- sum(census_other$predict_prop)
1636118872303:lib_pred
1636118872342:cons_pred
1636118872378:ndp_pred
1636118872419:quebec_pred
1636118872461:green_pred
1636118872491:people_pred
1636118872517:other_pred
1636118872567:# Here you can include some relevant visualizations.
1636119026332:#select variables from data that we need for analysis
1636119026351:survey_data <-
1636119026370:survey_data %>%
1636119026391:select(age_range, p3, q3, q4) %>%
1636119026411:rename(sex = q3, province = q4, vote = p3)
1636119030860:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636119030882:library(openintro)
1636119030909:library(tidyverse)
1636119030961:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636119030988:census_data <- read_csv("gss_clean.csv")
1636119031140:# You may need additional chunks, in case you want to include some of the cleaning output.
1636119031187:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636119031214:# First, if you don't already have it, install the devtools package:
1636119031235:# install.packages("devtools")
1636119031254:# Now use devtools to install the cesR package directly from Github:
1636119031280:# devtools::install_github("hodgettsp/cesR")
1636119031462:# Load it like any other package:
1636119031486:#library(cesR)
1636119031508:# There are many different CES datasets, and they have unique codes.
1636119031529:# See them with the get_cescodes() function:
1636119031552:#get_cescodes()
1636119031575:# Now pick one, let's try ces2019_phone
1636119031597:#get_ces("ces2019_phone")
1636119031621:#survey_data <- ces2019_phone
1636119031645:# Alternative to what is in the comments above, I have locally loaded
1636119031669:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636119031688:# We can load it in:
1636119031712:survey_data <- read_csv("ces2019-phone_clean.csv")
1636119032002:#select variables from data that we need for analysis
1636119032025:survey_data <-
1636119032046:survey_data %>%
1636119032066:select(age_range, p3, q3, q4) %>%
1636119032091:rename(sex = q3, province = q4, vote = p3)
1636119032121:#filter data
1636119032142:survey_data <-
1636119032164:survey_data %>%
1636119032183:filter(sex == "1" | sex == "2")
1636119032223:survey_data <-
1636119032241:survey_data %>%
1636119032259:filter(province %in% (1:10))
1636119032284:survey_data <-
1636119032304:survey_data %>%
1636119032321:filter(vote %in% (1:8))
1636119032346:#convert categorical data from numeric to string
1636119032364:survey_data$province <- as.character(survey_data$province)
1636119032383:survey_data$sex <- as.character(survey_data$sex)
1636119032401:survey_data$vote <- as.character(survey_data$vote)
1636119032423:#replace sex key with sex title
1636119032443:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636119032463:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636119032481:#replace province key with province name
1636119032497:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636119032518:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636119032535:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636119032554:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636119032572:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636119032592:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636119032614:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636119032633:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636119032654:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636119032673:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636119032694:#replace party key with party name
1636119032712:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636119032735:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636119032757:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636119032783:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636119032803:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636119032825:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636119032846:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636119032868:#replace age_range key with age range
1636119032888:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636119032918:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636119032946:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636119032973:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636119033003:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636119033053:#select age, province, and sex from census
1636119033075:#filter out data that does not include the province or the sex of the respondent
1636119033098:#filter out respondents who aren't old enough to vote
1636119033115:census_data <- census_data %>%
1636119033133:mutate(age=round(age)) %>%
1636119033153:filter(province == "Newfoundland and Labrador"|
1636119033172:province == "Prince Edward Island"|
1636119033190:province == "Nova Scotia"|
1636119033207:province == "New Brunswick"|
1636119033224:province == "Quebec"|
1636119033246:province == "Ontario"|
1636119033265:province == "Manitoba"|
1636119033287:province == "Saskatchewan"|
1636119033312:province == "Alberta"|
1636119033333:province == "British Columbia") %>%
1636119033355:filter(sex == "Female" | sex == "Male") %>%
1636119033377:filter(age >= 18) %>%
1636119033396:select(age, sex, province)%>%
1636119033417:rename(age_range = age)
1636119033561:#census_data$age_range <- as.character(census_data$age_range)
1636119033579:#replace age with age range
1636119033601:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636119033642:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636119033673:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636119033703:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636119033731:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636119033782:# Use this to calculate some summary measures.
1636119033804:library(readr)
1636119033827:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636119033852:prop.table(table(survey_data$age_range , survey_data$vote))
1636119034117:prop.table(table(survey_data$sex , survey_data$vote))
1636119034263:prop.table(table(survey_data$province , survey_data$vote))
1636119034761:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636119034792:ggplot(survey_data, aes(x = (vote))) +
1636119034813:xlab("Voted Party") +
1636119034834:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119034855:facet_grid(~ age_range) +
1636119034878:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119035118:ggplot(survey_data, aes(x = (vote))) +
1636119035139:xlab("Voted Party") +
1636119035158:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119035179:facet_grid(~ sex) +
1636119035197:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119035445:ggplot(survey_data, aes(x = (vote))) +
1636119035465:xlab("Voted Party") +
1636119035484:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119035503:facet_grid(~ province) +
1636119035520:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119036195:# Creating the Model
1636119036214:liberal_data <- survey_data %>%
1636119036236:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636119036300:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636119036332:conservative_data <- survey_data %>%
1636119036349:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636119036379:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636119036414:ndp_data <- survey_data %>%
1636119036431:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636119036464:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636119036497:blocq_data <- survey_data %>%
1636119036516:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636119036546:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636119036606:green_data <- survey_data %>%
1636119036625:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636119036657:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636119036702:people_data <- survey_data %>%
1636119036719:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636119036750:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636119036816:other_data <- survey_data %>%
1636119036836:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636119036873:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636119036966:census_data_counts <- census_data %>%
1636119036992:group_by(sex, province, age_range) %>%
1636119037010:summarise(n=n())
1636119037106:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636119037176:census_liberal <- census_data_counts
1636119037228:census_cons <- census_data_counts
1636119037274:census_ndp <- census_data_counts
1636119037336:census_green <- census_data_counts
1636119037386:census_quebec <- census_data_counts
1636119037432:census_people <- census_data_counts
1636119037480:census_other <- census_data_counts
1636119037529:##generate estimates of voting for liberal
1636119037549:census_liberal$liberal_estimate <- liberal_model %>%
1636119037567:predict(newdata=census_liberal)
1636119037619:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636119037677:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636119037731:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636119037752:#generate estimate for voting conservative
1636119037772:census_cons$estimate <- conservative_model %>%
1636119037796:predict(newdata=census_cons)
1636119037850:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636119037898:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636119037948:cons_pred <- sum(census_cons$predict_prop)
1636119037971:#generate estimate for voting ndp
1636119037991:census_ndp$estimate <- ndp_model %>%
1636119038011:predict(newdata=census_ndp)
1636119038079:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636119038138:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636119038193:ndp_pred <- sum(census_ndp$predict_prop)
1636119038214:#generate estimate for voting bloc quebecois
1636119038231:census_quebec$estimate <- blocq_model %>%
1636119038249:predict(newdata=census_quebec)
1636119038309:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636119038369:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636119038424:quebec_pred <- sum(census_quebec$predict_prop)
1636119038441:#generate estimate for voting green party
1636119038460:census_green$estimate <- green_model %>%
1636119038479:predict(newdata=census_green)
1636119038527:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636119038575:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636119038620:green_pred <- sum(census_green$predict_prop)
1636119038638:#generate estimate for voting people's party
1636119038656:census_people$estimate <- people_model %>%
1636119038673:predict(newdata=census_people)
1636119038732:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636119038776:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636119038822:people_pred <- sum(census_people$predict_prop)
1636119038840:#generate estimate for voting other
1636119038863:census_other$estimate <- other_model %>%
1636119038883:predict(newdata=census_other)
1636119038934:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636119038980:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636119039040:other_pred <- sum(census_other$predict_prop)
1636119039081:lib_pred
1636119039112:cons_pred
1636119039139:ndp_pred
1636119039166:quebec_pred
1636119039192:green_pred
1636119039218:people_pred
1636119039248:other_pred
1636119039304:# Here you can include some relevant visualizations.
1636119041982:#select variables from data that we need for analysis
1636119042005:survey_data <-
1636119042022:survey_data %>%
1636119042039:select(age_range, p3, q3, q4) %>%
1636119042060:rename(sex = q3, province = q4, vote = p3)
1636119044850:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636119044870:library(openintro)
1636119044892:library(tidyverse)
1636119044936:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636119044965:census_data <- read_csv("gss_clean.csv")
1636119045122:# You may need additional chunks, in case you want to include some of the cleaning output.
1636119045160:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636119045184:# First, if you don't already have it, install the devtools package:
1636119045204:# install.packages("devtools")
1636119045224:# Now use devtools to install the cesR package directly from Github:
1636119045246:# devtools::install_github("hodgettsp/cesR")
1636119045420:# Load it like any other package:
1636119045444:#library(cesR)
1636119045469:# There are many different CES datasets, and they have unique codes.
1636119045492:# See them with the get_cescodes() function:
1636119045517:#get_cescodes()
1636119045541:# Now pick one, let's try ces2019_phone
1636119045564:#get_ces("ces2019_phone")
1636119045584:#survey_data <- ces2019_phone
1636119045607:# Alternative to what is in the comments above, I have locally loaded
1636119045628:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636119045651:# We can load it in:
1636119045673:survey_data <- read_csv("ces2019-phone_clean.csv")
1636119045935:#select variables from data that we need for analysis
1636119045968:survey_data <-
1636119045990:survey_data %>%
1636119046010:select(age_range, p3, q3, q4) %>%
1636119046033:rename(sex = q3, province = q4, vote = p3)
1636119046065:#filter data
1636119046086:survey_data <-
1636119046108:survey_data %>%
1636119046127:filter(sex == "1" | sex == "2")
1636119046162:survey_data <-
1636119046179:survey_data %>%
1636119046198:filter(province %in% (1:10))
1636119046222:survey_data <-
1636119046247:survey_data %>%
1636119046269:filter(vote %in% (1:8))
1636119046296:#convert categorical data from numeric to string
1636119046317:survey_data$province <- as.character(survey_data$province)
1636119046338:survey_data$sex <- as.character(survey_data$sex)
1636119046362:survey_data$vote <- as.character(survey_data$vote)
1636119046385:#replace sex key with sex title
1636119046406:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636119046431:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636119046452:#replace province key with province name
1636119046474:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636119046498:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636119046522:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636119046548:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636119046570:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636119046592:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636119046613:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636119046634:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636119046655:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636119046678:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636119046702:#replace party key with party name
1636119046724:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636119046749:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636119046768:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636119046786:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636119046807:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636119046826:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636119046848:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636119046870:#replace age_range key with age range
1636119046890:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636119046921:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636119046949:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636119046987:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636119047016:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636119047057:#select age, province, and sex from census
1636119047076:#filter out data that does not include the province or the sex of the respondent
1636119047094:#filter out respondents who aren't old enough to vote
1636119047158:census_data <- census_data %>%
1636119047198:mutate(age=round(age)) %>%
1636119047220:filter(province == "Newfoundland and Labrador"|
1636119047238:province == "Prince Edward Island"|
1636119047256:province == "Nova Scotia"|
1636119047274:province == "New Brunswick"|
1636119047291:province == "Quebec"|
1636119047313:province == "Ontario"|
1636119047332:province == "Manitoba"|
1636119047353:province == "Saskatchewan"|
1636119047373:province == "Alberta"|
1636119047392:province == "British Columbia") %>%
1636119047414:filter(sex == "Female" | sex == "Male") %>%
1636119047433:filter(age >= 18) %>%
1636119047456:select(age, sex, province)%>%
1636119047475:rename(age_range = age)
1636119047624:#census_data$age_range <- as.character(census_data$age_range)
1636119047646:#replace age with age range
1636119047669:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636119047712:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636119047739:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636119047768:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636119047794:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636119047845:# Use this to calculate some summary measures.
1636119047874:library(readr)
1636119047895:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636119047917:prop.table(table(survey_data$age_range , survey_data$vote))
1636119048162:prop.table(table(survey_data$sex , survey_data$vote))
1636119048293:prop.table(table(survey_data$province , survey_data$vote))
1636119048785:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636119048813:ggplot(survey_data, aes(x = (vote))) +
1636119048834:xlab("Voted Party") +
1636119048855:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119048876:facet_grid(~ age_range) +
1636119048902:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119049124:ggplot(survey_data, aes(x = (vote))) +
1636119049147:xlab("Voted Party") +
1636119049164:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119049184:facet_grid(~ sex) +
1636119049201:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119049459:ggplot(survey_data, aes(x = (vote))) +
1636119049477:xlab("Voted Party") +
1636119049497:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636119049530:facet_grid(~ province) +
1636119049549:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636119050231:# Creating the Model
1636119050257:liberal_data <- survey_data %>%
1636119050280:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636119050313:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636119050347:conservative_data <- survey_data %>%
1636119050367:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636119050399:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636119050432:ndp_data <- survey_data %>%
1636119050453:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636119050488:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636119050550:blocq_data <- survey_data %>%
1636119050570:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636119050603:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636119050665:green_data <- survey_data %>%
1636119050691:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636119050725:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636119050761:people_data <- survey_data %>%
1636119050783:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636119050815:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636119050891:other_data <- survey_data %>%
1636119050915:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636119050948:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636119051036:census_data_counts <- census_data %>%
1636119051060:group_by(sex, province, age_range) %>%
1636119051079:summarise(n=n())
1636119051178:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636119051251:census_liberal <- census_data_counts
1636119051304:census_cons <- census_data_counts
1636119051351:census_ndp <- census_data_counts
1636119051406:census_green <- census_data_counts
1636119051458:census_quebec <- census_data_counts
1636119051502:census_people <- census_data_counts
1636119051544:census_other <- census_data_counts
1636119051588:##generate estimates of voting for liberal
1636119051605:census_liberal$liberal_estimate <- liberal_model %>%
1636119051622:predict(newdata=census_liberal)
1636119051669:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636119051730:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636119051778:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636119051799:#generate estimate for voting conservative
1636119051819:census_cons$estimate <- conservative_model %>%
1636119051836:predict(newdata=census_cons)
1636119051886:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636119051931:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636119051977:cons_pred <- sum(census_cons$predict_prop)
1636119051998:#generate estimate for voting ndp
1636119052020:census_ndp$estimate <- ndp_model %>%
1636119052041:predict(newdata=census_ndp)
1636119052104:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636119052146:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636119052193:ndp_pred <- sum(census_ndp$predict_prop)
1636119052216:#generate estimate for voting bloc quebecois
1636119052237:census_quebec$estimate <- blocq_model %>%
1636119052259:predict(newdata=census_quebec)
1636119052309:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636119052355:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636119052416:quebec_pred <- sum(census_quebec$predict_prop)
1636119052452:#generate estimate for voting green party
1636119052471:census_green$estimate <- green_model %>%
1636119052490:predict(newdata=census_green)
1636119052538:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636119052585:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636119052635:green_pred <- sum(census_green$predict_prop)
1636119052658:#generate estimate for voting people's party
1636119052680:census_people$estimate <- people_model %>%
1636119052699:predict(newdata=census_people)
1636119052761:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636119052816:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636119052864:people_pred <- sum(census_people$predict_prop)
1636119052884:#generate estimate for voting other
1636119052910:census_other$estimate <- other_model %>%
1636119052929:predict(newdata=census_other)
1636119052979:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636119053028:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636119053102:other_pred <- sum(census_other$predict_prop)
1636119053151:lib_pred
1636119053192:cons_pred
1636119053226:ndp_pred
1636119053254:quebec_pred
1636119053290:green_pred
1636119053326:people_pred
1636119053354:other_pred
1636119053411:# Here you can include some relevant visualizations.
1636119089717:# Use this to calculate some summary measures.
1636119089737:library(readr)
1636119089753:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636119089773:prop.table(table(survey_data$age_range , survey_data$vote))
1636119090011:prop.table(table(survey_data$sex , survey_data$vote))
1636119090154:prop.table(table(survey_data$province , survey_data$vote))
1636137493109:# Here you can include some relevant visualizations.
1636137493147:kable(lib_pred)
1636137498011:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636137498033:library(openintro)
1636137498166:library(tidyverse)
1636137498187:library(knitr)
1636137498255:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636137498283:census_data <- read_csv("gss_clean.csv")
1636137498736:# You may need additional chunks, in case you want to include some of the cleaning output.
1636137498803:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636137498847:# First, if you don't already have it, install the devtools package:
1636137498870:# install.packages("devtools")
1636137498890:# Now use devtools to install the cesR package directly from Github:
1636137498909:# devtools::install_github("hodgettsp/cesR")
1636137499194:# Load it like any other package:
1636137499218:#library(cesR)
1636137499242:# There are many different CES datasets, and they have unique codes.
1636137499265:# See them with the get_cescodes() function:
1636137499286:#get_cescodes()
1636137499317:# Now pick one, let's try ces2019_phone
1636137499340:#get_ces("ces2019_phone")
1636137499362:#survey_data <- ces2019_phone
1636137499385:# Alternative to what is in the comments above, I have locally loaded
1636137499410:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636137499435:# We can load it in:
1636137499456:survey_data <- read_csv("ces2019-phone_clean.csv")
1636137499971:#select variables from data that we need for analysis
1636137500002:survey_data <-
1636137500025:survey_data %>%
1636137500047:select(age_range, p3, q3, q4) %>%
1636137500070:rename(sex = q3, province = q4, vote = p3)
1636137500113:#filter data
1636137500133:survey_data <-
1636137500153:survey_data %>%
1636137500175:filter(sex == "1" | sex == "2")
1636137500220:survey_data <-
1636137500243:survey_data %>%
1636137500267:filter(province %in% (1:10))
1636137500297:survey_data <-
1636137500321:survey_data %>%
1636137500343:filter(vote %in% (1:8))
1636137500372:#convert categorical data from numeric to string
1636137500395:survey_data$province <- as.character(survey_data$province)
1636137500420:survey_data$sex <- as.character(survey_data$sex)
1636137500441:survey_data$vote <- as.character(survey_data$vote)
1636137500461:#replace sex key with sex title
1636137500482:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636137500513:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636137500536:#replace province key with province name
1636137500560:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636137500586:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636137500608:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636137500628:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636137500652:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636137500678:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636137500699:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636137500724:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636137500745:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636137500768:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636137500789:#replace party key with party name
1636137500815:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636137500857:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636137500883:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636137500906:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636137500926:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636137500952:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636137500975:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636137500998:#replace age_range key with age range
1636137501018:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636137501051:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636137501086:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636137501133:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636137501166:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636137501218:#select age, province, and sex from census
1636137501243:#filter out data that does not include the province or the sex of the respondent
1636137501265:#filter out respondents who aren't old enough to vote
1636137501299:census_data <- census_data %>%
1636137501320:mutate(age=round(age)) %>%
1636137501343:filter(province == "Newfoundland and Labrador"|
1636137501364:province == "Prince Edward Island"|
1636137501390:province == "Nova Scotia"|
1636137501414:province == "New Brunswick"|
1636137501441:province == "Quebec"|
1636137501465:province == "Ontario"|
1636137501489:province == "Manitoba"|
1636137501509:province == "Saskatchewan"|
1636137501542:province == "Alberta"|
1636137501566:province == "British Columbia") %>%
1636137501589:filter(sex == "Female" | sex == "Male") %>%
1636137501610:filter(age >= 18) %>%
1636137501637:select(age, sex, province)%>%
1636137501660:rename(age_range = age)
1636137501854:#census_data$age_range <- as.character(census_data$age_range)
1636137501876:#replace age with age range
1636137501894:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636137501940:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636137501978:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636137502010:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636137502042:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636137502100:# Use this to calculate some summary measures.
1636137502128:library(readr)
1636137502152:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636137502172:prop.table(table(survey_data$age_range , survey_data$vote))
1636137502461:prop.table(table(survey_data$sex , survey_data$vote))
1636137502624:prop.table(table(survey_data$province , survey_data$vote))
1636137503152:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636137503181:ggplot(survey_data, aes(x = (vote))) +
1636137503206:xlab("Voted Party") +
1636137503228:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636137503251:facet_grid(~ age_range) +
1636137503274:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636137503716:ggplot(survey_data, aes(x = (vote))) +
1636137503738:xlab("Voted Party") +
1636137503763:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636137503786:facet_grid(~ sex) +
1636137503810:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636137504110:ggplot(survey_data, aes(x = (vote))) +
1636137504133:xlab("Voted Party") +
1636137504157:scale_y_continuous(labels = scales::percent, name = "Distribution") +
1636137504179:facet_grid(~ province) +
1636137504199:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1636137504910:# Creating the Model
1636137504940:liberal_data <- survey_data %>%
1636137504963:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636137505000:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636137505045:conservative_data <- survey_data %>%
1636137505069:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636137505105:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636137505144:ndp_data <- survey_data %>%
1636137505168:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636137505203:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636137505250:blocq_data <- survey_data %>%
1636137505276:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636137505319:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636137505402:green_data <- survey_data %>%
1636137505422:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636137505455:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636137505509:people_data <- survey_data %>%
1636137505537:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636137505574:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636137505666:other_data <- survey_data %>%
1636137505691:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636137505728:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636137505847:census_data_counts <- census_data %>%
1636137505869:group_by(sex, province, age_range) %>%
1636137505897:summarise(n=n())
1636137506017:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636137506092:census_liberal <- census_data_counts
1636137506148:census_cons <- census_data_counts
1636137506218:census_ndp <- census_data_counts
1636137506270:census_green <- census_data_counts
1636137506325:census_quebec <- census_data_counts
1636137506385:census_people <- census_data_counts
1636137506499:census_other <- census_data_counts
1636137506553:##generate estimates of voting for liberal
1636137506578:census_liberal$liberal_estimate <- liberal_model %>%
1636137506603:predict(newdata=census_liberal)
1636137506664:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636137506717:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636137506792:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636137506819:#generate estimate for voting conservative
1636137506841:census_cons$estimate <- conservative_model %>%
1636137506864:predict(newdata=census_cons)
1636137506951:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636137507010:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636137507070:cons_pred <- sum(census_cons$predict_prop)
1636137507097:#generate estimate for voting ndp
1636137507132:census_ndp$estimate <- ndp_model %>%
1636137507160:predict(newdata=census_ndp)
1636137507235:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636137507293:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636137507351:ndp_pred <- sum(census_ndp$predict_prop)
1636137507377:#generate estimate for voting bloc quebecois
1636137507404:census_quebec$estimate <- blocq_model %>%
1636137507432:predict(newdata=census_quebec)
1636137507489:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636137507549:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636137507631:quebec_pred <- sum(census_quebec$predict_prop)
1636137507661:#generate estimate for voting green party
1636137507685:census_green$estimate <- green_model %>%
1636137507708:predict(newdata=census_green)
1636137507764:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636137507817:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636137507872:green_pred <- sum(census_green$predict_prop)
1636137507892:#generate estimate for voting people's party
1636137507925:census_people$estimate <- people_model %>%
1636137507945:predict(newdata=census_people)
1636137508016:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636137508070:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636137508123:people_pred <- sum(census_people$predict_prop)
1636137508150:#generate estimate for voting other
1636137508173:census_other$estimate <- other_model %>%
1636137508197:predict(newdata=census_other)
1636137508266:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636137508343:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636137508404:other_pred <- sum(census_other$predict_prop)
1636137508455:lib_pred
1636137508499:cons_pred
1636137508538:ndp_pred
1636137508582:quebec_pred
1636137508618:green_pred
1636137508659:people_pred
1636137508696:other_pred
1636137508760:# Here you can include some relevant visualizations.
1636137508804:kable(lib_pred)
1636137750754:lib_pred
1636137750796:cons_pred
1636137750836:ndp_pred
1636137750874:quebec_pred
1636137750905:green_pred
1636137750938:people_pred
1636137750977:other_pred
1636137751028:df <- df(lib_pred, cons_pred)
1636137803289:lib_pred
1636137803328:cons_pred
1636137803367:ndp_pred
1636137803407:quebec_pred
1636137803442:green_pred
1636137803487:people_pred
1636137803523:other_pred
1636137803573:df <- data.frame(lib_pred, cons_pred)
1636137803601:df
1636137811815:lib_pred
1636137811850:cons_pred
1636137811882:ndp_pred
1636137811920:quebec_pred
1636137811958:green_pred
1636137812003:people_pred
1636137812042:other_pred
1636137812104:df <- data.frame(lib_pred, cons_pred)
1636137812132:df
1636137851542:lib_pred
1636137851580:cons_pred
1636137851626:ndp_pred
1636137851669:quebec_pred
1636137851711:green_pred
1636137851750:people_pred
1636137851788:other_pred
1636137851835:df <- data.frame(lib_pred, cons_pred, ndp_pred, quebec_pred, green_pred, people_pred, other_pred)
1636137851867:df
1636137907852:# Here you can include some relevant visualizations.
1636137907904:kable(df)
1636142472813:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636142472837:library(openintro)
1636142472863:library(tidyverse)
1636142472920:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636142472956:census_data <- read_csv("gss_clean.csv")
1636142473144:# You may need additional chunks, in case you want to include some of the cleaning output.
1636142473197:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636142473231:# First, if you don't already have it, install the devtools package:
1636142473252:# install.packages("devtools")
1636142473276:# Now use devtools to install the cesR package directly from Github:
1636142473313:# devtools::install_github("hodgettsp/cesR")
1636142473596:# Load it like any other package:
1636142473618:#library(cesR)
1636142473641:# There are many different CES datasets, and they have unique codes.
1636142473668:# See them with the get_cescodes() function:
1636142473696:#get_cescodes()
1636142473718:# Now pick one, let's try ces2019_phone
1636142473740:#get_ces("ces2019_phone")
1636142473762:#survey_data <- ces2019_phone
1636142473782:# Alternative to what is in the comments above, I have locally loaded
1636142473809:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636142473830:# We can load it in:
1636142473891:survey_data <- read_csv("ces2019-phone_clean.csv")
1636142474473:#select variables from data that we need for analysis
1636142474506:survey_data <-
1636142474532:survey_data %>%
1636142474556:select(age, age_range, p3, q3, q4) %>%
1636142474584:rename(sex = q3, province = q4, vote = p3)
1636142474617:#filter data
1636142474640:#We start by reducing the survey's Gender variable into just male and female by removing all non-binary observations, this won't be an ethical or statistical issue as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female, which represents less than 0.1% of the total observations in the survey.
1636142474662:#Then, given that we have Gender as a binary variable we make the assumption that its proportion of male and female observations is a good enough estimate for us to accurately impute sex from gender.
1636142474683:survey_data <-
1636142474711:survey_data %>%
1636142474740:filter(sex == "1" | sex == "2")
1636142474795:survey_data <-
1636142474818:survey_data %>%
1636142474844:filter(province %in% (1:10))
1636142474881:survey_data <-
1636142474902:survey_data %>%
1636142474926:filter(vote %in% (1:7))
1636142474961:#convert categorical data from numeric to string
1636142474992:survey_data$province <- as.character(survey_data$province)
1636142475018:survey_data$sex <- as.character(survey_data$sex)
1636142475041:survey_data$vote <- as.character(survey_data$vote)
1636142475067:#replace sex key with sex title
1636142475099:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636142475144:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636142475175:#replace province key with province name
1636142475203:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636142475236:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636142475261:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636142475292:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636142475321:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636142475343:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636142475372:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636142475398:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636142475421:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636142475442:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636142475466:#replace party key with party name
1636142475488:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636142475515:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636142475541:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636142475569:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636142475600:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636142475623:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636142475646:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636142475705:#replace age_range key with age range
1636142475732:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636142475768:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636142475792:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636142475820:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636142475845:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636142475900:#select age, province, and sex from census
1636142475926:#filter out data that does not include the province or the sex of the respondent
1636142475949:#filter out respondents who aren't old enough to vote
1636142475970:census_data <- census_data %>%
1636142475994:mutate(age=round(age)) %>%
1636142476015:filter(province == "Newfoundland and Labrador"|
1636142476039:province == "Prince Edward Island"|
1636142476063:province == "Nova Scotia"|
1636142476084:province == "New Brunswick"|
1636142476112:province == "Quebec"|
1636142476133:province == "Ontario"|
1636142476155:province == "Manitoba"|
1636142476177:province == "Saskatchewan"|
1636142476199:province == "Alberta"|
1636142476221:province == "British Columbia") %>%
1636142476241:filter(sex == "Female" | sex == "Male") %>%
1636142476262:filter(age >= 18) %>%
1636142476285:select(age, sex, province)%>%
1636142476308:rename(age_range = age)
1636142476494:#census_data$age_range <- as.character(census_data$age_range)
1636142476523:#replace age with age range
1636142476552:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636142476606:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636142476646:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636142476688:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636142476719:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636142476776:library(readr)
1636142476805:#For the summaries given that we are dealing with categorical variables we will produce contingency tables .
1636142476827:prop.table(table(survey_data$age_range , survey_data$vote))
1636142477104:prop.table(table(survey_data$sex , survey_data$vote))
1636142477257:prop.table(table(survey_data$province , survey_data$vote))
1636142477788:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636142477829:# survey_data %>% ggplot(aes(y=reorder(province,province,
1636142477852:#                      function(x)length(x)), x = (..count..)/sum(..count..))) + geom_bar(aes(fill = vote), position = "identity") + labs(title = "Proportion of each Province that voted for each Party", y="Province", x="Proportion", fill="Party")
1636142477872:survey_data %>% ggplot(aes(y=reorder(province,province,
1636142477899:function(x)length(x)), x = (..count..)/sum(..count..))) + geom_bar(aes(fill = vote))+ labs(title = "Proportion of each Province that voted for each Party", y="Province", x="Proportion", fill="Party")
1636142478537:# Creating the Model
1636142478565:liberal_data <- survey_data %>%
1636142478596:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636142478633:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636142478670:conservative_data <- survey_data %>%
1636142478690:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636142478721:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636142478765:ndp_data <- survey_data %>%
1636142478789:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636142478821:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636142478880:blocq_data <- survey_data %>%
1636142478907:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636142478936:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636142479196:green_data <- survey_data %>%
1636142479218:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636142479243:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636142479278:people_data <- survey_data %>%
1636142479302:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636142479326:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636142479414:other_data <- survey_data %>%
1636142479435:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636142479464:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636142479543:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636142479906:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636142480445:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636142480820:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636142481180:step(green_model, trace = 0, k = log(nrow(green_data)))
1636142481532:step(people_model, trace = 0, k = log(nrow(people_data)))
1636142481856:step(other_model, trace = 0, k = log(nrow(other_data)))
1636142482256:census_data_counts <- census_data %>%
1636142482287:group_by(sex, province, age_range) %>%
1636142482311:summarise(n=n())
1636142482436:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636142482518:census_liberal <- census_data_counts
1636142482579:census_cons <- census_data_counts
1636142482639:census_ndp <- census_data_counts
1636142482685:census_green <- census_data_counts
1636142482733:census_quebec <- census_data_counts
1636142482783:census_people <- census_data_counts
1636142482842:census_other <- census_data_counts
1636142482910:##generate estimates of voting for liberal
1636142482938:census_liberal$liberal_estimate <- liberal_model %>%
1636142482960:predict(newdata=census_liberal)
1636142483018:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636142483072:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636142483142:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636142483165:#generate estimate for voting conservative
1636142483187:census_cons$estimate <- conservative_model %>%
1636142483207:predict(newdata=census_cons)
1636142483276:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636142483342:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636142483393:cons_pred <- sum(census_cons$predict_prop)
1636142483416:#generate estimate for voting ndp
1636142483436:census_ndp$estimate <- ndp_model %>%
1636142483464:predict(newdata=census_ndp)
1636142483528:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636142483586:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636142483643:ndp_pred <- sum(census_ndp$predict_prop)
1636142483671:#generate estimate for voting bloc quebecois
1636142483693:census_quebec$estimate <- blocq_model %>%
1636142483715:predict(newdata=census_quebec)
1636142483766:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636142483815:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636142483886:quebec_pred <- sum(census_quebec$predict_prop)
1636142483910:#generate estimate for voting green party
1636142483932:census_green$estimate <- green_model %>%
1636142483955:predict(newdata=census_green)
1636142484015:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636142484065:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636142484134:green_pred <- sum(census_green$predict_prop)
1636142484156:#generate estimate for voting people's party
1636142484177:census_people$estimate <- people_model %>%
1636142484199:predict(newdata=census_people)
1636142484258:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636142484312:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636142484371:people_pred <- sum(census_people$predict_prop)
1636142484392:#generate estimate for voting other
1636142484414:census_other$estimate <- other_model %>%
1636142484437:predict(newdata=census_other)
1636142484493:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636142484553:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636142484620:other_pred <- sum(census_other$predict_prop)
1636142484667:lib_pred
1636142484703:cons_pred
1636142484735:ndp_pred
1636142484770:quebec_pred
1636142484816:green_pred
1636142484861:people_pred
1636142484900:other_pred
1636144690960:knitr::opts_chunk$set(warning = FALSE, message = FALSE)
1636144690977:library(openintro)
1636144691002:library(tidyverse)
1636144691041:# Here you can load in and clean the census data (you may need to do the cleaning in a separate R script).
1636144691067:census_data <- read_csv("gss_clean.csv")
1636144691236:# You may need additional chunks, in case you want to include some of the cleaning output.
1636144691280:# Here you can load in and clean the survey data (you may need to do the cleaning in a separate R script).
1636144691307:# First, if you don't already have it, install the devtools package:
1636144691330:# install.packages("devtools")
1636144691349:# Now use devtools to install the cesR package directly from Github:
1636144691371:# devtools::install_github("hodgettsp/cesR")
1636144691554:# Load it like any other package:
1636144691577:#library(cesR)
1636144691599:# There are many different CES datasets, and they have unique codes.
1636144691625:# See them with the get_cescodes() function:
1636144691649:#get_cescodes()
1636144691675:# Now pick one, let's try ces2019_phone
1636144691696:#get_ces("ces2019_phone")
1636144691721:#survey_data <- ces2019_phone
1636144691744:# Alternative to what is in the comments above, I have locally loaded
1636144691764:# and (mildly) cleaned the CES2019 phone data and have included it in here.
1636144691787:# We can load it in:
1636144691809:survey_data <- read_csv("ces2019-phone_clean.csv")
1636144692133:#select variables from data that we need for analysis
1636144692157:survey_data <-
1636144692176:survey_data %>%
1636144692196:select(age, age_range, p3, q3, q4) %>%
1636144692218:rename(sex = q3, province = q4, vote = p3)
1636144692246:#filter data
1636144692265:#We start by reducing the survey's Gender variable into just male and female by removing all non-binary observations, this won't be an ethical or statistical issue as among all individuals surveyed there was only 1 case that reported identifying as neither a male or female, which represents less than 0.1% of the total observations in the survey.
1636144692286:#Then, given that we have Gender as a binary variable we make the assumption that its proportion of male and female observations is a good enough estimate for us to accurately impute sex from gender.
1636144692306:survey_data <-
1636144692326:survey_data %>%
1636144692349:filter(sex == "1" | sex == "2")
1636144692387:survey_data <-
1636144692408:survey_data %>%
1636144692430:filter(province %in% (1:10))
1636144692457:survey_data <-
1636144692481:survey_data %>%
1636144692502:filter(vote %in% (1:7))
1636144692533:#convert categorical data from numeric to string
1636144692557:survey_data$province <- as.character(survey_data$province)
1636144692579:survey_data$sex <- as.character(survey_data$sex)
1636144692603:survey_data$vote <- as.character(survey_data$vote)
1636144692626:#replace sex key with sex title
1636144692651:survey_data$sex[survey_data$sex == "1"] <- "Male"
1636144692676:survey_data$sex[survey_data$sex == "2"] <- "Female"
1636144692701:#replace province key with province name
1636144692726:survey_data$province[survey_data$province == "1"] <- "Newfoundland and Labrador"
1636144692754:survey_data$province[survey_data$province == "2"] <- "Prince Edward Island"
1636144692773:survey_data$province[survey_data$province == "3"] <- "Nova Scotia"
1636144692794:survey_data$province[survey_data$province == "4"] <- "New Brunswick"
1636144692815:survey_data$province[survey_data$province == "5"] <- "Quebec"
1636144692835:survey_data$province[survey_data$province == "6"] <- "Ontario"
1636144692858:survey_data$province[survey_data$province == "7"] <- "Manitoba"
1636144692885:survey_data$province[survey_data$province == "8"] <- "Saskatchewan"
1636144692909:survey_data$province[survey_data$province == "9"] <- "Alberta"
1636144692932:survey_data$province[survey_data$province == "10"] <- "British Columbia"
1636144692960:#replace party key with party name
1636144692980:survey_data$vote[survey_data$vote == "1"] <- "Liberal Party"
1636144693009:survey_data$vote[survey_data$vote == "2"] <- "Conservative Party"
1636144693031:survey_data$vote[survey_data$vote == "3"] <- "NDP"
1636144693053:survey_data$vote[survey_data$vote == "4"] <- "Bloc Qubcois"
1636144693072:survey_data$vote[survey_data$vote == "5"] <- "Green Party"
1636144693093:survey_data$vote[survey_data$vote == "6"] <- "People's Party"
1636144693113:survey_data$vote[survey_data$vote == "7"] <- "Other"
1636144693135:#replace age_range key with age range
1636144693155:survey_data$age_range[survey_data$age_range == "1"] <- "18-24"
1636144693182:survey_data$age_range[survey_data$age_range == "2"] <- "25-34"
1636144693202:survey_data$age_range[survey_data$age_range == "3"] <- "35-44"
1636144693221:survey_data$age_range[survey_data$age_range == "4"] <- "45-54"
1636144693243:survey_data$age_range[survey_data$age_range == "5"] <- "55+"
1636144693282:#select age, province, and sex from census
1636144693304:#filter out data that does not include the province or the sex of the respondent
1636144693325:#filter out respondents who aren't old enough to vote
1636144693345:census_data <- census_data %>%
1636144693364:mutate(age=round(age)) %>%
1636144693388:filter(province == "Newfoundland and Labrador"|
1636144693409:province == "Prince Edward Island"|
1636144693426:province == "Nova Scotia"|
1636144693444:province == "New Brunswick"|
1636144693466:province == "Quebec"|
1636144693486:province == "Ontario"|
1636144693506:province == "Manitoba"|
1636144693524:province == "Saskatchewan"|
1636144693542:province == "Alberta"|
1636144693562:province == "British Columbia") %>%
1636144693582:filter(sex == "Female" | sex == "Male") %>%
1636144693602:filter(age >= 18) %>%
1636144693622:select(age, sex, province)%>%
1636144693642:rename(age_range = age)
1636144693833:#census_data$age_range <- as.character(census_data$age_range)
1636144693855:#replace age with age range
1636144693877:census_data$age_range[census_data$age_range >= 18 &census_data$age_range <=24] <- "18-24"
1636144693926:census_data$age_range[census_data$age_range >= 25 &census_data$age_range <=34] <- "25-34"
1636144693955:census_data$age_range[census_data$age_range >= 35 &census_data$age_range <=44] <- "35-44"
1636144693988:census_data$age_range[census_data$age_range >= 45 &census_data$age_range <=54] <- "45-54"
1636144694016:census_data$age_range[census_data$age_range >= 55] <- "55+"
1636144694068:prop.table(table(survey_data$age_range , survey_data$vote))
1636144694316:prop.table(table(survey_data$sex , survey_data$vote))
1636144694492:prop.table(table(survey_data$province , survey_data$vote))
1636144694927:#Here we are plotting our the distribution of the votes across all of our 3 predictor variables
1636144694953:# survey_data %>% ggplot(aes(y=reorder(province,province,
1636144694973:#                      function(x)length(x)), x = (..count..)/sum(..count..))) + geom_bar(aes(fill = vote), position = "identity") + labs(title = "Proportion of each Province that voted for each Party", y="Province", x="Proportion", fill="Party")
1636144694994:survey_data %>% ggplot(aes(y=reorder(province,province,
1636144695016:function(x)length(x)), x = (..count..)/sum(..count..))) + geom_bar(aes(fill = vote))+ labs(title = "Proportion of each Province that voted for each Party", y="Province", x="Proportion", fill="Party")
1636144695576:# Creating the Model
1636144695610:liberal_data <- survey_data %>%
1636144695630:mutate(votedliberal = ifelse(survey_data$vote == "Liberal Party", 1, 0))
1636144695656:liberal_model <- glm(votedliberal ~ sex + province + age_range, data = liberal_data, family = binomial)
1636144695693:conservative_data <- survey_data %>%
1636144695712:mutate(votedconservative = ifelse(survey_data$vote == "Conservative Party", 1, 0))
1636144695738:conservative_model <- glm(votedconservative ~  sex + province + age_range, data = conservative_data, family = binomial)
1636144695773:ndp_data <- survey_data %>%
1636144695792:mutate(votedndp = ifelse(survey_data$vote == "NDP", 1, 0))
1636144695819:ndp_model <- glm(votedndp ~ sex + province + age_range, data = ndp_data, family = binomial)
1636144695854:blocq_data <- survey_data %>%
1636144695874:mutate(votedblocq = ifelse(survey_data$vote == "Bloc Qubcois", 1, 0))
1636144695901:blocq_model <- glm(votedblocq ~ sex + province, data = blocq_data, family = binomial)
1636144695970:green_data <- survey_data %>%
1636144695993:mutate(votedgreen = ifelse(survey_data$vote == "Green Party", 1, 0))
1636144696017:green_model <- glm(votedgreen ~ sex + province + age_range, data = green_data, family = binomial)
1636144696067:people_data <- survey_data %>%
1636144696088:mutate(votedpeople = ifelse(survey_data$vote == "People's Party", 1, 0))
1636144696112:people_model <- glm(votedpeople ~ sex + province + age_range, data = people_data, family = binomial)
1636144696185:other_data <- survey_data %>%
1636144696208:mutate(votedother = ifelse(survey_data$vote == "Other", 1, 0))
1636144696234:other_model <- glm(votedother ~ sex + province + age_range, data = other_data, family = binomial)
1636144696312:step(liberal_model, trace = 0, k = log(nrow(liberal_data)))
1636144696652:step(conservative_model, trace = 0, k = log(nrow(conservative_data)))
1636144696974:step(ndp_model, trace = 0, k = log(nrow(ndp_data)))
1636144697272:step(blocq_model, trace = 0, k = log(nrow(blocq_data)))
1636144697650:step(green_model, trace = 0, k = log(nrow(green_data)))
1636144698002:step(people_model, trace = 0, k = log(nrow(people_data)))
1636144698310:step(other_model, trace = 0, k = log(nrow(other_data)))
1636144698644:census_data_counts <- census_data %>%
1636144698670:group_by(sex, province, age_range) %>%
1636144698692:summarise(n=n())
1636144698797:census_data_counts$group_prop <- census_data_counts$n/sum(census_data_counts$n)
1636144698869:census_liberal <- census_data_counts
1636144698927:census_cons <- census_data_counts
1636144698978:census_ndp <- census_data_counts
1636144699030:census_green <- census_data_counts
1636144699076:census_quebec <- census_data_counts
1636144699119:census_people <- census_data_counts
1636144699167:census_other <- census_data_counts
1636144699212:##generate estimates of voting for liberal
1636144699238:census_liberal$liberal_estimate <- liberal_model %>%
1636144699261:predict(newdata=census_liberal)
1636144699317:census_liberal$liberal_estimate <- exp(census_liberal$liberal_estimate)/(1+exp(census_liberal$liberal_estimate))
1636144699376:census_liberal$liberal_predict_prop <- census_liberal$liberal_estimate * census_liberal$group_prop
1636144699439:lib_pred <- sum(census_liberal$liberal_predict_prop)
1636144699464:#generate estimate for voting conservative
1636144699488:census_cons$estimate <- conservative_model %>%
1636144699511:predict(newdata=census_cons)
1636144699564:census_cons$estimate <- exp(census_cons$estimate)/(1+exp(census_cons$estimate))
1636144699618:census_cons$predict_prop <- census_cons$estimate * census_cons$group_prop
1636144699671:cons_pred <- sum(census_cons$predict_prop)
1636144699698:#generate estimate for voting ndp
1636144699718:census_ndp$estimate <- ndp_model %>%
1636144699737:predict(newdata=census_ndp)
1636144699797:census_ndp$estimate <- exp(census_ndp$estimate)/(1+exp(census_ndp$estimate))
1636144699852:census_ndp$predict_prop <- census_ndp$estimate * census_ndp$group_prop
1636144699904:ndp_pred <- sum(census_ndp$predict_prop)
1636144699927:#generate estimate for voting bloc quebecois
1636144699948:census_quebec$estimate <- blocq_model %>%
1636144699970:predict(newdata=census_quebec)
1636144700019:census_quebec$estimate <- exp(census_quebec$estimate)/(1+exp(census_quebec$estimate))
1636144700070:census_quebec$predict_prop <- census_quebec$estimate * census_quebec$group_prop
1636144700119:quebec_pred <- sum(census_quebec$predict_prop)
1636144700138:#generate estimate for voting green party
1636144700155:census_green$estimate <- green_model %>%
1636144700171:predict(newdata=census_green)
1636144700227:census_green$estimate <- exp(census_green$estimate)/(1+exp(census_green$estimate))
1636144700277:census_green$predict_prop <- census_green$estimate * census_green$group_prop
1636144700339:green_pred <- sum(census_green$predict_prop)
1636144700361:#generate estimate for voting people's party
1636144700382:census_people$estimate <- people_model %>%
1636144700400:predict(newdata=census_people)
1636144700455:census_people$estimate <- exp(census_people$estimate)/(1+exp(census_people$estimate))
1636144700512:census_people$predict_prop <- census_people$estimate * census_people$group_prop
1636144700571:people_pred <- sum(census_people$predict_prop)
1636144700593:#generate estimate for voting other
1636144700614:census_other$estimate <- other_model %>%
1636144700634:predict(newdata=census_other)
1636144700698:census_other$estimate <- exp(census_other$estimate)/(1+exp(census_other$estimate))
1636144700760:census_other$predict_prop <- census_other$estimate * census_other$group_prop
1636144700815:other_pred <- sum(census_other$predict_prop)
1636144700858:lib_pred
1636144700907:cons_pred
1636144700944:ndp_pred
1636144700975:quebec_pred
1636144701007:green_pred
1636144701037:people_pred
1636144701073:other_pred
